{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Orchestry Documentation","text":"<p>Welcome to Orchestry - A lightweight container orchestration and auto-scaling platform designed for web applications.</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":""},{"location":"#for-users","title":"For Users","text":"<ul> <li>Quick Start Guide - Get up and running in minutes</li> <li>CLI Reference - Complete command-line interface documentation</li> <li>Application Specification - How to define your applications</li> <li>Configuration Guide - Environment and scaling configuration</li> <li>REST API Reference - HTTP API endpoints and usage</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"#for-developers","title":"For Developers","text":"<ul> <li>Architecture Overview - System design and components</li> <li>Core Components - Detailed component documentation</li> <li>Leader Election - Distributed controller and high availability</li> <li>Database Schema - State management and persistence</li> <li>Scaling Algorithm - Auto-scaling logic and policies</li> <li>Health Monitoring - Health check system</li> <li>Load Balancing - Nginx integration and routing</li> <li>Development Setup - Contributing to Orchestry</li> <li>Extension Guide - Adding new features</li> </ul>"},{"location":"#examples","title":"Examples","text":"<ul> <li>Sample Applications - Real-world application examples</li> </ul>"},{"location":"#what-is-orchestry","title":"What is Orchestry?","text":"<p>Orchestry is a container orchestration platform that provides:</p> <ul> <li>Intelligent Auto-Scaling: Automatically scales your applications based on CPU, memory, RPS, latency, and connection metrics</li> <li>Load Balancing: Dynamic Nginx configuration with health-aware routing</li> <li>Health Monitoring: Continuous health checks with automatic recovery</li> <li>Simple Deployment: YAML-based application specifications</li> <li>RESTful API: Complete programmatic control</li> <li>High Availability: Distributed controller with leader election eliminates single points of failure</li> <li>Database HA: PostgreSQL-based state management with primary-replica replication</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Container Orchestration: Docker-based application lifecycle management</li> <li>Multi-Metric Auto-Scaling: CPU, memory, RPS, latency, and connection-based scaling</li> <li>Dynamic Load Balancing: Nginx with health-aware routing and SSL termination</li> <li>Health Monitoring: Continuous health checks with automatic recovery</li> <li>Distributed Architecture: 3-node controller cluster with leader election</li> <li>High Availability: Automatic failover and split-brain prevention</li> <li>CLI and REST API: Complete programmatic and command-line interfaces</li> <li>Persistent State: PostgreSQL with primary-replica setup</li> <li>Event Logging: Complete audit trail and cluster event tracking</li> <li>Resource Management: CPU/memory constraints and intelligent scaling policies </li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation</li> <li>Your First Application</li> <li>CLI Commands</li> <li>API Endpoints</li> <li>Architecture</li> </ul> <p>Orchestry v1.0.0 - Built for simplicity, designed for scale</p>"},{"location":"developer-guide/architecture/","title":"Architecture Overview","text":"<p>Understanding Orchestry's system design, components, and architectural decisions.</p>"},{"location":"developer-guide/architecture/#system-architecture","title":"System Architecture","text":"<p>Orchestry follows a microservices architecture with clear separation of concerns. The system is designed to be scalable, resilient, and easy to maintain.</p> <p></p>"},{"location":"developer-guide/architecture/#core-components","title":"Core Components","text":""},{"location":"developer-guide/architecture/#1-api-server-fastapi","title":"1. API Server (FastAPI)","text":"<p>Purpose: Provides REST API endpoints for external interaction</p> <p>Key Responsibilities: - Accept API requests for application management - Validate input specifications - Coordinate with other components - Return structured responses - Handle authentication and authorization (future)</p> <p>Technology: FastAPI with uvicorn ASGI server</p> <p>Key Files: - <code>controller/api.py</code> - Main API endpoints - <code>controller/main.py</code> - Application entry point</p>"},{"location":"developer-guide/architecture/#2-application-manager","title":"2. Application Manager","text":"<p>Purpose: Manages the lifecycle of containerized applications</p> <p>Key Responsibilities: - Register applications from specifications - Create and destroy Docker containers - Monitor container health and status - Handle container networking - Manage application scaling</p> <p>Technology: Docker Python SDK</p> <p>Key Files: - <code>controller/manager.py</code> - Core application management logic - <code>app_spec/models.py</code> - Application specification models</p> <p>Key Operations: <pre><code># Register a new application\napp_manager.register_app(app_spec)\n\n# Start application with desired replicas\napp_manager.start_app(app_name, replicas=3)\n\n# Scale application\napp_manager.scale_app(app_name, target_replicas=5)\n\n# Stop application\napp_manager.stop_app(app_name)\n</code></pre></p>"},{"location":"developer-guide/architecture/#3-auto-scaler","title":"3. Auto Scaler","text":"<p>Purpose: Makes intelligent scaling decisions based on metrics</p> <p>Key Responsibilities: - Collect application metrics (CPU, memory, RPS, latency) - Analyze metrics against scaling policies - Make scale-out/scale-in decisions - Implement cooldown periods - Track scaling history and decisions</p> <p>Technology: Custom scaling algorithm with pluggable metrics</p> <p>Key Files: - <code>controller/scaler.py</code> - Auto-scaling logic and policies</p>"},{"location":"developer-guide/architecture/#4-health-checker","title":"4. Health Checker","text":"<p>Purpose: Monitors application health and availability</p> <p>Key Responsibilities: - Perform periodic health checks on containers - Support HTTP and TCP health checks - Track health status and failure counts - Trigger container replacement on failures - Update load balancer configuration</p> <p>Technology: Async HTTP client (aiohttp) and TCP sockets</p> <p>Key Files: - <code>controller/health.py</code> - Health checking logic</p> <p>Health Check Types: - HTTP: GET/POST requests to health endpoints - TCP: Socket connections to specified ports - Custom: Application-specific health logic</p>"},{"location":"developer-guide/architecture/#5-distributed-controller-leader-election","title":"5. Distributed Controller (Leader Election)","text":"<p>Purpose: Eliminates single point of failure through distributed controller architecture</p> <p>Key Responsibilities: - Coordinate leadership election among multiple controller nodes - Ensure only one active leader manages applications at a time - Handle automatic failover when leader becomes unavailable - Maintain cluster membership and health monitoring - Provide seamless leadership handoff</p> <p>Technology: PostgreSQL-based leader election with lease system</p> <p>Key Files: - <code>controller/cluster.py</code> - Distributed controller and leader election logic - <code>controller/api.py</code> - Leader-aware API decorators and routing</p> <p>Key Features: - 3-Node Cluster: Production-ready high availability setup - Automatic Failover: 15-30 second failover on leader failure - Split-Brain Prevention: Database-based coordination prevents conflicts - Load Balancer Integration: Nginx routes write operations to leader only - Health Monitoring: Continuous node health and lease management</p> <p>API Integration: <pre><code>@leader_required\nasync def register_app(app_spec: AppSpec):\n    # Only leader can execute write operations\n    return await app_manager.register_app(app_spec.dict())\n</code></pre></p> <p>See Leader Election Guide for detailed implementation.</p>"},{"location":"developer-guide/architecture/#6-nginx-manager","title":"6. Nginx Manager","text":"<p>Purpose: Manages dynamic load balancer configuration</p> <p>Key Responsibilities: - Generate Nginx upstream configurations - Update configurations when containers change - Reload Nginx without downtime - Handle SSL/TLS termination - Route traffic based on application specifications</p> <p>Technology: Nginx with dynamic configuration generation</p> <p>Key Files: - <code>controller/nginx.py</code> - Nginx configuration management - <code>configs/nginx/</code> - Nginx templates and configurations</p> <p>Configuration Generation: <pre><code>def generate_upstream_config(app_name, instances):\n    config = f\"\"\"\nupstream {app_name} {{\n    {upstream_method};\n    keepalive 32;\n\n\"\"\"\n    for instance in healthy_instances:\n        config += f\"    server {instance.ip}:{instance.port};\\n\"\n\n    config += \"}\\n\"\n    return config\n</code></pre></p>"},{"location":"developer-guide/architecture/#6-state-manager","title":"6. State Manager","text":"<p>Purpose: Provides persistent state storage and management</p> <p>Key Responsibilities: - Store application specifications and status - Track container instances and health - Maintain scaling policies and history - Provide event audit trail - Handle database connections and transactions</p> <p>Technology: PostgreSQL with connection pooling</p> <p>Key Files: - <code>state/db.py</code> - Database abstraction layer</p> <p>Data Models: - Applications: Specifications, status, scaling policies - Instances: Container details, health status, metrics - Events: System events, scaling decisions, errors - Metrics: Historical performance data</p>"},{"location":"developer-guide/architecture/#7-metrics-collector","title":"7. Metrics Collector","text":"<p>Purpose: Collects and aggregates application metrics</p> <p>Key Responsibilities: - Gather container resource metrics - Collect application-specific metrics - Calculate derived metrics (RPS, latency percentiles) - Store time-series data - Expose metrics for monitoring systems</p> <p>Technology: Docker stats API, Prometheus exposition</p> <p>Key Files: - <code>metrics/exporter.py</code> - Metrics collection and export</p>"},{"location":"developer-guide/architecture/#data-flow","title":"Data Flow","text":""},{"location":"developer-guide/architecture/#application-deployment-flow","title":"Application Deployment Flow","text":"<pre><code>1. User submits app spec \u2192 API Server\n2. API Server validates spec \u2192 App Manager\n3. App Manager stores spec \u2192 State Manager \u2192 Database\n4. App Manager creates containers \u2192 Docker Engine\n5. Health Checker starts monitoring \u2192 Containers\n6. Nginx Manager updates config \u2192 Load Balancer\n7. Auto Scaler starts monitoring \u2192 Metrics Collector\n</code></pre>"},{"location":"developer-guide/architecture/#scaling-decision-flow","title":"Scaling Decision Flow","text":"<pre><code>1. Metrics Collector gathers data \u2192 Containers\n2. Auto Scaler analyzes metrics \u2192 Scaling Policy\n3. Scaling decision made \u2192 App Manager\n4. App Manager adjusts containers \u2192 Docker Engine\n5. Health Checker updates status \u2192 Nginx Manager\n6. Nginx Manager reloads config \u2192 Load Balancer\n7. Event logged \u2192 State Manager \u2192 Database\n</code></pre>"},{"location":"developer-guide/architecture/#request-handling-flow","title":"Request Handling Flow","text":"<pre><code>1. External request \u2192 Nginx Load Balancer\n2. Nginx routes to healthy container \u2192 Application Container\n3. Container processes request \u2192 Response\n4. Metrics collected \u2192 Metrics Collector\n5. Health status updated \u2192 Health Checker\n</code></pre>"},{"location":"developer-guide/architecture/#database-schema","title":"Database Schema","text":""},{"location":"developer-guide/architecture/#core-tables","title":"Core Tables","text":"<pre><code>-- Applications table\nCREATE TABLE applications (\n    name VARCHAR(253) PRIMARY KEY,\n    spec JSONB NOT NULL,\n    status VARCHAR(50) NOT NULL,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    replicas INTEGER DEFAULT 0,\n    last_scaled_at TIMESTAMP WITH TIME ZONE,\n    mode VARCHAR(20) DEFAULT 'auto'\n);\n\n-- Container instances\nCREATE TABLE instances (\n    id SERIAL PRIMARY KEY,\n    app_name VARCHAR(253) NOT NULL REFERENCES applications(name),\n    container_id VARCHAR(128) UNIQUE NOT NULL,\n    ip INET NOT NULL,\n    port INTEGER NOT NULL,\n    status VARCHAR(50) NOT NULL,\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    failure_count INTEGER DEFAULT 0,\n    last_health_check TIMESTAMP WITH TIME ZONE\n);\n\n-- System events\nCREATE TABLE events (\n    id SERIAL PRIMARY KEY,\n    app_name VARCHAR(253) REFERENCES applications(name),\n    event_type VARCHAR(50) NOT NULL,\n    message TEXT NOT NULL,\n    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    details JSONB\n);\n\n-- Metrics (time-series data)\nCREATE TABLE metrics (\n    id SERIAL PRIMARY KEY,\n    app_name VARCHAR(253) NOT NULL REFERENCES applications(name),\n    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    cpu_percent REAL,\n    memory_percent REAL,\n    rps REAL,\n    latency_p95_ms REAL,\n    active_connections INTEGER,\n    replicas INTEGER\n);\n</code></pre>"},{"location":"developer-guide/architecture/#indexes-for-performance","title":"Indexes for Performance","text":"<pre><code>-- Query optimization indexes\nCREATE INDEX idx_instances_app_name ON instances(app_name);\nCREATE INDEX idx_instances_status ON instances(status);\nCREATE INDEX idx_events_app_name_timestamp ON events(app_name, timestamp DESC);\nCREATE INDEX idx_events_type_timestamp ON events(event_type, timestamp DESC);\nCREATE INDEX idx_metrics_app_timestamp ON metrics(app_name, timestamp DESC);\n</code></pre>"},{"location":"developer-guide/architecture/#configuration-architecture","title":"Configuration Architecture","text":""},{"location":"developer-guide/architecture/#hierarchical-configuration","title":"Hierarchical Configuration","text":"<p>Configuration is loaded in priority order:</p> <ol> <li>Default values (hardcoded)</li> <li>Configuration files (<code>config.yaml</code>)</li> <li>Environment variables (<code>.env</code>, system env)</li> <li>Runtime parameters (API calls)</li> </ol>"},{"location":"developer-guide/architecture/#configuration-sources","title":"Configuration Sources","text":"<pre><code>class ConfigManager:\n    def load_config(self):\n        config = {}\n\n        # 1. Load defaults\n        config.update(DEFAULT_CONFIG)\n\n        # 2. Load from files\n        if os.path.exists('config.yaml'):\n            config.update(load_yaml('config.yaml'))\n\n        # 3. Load from environment\n        config.update(load_env_config())\n\n        # 4. Validate and return\n        return validate_config(config)\n</code></pre>"},{"location":"developer-guide/architecture/#error-handling-strategy","title":"Error Handling Strategy","text":""},{"location":"developer-guide/architecture/#error-categories","title":"Error Categories","text":"<ol> <li>Validation Errors: Invalid input specifications</li> <li>Resource Errors: Insufficient system resources</li> <li>Infrastructure Errors: Docker daemon, database issues</li> <li>Application Errors: Container startup failures</li> <li>Network Errors: Load balancer configuration issues</li> </ol>"},{"location":"developer-guide/architecture/#error-recovery","title":"Error Recovery","text":"<pre><code>class ErrorHandler:\n    async def handle_container_failure(self, container_id, error):\n        # 1. Log the error\n        await self.log_event('container_failure', container_id, error)\n\n        # 2. Attempt recovery\n        if self.should_restart(error):\n            await self.restart_container(container_id)\n        else:\n            await self.replace_container(container_id)\n\n        # 3. Update load balancer\n        await self.update_nginx_config()\n</code></pre>"},{"location":"developer-guide/architecture/#security-architecture","title":"Security Architecture","text":""},{"location":"developer-guide/architecture/#network-security","title":"Network Security","text":"<ul> <li>Container Isolation: Dedicated Docker network</li> <li>Traffic Encryption: TLS termination at load balancer</li> <li>Internal Communication: Encrypted inter-service communication</li> <li>Firewall Rules: Restrict network access</li> </ul>"},{"location":"developer-guide/architecture/#access-control","title":"Access Control","text":"<ul> <li>API Authentication: JWT-based authentication (future)</li> <li>Role-Based Access: RBAC for different user types (future)</li> <li>Audit Logging: Complete audit trail of all operations</li> </ul>"},{"location":"developer-guide/architecture/#container-security","title":"Container Security","text":"<ul> <li>Image Scanning: Vulnerability scanning of container images</li> <li>Runtime Security: Container runtime protection</li> <li>Resource Limits: CPU and memory constraints</li> <li>Non-Root Execution: Containers run as non-root users</li> </ul>"},{"location":"developer-guide/architecture/#monitoring-architecture","title":"Monitoring Architecture","text":""},{"location":"developer-guide/architecture/#metrics-collection","title":"Metrics Collection","text":"<pre><code>class MetricsCollector:\n    async def collect_app_metrics(self, app_name):\n        instances = await self.get_app_instances(app_name)\n\n        metrics = {\n            'cpu_percent': await self.get_cpu_usage(instances),\n            'memory_percent': await self.get_memory_usage(instances),\n            'rps': await self.calculate_rps(app_name),\n            'latency_p95': await self.get_latency_percentile(app_name, 95),\n            'active_connections': await self.get_connection_count(instances)\n        }\n\n        await self.store_metrics(app_name, metrics)\n        return metrics\n</code></pre>"},{"location":"developer-guide/architecture/#observability-stack","title":"Observability Stack","text":"<ul> <li>Metrics: Prometheus + Grafana (future)</li> <li>Logs: Structured JSON logging</li> <li>Tracing: OpenTelemetry integration (future)</li> <li>Alerting: AlertManager integration (future)</li> </ul>"},{"location":"developer-guide/architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"developer-guide/architecture/#database-performance","title":"Database Performance","text":"<ul> <li>Connection Pooling: Efficient database connection management</li> <li>Query Optimization: Indexed queries and efficient joins</li> <li>Read Replicas: Separate read/write workloads</li> <li>Archival Strategy: Historical data management</li> </ul>"},{"location":"developer-guide/architecture/#scaling-performance","title":"Scaling Performance","text":"<ul> <li>Concurrent Operations: Parallel scaling operations</li> <li>Batch Processing: Bulk container operations</li> <li>Caching: Metrics and configuration caching</li> <li>Async Processing: Non-blocking operations</li> </ul>"},{"location":"developer-guide/architecture/#memory-management","title":"Memory Management","text":"<ul> <li>Connection Pools: Bounded connection pools</li> <li>Metrics Retention: Time-based data cleanup</li> <li>Container Limits: Per-container resource limits</li> <li>Garbage Collection: Periodic cleanup tasks</li> </ul> <p>Next Steps: Explore Core Components for detailed implementation details.</p>"},{"location":"developer-guide/components/","title":"Core Components","text":"<p>Detailed documentation of Orchestry's core components, their implementation, and interactions.</p>"},{"location":"developer-guide/components/#application-manager","title":"Application Manager","text":"<p>The Application Manager is the heart of Orchestry, responsible for managing the complete lifecycle of containerized applications.</p>"},{"location":"developer-guide/components/#class-structure","title":"Class Structure","text":"<pre><code>class AppManager:\n    def __init__(self, state_store=None, nginx_manager=None):\n        self.client = docker.from_env()\n        self.state_store = state_store or get_database_manager()\n        self.nginx = nginx_manager or DockerNginxManager()\n        self.health_checker = HealthChecker()\n        self.instances = {}  # app_name -&gt; list of ContainerInstance\n        self._lock = threading.RLock()\n        self._ensure_network()\n</code></pre>"},{"location":"developer-guide/components/#core-methods","title":"Core Methods","text":""},{"location":"developer-guide/components/#application-registration","title":"Application Registration","text":"<pre><code>async def register_app(self, app_spec: dict) -&gt; str:\n    \"\"\"Register a new application from specification.\"\"\"\n    # 1. Validate specification\n    validated_spec = self._validate_spec(app_spec)\n\n    # 2. Check for conflicts\n    if await self.state_store.app_exists(app_spec['metadata']['name']):\n        raise AppAlreadyExistsError()\n\n    # 3. Store in database\n    app_record = AppRecord(\n        name=app_spec['metadata']['name'],\n        spec=validated_spec,\n        status='registered',\n        created_at=time.time(),\n        updated_at=time.time()\n    )\n    await self.state_store.store_app(app_record)\n\n    # 4. Log event\n    await self.state_store.log_event(\n        app_name=app_record.name,\n        event_type='registration',\n        message=f\"Application {app_record.name} registered successfully\"\n    )\n\n    return app_record.name\n</code></pre>"},{"location":"developer-guide/components/#container-management","title":"Container Management","text":"<pre><code>def _create_container(self, app_name: str, spec: dict, replica_index: int) -&gt; str:\n    \"\"\"Create a single container instance.\"\"\"\n    container_config = {\n        'image': spec['spec']['image'],\n        'name': f\"{app_name}-{replica_index}\",\n        'labels': {\n            'orchestry.app': app_name,\n            'orchestry.replica': str(replica_index),\n            'orchestry.managed': 'true'\n        },\n        'network': 'orchestry',\n        'detach': True,\n        'restart_policy': {'Name': 'unless-stopped'}\n    }\n\n    # Add environment variables\n    if 'environment' in spec['spec']:\n        container_config['environment'] = self._build_environment(\n            spec['spec']['environment'], app_name, replica_index\n        )\n\n    # Add resource limits\n    if 'resources' in spec['spec']:\n        container_config['mem_limit'] = spec['spec']['resources'].get('memory', '512m')\n        container_config['cpu_quota'] = self._parse_cpu_limit(\n            spec['spec']['resources'].get('cpu', '500m')\n        )\n\n    # Add port configuration\n    if 'ports' in spec['spec']:\n        container_config['ports'] = self._configure_ports(spec['spec']['ports'])\n\n    # Create container\n    container = self.client.containers.run(**container_config)\n\n    # Wait for network assignment\n    self._wait_for_network(container)\n\n    return container.id\n</code></pre>"},{"location":"developer-guide/components/#scaling-operations","title":"Scaling Operations","text":"<pre><code>async def scale_app(self, app_name: str, target_replicas: int) -&gt; dict:\n    \"\"\"Scale application to target replica count.\"\"\"\n    async with self._lock:\n        app_record = await self.state_store.get_app(app_name)\n        if not app_record:\n            raise AppNotFoundError(app_name)\n\n        current_replicas = len(self.instances.get(app_name, []))\n\n        if target_replicas &gt; current_replicas:\n            # Scale out\n            await self._scale_out(app_name, target_replicas - current_replicas)\n        elif target_replicas &lt; current_replicas:\n            # Scale in\n            await self._scale_in(app_name, current_replicas - target_replicas)\n\n        # Update database\n        app_record.replicas = target_replicas\n        app_record.last_scaled_at = time.time()\n        await self.state_store.update_app(app_record)\n\n        # Update nginx configuration\n        await self.nginx.update_upstream(app_name, self.instances[app_name])\n\n        return {\n            'app_name': app_name,\n            'previous_replicas': current_replicas,\n            'current_replicas': target_replicas,\n            'scaling_time': time.time() - start_time\n        }\n</code></pre>"},{"location":"developer-guide/components/#container-instance-management","title":"Container Instance Management","text":"<pre><code>@dataclass\nclass ContainerInstance:\n    container_id: str\n    ip: str\n    port: int\n    state: str  # ready, draining, down\n    cpu_percent: float = 0.0\n    memory_percent: float = 0.0\n    last_seen: float = 0.0\n    failures: int = 0\n\n    def is_healthy(self) -&gt; bool:\n        return self.state == 'ready' and self.failures &lt; 3\n\n    def update_metrics(self, stats: dict):\n        self.cpu_percent = self._calculate_cpu_percent(stats)\n        self.memory_percent = self._calculate_memory_percent(stats)\n        self.last_seen = time.time()\n</code></pre>"},{"location":"developer-guide/components/#health-integration","title":"Health Integration","text":"<pre><code>def _on_health_status_change(self, container_id: str, is_healthy: bool):\n    \"\"\"Callback for health status changes.\"\"\"\n    for app_name, instances in self.instances.items():\n        for instance in instances:\n            if instance.container_id == container_id:\n                if is_healthy:\n                    instance.state = 'ready'\n                    instance.failures = 0\n                else:\n                    instance.failures += 1\n                    if instance.failures &gt;= 3:\n                        instance.state = 'down'\n                        # Schedule container replacement\n                        self._schedule_replacement(app_name, container_id)\n\n                # Update nginx configuration\n                self._update_nginx_config(app_name)\n                break\n</code></pre>"},{"location":"developer-guide/components/#auto-scaler","title":"Auto Scaler","text":"<p>The Auto Scaler makes intelligent scaling decisions based on multiple metrics and configurable policies.</p>"},{"location":"developer-guide/components/#scaling-policy-engine","title":"Scaling Policy Engine","text":"<pre><code>@dataclass\nclass ScalingPolicy:\n    min_replicas: int = 1\n    max_replicas: int = 5\n    target_rps_per_replica: int = 50\n    max_p95_latency_ms: int = 250\n    max_conn_per_replica: int = 80\n    scale_out_threshold_pct: int = 80\n    scale_in_threshold_pct: int = 30\n    window_seconds: int = 20\n    cooldown_seconds: int = 30\n    max_cpu_percent: float = 70.0\n    max_memory_percent: float = 75.0\n</code></pre>"},{"location":"developer-guide/components/#decision-algorithm","title":"Decision Algorithm","text":"<pre><code>def evaluate_scaling(self, app_name: str, metrics: ScalingMetrics) -&gt; ScalingDecision:\n    \"\"\"Evaluate if scaling is needed based on current metrics.\"\"\"\n    policy = self.policies.get(app_name)\n    if not policy:\n        return ScalingDecision(should_scale=False, reason=\"No policy configured\")\n\n    # Check cooldown period\n    if self._in_cooldown(app_name, policy.cooldown_seconds):\n        return ScalingDecision(should_scale=False, reason=\"In cooldown period\")\n\n    # Calculate scale factors for each metric\n    scale_factors = self._calculate_scale_factors(metrics, policy)\n\n    # Determine scaling direction\n    max_factor = max(scale_factors.values())\n    min_factor = min(scale_factors.values())\n\n    current_replicas = metrics.healthy_replicas\n\n    # Scale out decision\n    if max_factor &gt; policy.scale_out_threshold_pct / 100:\n        target_replicas = self._calculate_scale_out_target(\n            current_replicas, scale_factors, policy\n        )\n        return ScalingDecision(\n            should_scale=True,\n            target_replicas=min(target_replicas, policy.max_replicas),\n            current_replicas=current_replicas,\n            reason=f\"Scale out: {self._get_dominant_metric(scale_factors)} exceeds threshold\",\n            triggered_by=self._get_triggered_metrics(scale_factors, policy.scale_out_threshold_pct / 100),\n            metrics=metrics\n        )\n\n    # Scale in decision\n    elif (max_factor &lt; policy.scale_in_threshold_pct / 100 and \n          current_replicas &gt; policy.min_replicas):\n        target_replicas = self._calculate_scale_in_target(\n            current_replicas, scale_factors, policy\n        )\n        return ScalingDecision(\n            should_scale=True,\n            target_replicas=max(target_replicas, policy.min_replicas),\n            current_replicas=current_replicas,\n            reason=f\"Scale in: All metrics below threshold\",\n            triggered_by=['all_metrics_low'],\n            metrics=metrics\n        )\n\n    return ScalingDecision(\n        should_scale=False,\n        target_replicas=current_replicas,\n        current_replicas=current_replicas,\n        reason=\"Metrics within acceptable range\"\n    )\n</code></pre>"},{"location":"developer-guide/components/#metrics-calculation","title":"Metrics Calculation","text":"<pre><code>def _calculate_scale_factors(self, metrics: ScalingMetrics, policy: ScalingPolicy) -&gt; dict:\n    \"\"\"Calculate how much each metric contributes to scaling pressure.\"\"\"\n    factors = {}\n\n    # CPU utilization factor\n    if policy.max_cpu_percent &gt; 0:\n        factors['cpu'] = metrics.cpu_percent / policy.max_cpu_percent\n\n    # Memory utilization factor\n    if policy.max_memory_percent &gt; 0:\n        factors['memory'] = metrics.memory_percent / policy.max_memory_percent\n\n    # RPS factor (requests per replica)\n    if policy.target_rps_per_replica &gt; 0 and metrics.healthy_replicas &gt; 0:\n        current_rps_per_replica = metrics.rps / metrics.healthy_replicas\n        factors['rps'] = current_rps_per_replica / policy.target_rps_per_replica\n\n    # Latency factor\n    if policy.max_p95_latency_ms &gt; 0:\n        factors['latency'] = metrics.p95_latency_ms / policy.max_p95_latency_ms\n\n    # Connection factor\n    if policy.max_conn_per_replica &gt; 0 and metrics.healthy_replicas &gt; 0:\n        current_conn_per_replica = metrics.active_connections / metrics.healthy_replicas\n        factors['connections'] = current_conn_per_replica / policy.max_conn_per_replica\n\n    # Store for debugging\n    self.last_scale_factors[app_name] = factors\n\n    return factors\n</code></pre>"},{"location":"developer-guide/components/#scaling-target-calculation","title":"Scaling Target Calculation","text":"<pre><code>def _calculate_scale_out_target(self, current: int, factors: dict, policy: ScalingPolicy) -&gt; int:\n    \"\"\"Calculate target replicas for scale out.\"\"\"\n    # Use the highest factor to determine scale out amount\n    max_factor = max(factors.values())\n\n    # Conservative scaling: increase by 1-3 replicas based on pressure\n    if max_factor &gt; 1.5:  # Very high pressure\n        return current + min(3, policy.max_replicas - current)\n    elif max_factor &gt; 1.2:  # High pressure\n        return current + min(2, policy.max_replicas - current)\n    else:  # Moderate pressure\n        return current + 1\n\ndef _calculate_scale_in_target(self, current: int, factors: dict, policy: ScalingPolicy) -&gt; int:\n    \"\"\"Calculate target replicas for scale in.\"\"\"\n    # Conservative scaling: decrease by 1 replica at a time\n    return max(current - 1, policy.min_replicas)\n</code></pre>"},{"location":"developer-guide/components/#health-checker","title":"Health Checker","text":"<p>The Health Checker monitors application health and triggers recovery actions.</p>"},{"location":"developer-guide/components/#health-check-implementation","title":"Health Check Implementation","text":"<pre><code>class HealthChecker:\n    def __init__(self):\n        self.health_status = {}  # container_id -&gt; HealthStatus\n        self.check_tasks = {}    # container_id -&gt; asyncio.Task\n        self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10))\n        self._health_change_callback = None\n\n    async def start_monitoring(self, container_id: str, config: HealthCheckConfig):\n        \"\"\"Start health monitoring for a container.\"\"\"\n        if container_id in self.check_tasks:\n            self.check_tasks[container_id].cancel()\n\n        self.health_status[container_id] = HealthStatus(\n            container_id=container_id,\n            status='unknown',\n            consecutive_failures=0,\n            last_check=None\n        )\n\n        # Start health check task\n        self.check_tasks[container_id] = asyncio.create_task(\n            self._health_check_loop(container_id, config)\n        )\n</code></pre>"},{"location":"developer-guide/components/#health-check-types","title":"Health Check Types","text":"<pre><code>async def _perform_health_check(self, container_id: str, config: HealthCheckConfig) -&gt; bool:\n    \"\"\"Perform a single health check.\"\"\"\n    try:\n        if config.protocol == 'HTTP':\n            return await self._http_health_check(container_id, config)\n        elif config.protocol == 'TCP':\n            return await self._tcp_health_check(container_id, config)\n        else:\n            raise ValueError(f\"Unsupported protocol: {config.protocol}\")\n    except Exception as e:\n        logger.warning(f\"Health check failed for {container_id}: {e}\")\n        return False\n\nasync def _http_health_check(self, container_id: str, config: HealthCheckConfig) -&gt; bool:\n    \"\"\"Perform HTTP health check.\"\"\"\n    container = self._get_container(container_id)\n    if not container:\n        return False\n\n    # Get container IP\n    ip = self._get_container_ip(container)\n    url = f\"http://{ip}:{config.port}{config.path}\"\n\n    # Prepare headers\n    headers = {}\n    if hasattr(config, 'headers') and config.headers:\n        for header in config.headers:\n            headers[header.name] = header.value\n\n    # Make request\n    async with self.session.get(url, headers=headers) as response:\n        # Check status code\n        if hasattr(config, 'expected_status_codes'):\n            return response.status in config.expected_status_codes\n        else:\n            return 200 &lt;= response.status &lt; 300\n\nasync def _tcp_health_check(self, container_id: str, config: HealthCheckConfig) -&gt; bool:\n    \"\"\"Perform TCP health check.\"\"\"\n    container = self._get_container(container_id)\n    if not container:\n        return False\n\n    ip = self._get_container_ip(container)\n\n    try:\n        reader, writer = await asyncio.wait_for(\n            asyncio.open_connection(ip, config.port),\n            timeout=config.timeout_seconds\n        )\n        writer.close()\n        await writer.wait_closed()\n        return True\n    except (asyncio.TimeoutError, ConnectionRefusedError, OSError):\n        return False\n</code></pre>"},{"location":"developer-guide/components/#health-status-management","title":"Health Status Management","text":"<pre><code>@dataclass\nclass HealthStatus:\n    container_id: str\n    status: str  # 'healthy', 'unhealthy', 'unknown'\n    consecutive_failures: int\n    consecutive_successes: int\n    last_check: Optional[float]\n    last_success: Optional[float]\n    last_failure: Optional[float]\n    total_checks: int = 0\n    total_failures: int = 0\n\nasync def _update_health_status(self, container_id: str, is_healthy: bool, config: HealthCheckConfig):\n    \"\"\"Update health status based on check result.\"\"\"\n    status = self.health_status[container_id]\n    status.total_checks += 1\n    status.last_check = time.time()\n\n    if is_healthy:\n        status.consecutive_failures = 0\n        status.consecutive_successes += 1\n        status.last_success = time.time()\n\n        # Mark as healthy if enough successes\n        if (status.status != 'healthy' and \n            status.consecutive_successes &gt;= config.success_threshold):\n            await self._set_health_status(container_id, 'healthy')\n    else:\n        status.consecutive_successes = 0\n        status.consecutive_failures += 1\n        status.total_failures += 1\n        status.last_failure = time.time()\n\n        # Mark as unhealthy if enough failures\n        if (status.status != 'unhealthy' and \n            status.consecutive_failures &gt;= config.failure_threshold):\n            await self._set_health_status(container_id, 'unhealthy')\n</code></pre>"},{"location":"developer-guide/components/#nginx-manager","title":"Nginx Manager","text":"<p>The Nginx Manager handles dynamic load balancer configuration.</p>"},{"location":"developer-guide/components/#configuration-generation","title":"Configuration Generation","text":"<pre><code>class DockerNginxManager:\n    def __init__(self, config_path='/etc/nginx/conf.d'):\n        self.config_path = Path(config_path)\n        self.template_path = Path('/etc/nginx/templates')\n        self.active_configs = set()\n\n    async def update_upstream(self, app_name: str, instances: List[ContainerInstance]):\n        \"\"\"Update upstream configuration for an application.\"\"\"\n        # Filter healthy instances\n        healthy_instances = [i for i in instances if i.is_healthy()]\n\n        if not healthy_instances:\n            # Remove configuration if no healthy instances\n            await self._remove_upstream(app_name)\n            return\n\n        # Generate upstream configuration\n        config_content = self._generate_upstream_config(app_name, healthy_instances)\n\n        # Write configuration file\n        config_file = self.config_path / f\"{app_name}.conf\"\n        await self._write_config_file(config_file, config_content)\n\n        # Test configuration\n        if await self._test_nginx_config():\n            # Reload nginx\n            await self._reload_nginx()\n            self.active_configs.add(app_name)\n        else:\n            # Remove bad configuration\n            config_file.unlink(missing_ok=True)\n            raise NginxConfigurationError(f\"Invalid configuration for {app_name}\")\n</code></pre>"},{"location":"developer-guide/components/#template-system","title":"Template System","text":"<pre><code>def _generate_upstream_config(self, app_name: str, instances: List[ContainerInstance]) -&gt; str:\n    \"\"\"Generate nginx upstream configuration.\"\"\"\n    # Load template\n    template_file = self.template_path / 'upstream.conf.j2'\n    if template_file.exists():\n        template = Template(template_file.read_text())\n        return template.render(\n            app_name=app_name,\n            instances=instances,\n            upstream_method='least_conn',\n            keepalive=32\n        )\n\n    # Fallback to built-in template\n    config = f\"\"\"\n# Generated configuration for {app_name}\nupstream {app_name} {{\n    least_conn;\n    keepalive 32;\n\n\"\"\"\n\n    for instance in instances:\n        config += f\"    server {instance.ip}:{instance.port}\"\n        if instance.state == 'draining':\n            config += \" down\"\n        config += \";\\n\"\n\n    config += \"}\\n\\n\"\n\n    # Add location block\n    config += f\"\"\"\nlocation /{app_name} {{\n    proxy_pass http://{app_name};\n    proxy_http_version 1.1;\n    proxy_set_header Connection \"\";\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n\n    # Health check\n    proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;\n    proxy_connect_timeout 5s;\n    proxy_send_timeout 60s;\n    proxy_read_timeout 60s;\n}}\n\"\"\"\n\n    return config\n</code></pre>"},{"location":"developer-guide/components/#configuration-management","title":"Configuration Management","text":"<pre><code>async def _test_nginx_config(self) -&gt; bool:\n    \"\"\"Test nginx configuration validity.\"\"\"\n    try:\n        result = await asyncio.create_subprocess_exec(\n            'nginx', '-t',\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE\n        )\n        stdout, stderr = await result.communicate()\n        return result.returncode == 0\n    except Exception as e:\n        logger.error(f\"Failed to test nginx configuration: {e}\")\n        return False\n\nasync def _reload_nginx(self):\n    \"\"\"Reload nginx configuration.\"\"\"\n    try:\n        result = await asyncio.create_subprocess_exec(\n            'nginx', '-s', 'reload',\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE\n        )\n        await result.communicate()\n        if result.returncode != 0:\n            raise NginxReloadError(\"Failed to reload nginx\")\n    except Exception as e:\n        logger.error(f\"Failed to reload nginx: {e}\")\n        raise NginxReloadError(str(e))\n</code></pre>"},{"location":"developer-guide/components/#state-manager","title":"State Manager","text":"<p>The State Manager provides database abstraction and state persistence.</p>"},{"location":"developer-guide/components/#database-connection-management","title":"Database Connection Management","text":"<pre><code>class DatabaseManager:\n    def __init__(self, config: dict):\n        self.config = config\n        self.pool = None\n        self._lock = asyncio.Lock()\n\n    async def initialize(self):\n        \"\"\"Initialize database connection pool.\"\"\"\n        self.pool = await asyncpg.create_pool(\n            host=self.config['host'],\n            port=self.config['port'],\n            user=self.config['user'],\n            password=self.config['password'],\n            database=self.config['database'],\n            min_size=5,\n            max_size=self.config.get('pool_size', 10),\n            command_timeout=30\n        )\n\n        # Create tables if they don't exist\n        await self._create_tables()\n\n    @contextmanager\n    async def get_connection(self):\n        \"\"\"Get database connection from pool.\"\"\"\n        async with self.pool.acquire() as connection:\n            yield connection\n</code></pre>"},{"location":"developer-guide/components/#application-data-management","title":"Application Data Management","text":"<pre><code>async def store_app(self, app_record: AppRecord):\n    \"\"\"Store application record in database.\"\"\"\n    async with self.get_connection() as conn:\n        await conn.execute(\n            \"\"\"\n            INSERT INTO applications (name, spec, status, created_at, updated_at, replicas, mode)\n            VALUES ($1, $2, $3, $4, $5, $6, $7)\n            \"\"\",\n            app_record.name,\n            json.dumps(app_record.spec),\n            app_record.status,\n            datetime.fromtimestamp(app_record.created_at),\n            datetime.fromtimestamp(app_record.updated_at),\n            app_record.replicas,\n            app_record.mode\n        )\n\nasync def get_app(self, app_name: str) -&gt; Optional[AppRecord]:\n    \"\"\"Retrieve application record from database.\"\"\"\n    async with self.get_connection() as conn:\n        row = await conn.fetchrow(\n            \"SELECT * FROM applications WHERE name = $1\",\n            app_name\n        )\n\n        if not row:\n            return None\n\n        return AppRecord(\n            name=row['name'],\n            spec=json.loads(row['spec']),\n            status=row['status'],\n            created_at=row['created_at'].timestamp(),\n            updated_at=row['updated_at'].timestamp(),\n            replicas=row['replicas'],\n            last_scaled_at=row['last_scaled_at'].timestamp() if row['last_scaled_at'] else None,\n            mode=row['mode']\n        )\n</code></pre>"},{"location":"developer-guide/components/#event-logging","title":"Event Logging","text":"<pre><code>async def log_event(self, app_name: str, event_type: str, message: str, details: dict = None):\n    \"\"\"Log system event.\"\"\"\n    async with self.get_connection() as conn:\n        await conn.execute(\n            \"\"\"\n            INSERT INTO events (app_name, event_type, message, details)\n            VALUES ($1, $2, $3, $4)\n            \"\"\",\n            app_name,\n            event_type,\n            message,\n            json.dumps(details) if details else None\n        )\n\nasync def get_events(self, app_name: str = None, event_type: str = None, \n                    since: float = None, limit: int = 100) -&gt; List[EventRecord]:\n    \"\"\"Retrieve system events with filtering.\"\"\"\n    conditions = []\n    params = []\n    param_count = 0\n\n    if app_name:\n        param_count += 1\n        conditions.append(f\"app_name = ${param_count}\")\n        params.append(app_name)\n\n    if event_type:\n        param_count += 1\n        conditions.append(f\"event_type = ${param_count}\")\n        params.append(event_type)\n\n    if since:\n        param_count += 1\n        conditions.append(f\"timestamp &gt;= ${param_count}\")\n        params.append(datetime.fromtimestamp(since))\n\n    where_clause = \" AND \".join(conditions) if conditions else \"TRUE\"\n\n    param_count += 1\n    params.append(limit)\n\n    async with self.get_connection() as conn:\n        rows = await conn.fetch(\n            f\"\"\"\n            SELECT * FROM events \n            WHERE {where_clause}\n            ORDER BY timestamp DESC \n            LIMIT ${param_count}\n            \"\"\",\n            *params\n        )\n\n        return [\n            EventRecord(\n                id=row['id'],\n                app_name=row['app_name'],\n                event_type=row['event_type'],\n                message=row['message'],\n                timestamp=row['timestamp'].timestamp(),\n                details=json.loads(row['details']) if row['details'] else None\n            )\n            for row in rows\n        ]\n</code></pre>"},{"location":"developer-guide/components/#component-interactions","title":"Component Interactions","text":""},{"location":"developer-guide/components/#startup-sequence","title":"Startup Sequence","text":"<pre><code>class OrchestryController:\n    async def start(self):\n        \"\"\"Start all components in correct order.\"\"\"\n        # 1. Initialize database\n        await self.state_manager.initialize()\n\n        # 2. Start application manager\n        await self.app_manager.initialize()\n\n        # 3. Start health checker\n        await self.health_checker.start()\n\n        # 4. Start auto scaler\n        await self.auto_scaler.start()\n\n        # 5. Start nginx manager\n        await self.nginx_manager.initialize()\n\n        # 6. Start API server\n        await self.api_server.start()\n\n        # 7. Start background tasks\n        await self._start_background_tasks()\n</code></pre>"},{"location":"developer-guide/components/#event-flow","title":"Event Flow","text":"<pre><code>async def _handle_container_health_change(self, container_id: str, is_healthy: bool):\n    \"\"\"Handle container health status change.\"\"\"\n    # 1. Update application manager\n    await self.app_manager.update_container_health(container_id, is_healthy)\n\n    # 2. Update nginx configuration if needed\n    app_name = await self.app_manager.get_app_for_container(container_id)\n    if app_name:\n        instances = self.app_manager.get_app_instances(app_name)\n        await self.nginx_manager.update_upstream(app_name, instances)\n\n    # 3. Log event\n    await self.state_manager.log_event(\n        app_name=app_name,\n        event_type='health',\n        message=f\"Container {container_id[:12]} marked as {'healthy' if is_healthy else 'unhealthy'}\",\n        details={'container_id': container_id, 'healthy': is_healthy}\n    )\n</code></pre> <p>Next Steps: Learn about the Database Schema and data persistence layer.</p>"},{"location":"developer-guide/database/","title":"Database Schema","text":"<p>Complete documentation of Orchestry's database schema, data models, and persistence layer.</p>"},{"location":"developer-guide/database/#overview","title":"Overview","text":"<p>Orchestry uses PostgreSQL as its primary datastore with an optional read replica for scalability. The database schema is designed for:</p> <ul> <li>High Performance: Optimized queries with proper indexing</li> <li>Scalability: Support for large numbers of applications and metrics</li> <li>Consistency: ACID transactions for critical operations</li> <li>Auditability: Complete event trail for all operations</li> <li>Extensibility: Schema designed for future enhancements</li> </ul>"},{"location":"developer-guide/database/#database-architecture","title":"Database Architecture","text":""},{"location":"developer-guide/database/#primary-replica-setup","title":"Primary-Replica Setup","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Primary Database     \u2502    \u2502    Replica Database     \u2502\n\u2502                         \u2502    \u2502                         \u2502\n\u2502  \u2022 Read/Write           \u2502\u25c4\u2500\u2500\u25ba\u2502  \u2022 Read Only            \u2502\n\u2502  \u2022 Real-time data       \u2502    \u2502  \u2022 Analytics queries    \u2502\n\u2502  \u2022 Critical operations  \u2502    \u2502  \u2022 Reporting            \u2502\n\u2502  \u2022 Schema changes       \u2502    \u2502  \u2022 Backup source        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/database/#connection-management","title":"Connection Management","text":"<pre><code>class DatabaseManager:\n    \"\"\"Database connection and query management.\"\"\"\n\n    def __init__(self, config):\n        self.primary_pool = None    # Read/write operations\n        self.replica_pool = None    # Read-only operations\n        self.config = config\n\n    async def get_write_connection(self):\n        \"\"\"Get connection for write operations.\"\"\"\n        return await self.primary_pool.acquire()\n\n    async def get_read_connection(self):\n        \"\"\"Get connection for read operations.\"\"\"\n        if self.replica_pool and self.config.get('prefer_replica'):\n            return await self.replica_pool.acquire()\n        return await self.primary_pool.acquire()\n</code></pre>"},{"location":"developer-guide/database/#core-tables","title":"Core Tables","text":""},{"location":"developer-guide/database/#applications-table","title":"Applications Table","text":"<p>Stores application specifications and metadata.</p> <pre><code>CREATE TABLE applications (\n    -- Primary identification\n    name VARCHAR(253) PRIMARY KEY,              -- DNS-compatible app name\n\n    -- Application specification\n    spec JSONB NOT NULL,                        -- Complete app specification\n    status VARCHAR(50) NOT NULL DEFAULT 'registered', -- Current status\n\n    -- Timestamps\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n\n    -- Scaling information\n    replicas INTEGER DEFAULT 0,                 -- Current replica count\n    desired_replicas INTEGER DEFAULT 0,         -- Desired replica count\n    last_scaled_at TIMESTAMP WITH TIME ZONE,    -- Last scaling operation\n\n    -- Configuration\n    mode VARCHAR(20) DEFAULT 'auto',            -- Scaling mode (auto/manual)\n\n    -- Constraints\n    CONSTRAINT valid_status CHECK (status IN (\n        'registered', 'starting', 'running', 'stopping', 'stopped', 'error', 'updating'\n    )),\n    CONSTRAINT valid_mode CHECK (mode IN ('auto', 'manual')),\n    CONSTRAINT valid_replicas CHECK (replicas &gt;= 0),\n    CONSTRAINT valid_desired_replicas CHECK (desired_replicas &gt;= 0)\n);\n\n-- Indexes for performance\nCREATE INDEX idx_applications_status ON applications(status);\nCREATE INDEX idx_applications_mode ON applications(mode);\nCREATE INDEX idx_applications_updated_at ON applications(updated_at DESC);\nCREATE INDEX idx_applications_spec_image ON applications USING GIN ((spec-&gt;'spec'-&gt;&gt;'image'));\n</code></pre> <p>Application Status Values:</p> Status Description <code>registered</code> Application spec stored, not yet started <code>starting</code> Containers being created <code>running</code> Application running normally <code>stopping</code> Graceful shutdown in progress <code>stopped</code> Application stopped <code>error</code> Error state, manual intervention needed <code>updating</code> Configuration or image update in progress"},{"location":"developer-guide/database/#instances-table","title":"Instances Table","text":"<p>Tracks individual container instances for each application.</p> <pre><code>CREATE TABLE instances (\n    -- Primary key\n    id SERIAL PRIMARY KEY,\n\n    -- Application relationship\n    app_name VARCHAR(253) NOT NULL REFERENCES applications(name) ON DELETE CASCADE,\n\n    -- Container identification\n    container_id VARCHAR(128) UNIQUE NOT NULL,  -- Docker container ID\n    container_name VARCHAR(253) NOT NULL,       -- Human-readable container name\n    replica_index INTEGER NOT NULL,             -- Replica number (0, 1, 2, ...)\n\n    -- Network configuration\n    ip INET NOT NULL,                           -- Container IP address\n    port INTEGER NOT NULL,                      -- Primary application port\n\n    -- Status information\n    status VARCHAR(50) NOT NULL DEFAULT 'starting',\n    health_status VARCHAR(20) DEFAULT 'unknown', -- Health check status\n\n    -- Timestamps\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    started_at TIMESTAMP WITH TIME ZONE,        -- When container started\n    last_health_check TIMESTAMP WITH TIME ZONE,\n\n    -- Failure tracking\n    failure_count INTEGER DEFAULT 0,\n    consecutive_failures INTEGER DEFAULT 0,\n    last_failure_at TIMESTAMP WITH TIME ZONE,\n\n    -- Resource usage (latest values)\n    cpu_percent REAL DEFAULT 0,\n    memory_percent REAL DEFAULT 0,\n    memory_usage_bytes BIGINT DEFAULT 0,\n\n    -- Constraints\n    CONSTRAINT valid_status CHECK (status IN (\n        'starting', 'running', 'stopping', 'stopped', 'error', 'draining'\n    )),\n    CONSTRAINT valid_health_status CHECK (health_status IN (\n        'unknown', 'healthy', 'unhealthy', 'starting'\n    )),\n    CONSTRAINT valid_replica_index CHECK (replica_index &gt;= 0),\n    CONSTRAINT valid_port CHECK (port &gt; 0 AND port &lt;= 65535),\n    CONSTRAINT valid_failure_count CHECK (failure_count &gt;= 0),\n    CONSTRAINT valid_cpu_percent CHECK (cpu_percent &gt;= 0),\n    CONSTRAINT valid_memory_percent CHECK (memory_percent &gt;= 0 AND memory_percent &lt;= 100),\n\n    -- Unique constraint for app + replica\n    UNIQUE(app_name, replica_index)\n);\n\n-- Indexes for performance\nCREATE INDEX idx_instances_app_name ON instances(app_name);\nCREATE INDEX idx_instances_status ON instances(status);\nCREATE INDEX idx_instances_health_status ON instances(health_status);\nCREATE INDEX idx_instances_container_id ON instances(container_id);\nCREATE INDEX idx_instances_updated_at ON instances(updated_at DESC);\nCREATE INDEX idx_instances_app_status ON instances(app_name, status);\nCREATE INDEX idx_instances_health_check ON instances(last_health_check DESC);\n</code></pre> <p>Instance Status Values:</p> Status Description <code>starting</code> Container is being created/started <code>running</code> Container is running normally <code>stopping</code> Container is being gracefully stopped <code>stopped</code> Container has stopped <code>error</code> Container in error state <code>draining</code> Container marked for removal, not receiving new traffic"},{"location":"developer-guide/database/#events-table","title":"Events Table","text":"<p>Comprehensive audit trail of all system events.</p> <pre><code>CREATE TABLE events (\n    -- Primary key\n    id SERIAL PRIMARY KEY,\n\n    -- Event identification\n    event_type VARCHAR(50) NOT NULL,            -- Type of event\n    event_category VARCHAR(30) NOT NULL DEFAULT 'application', -- Event category\n\n    -- Associated resources\n    app_name VARCHAR(253) REFERENCES applications(name) ON DELETE SET NULL,\n    container_id VARCHAR(128),                  -- Optional container reference\n\n    -- Event details\n    message TEXT NOT NULL,                      -- Human-readable message\n    details JSONB,                              -- Structured event data\n    severity VARCHAR(20) DEFAULT 'info',       -- Event severity level\n\n    -- Timestamps\n    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n\n    -- Source information\n    source VARCHAR(50) DEFAULT 'controller',    -- Component that generated event\n    node_id VARCHAR(100),                       -- Cluster node ID (if applicable)\n\n    -- Constraints\n    CONSTRAINT valid_event_type CHECK (event_type IN (\n        'registration', 'scaling', 'health', 'config', 'deployment', \n        'error', 'warning', 'network', 'resource', 'security'\n    )),\n    CONSTRAINT valid_event_category CHECK (event_category IN (\n        'application', 'system', 'cluster', 'security', 'performance'\n    )),\n    CONSTRAINT valid_severity CHECK (severity IN (\n        'debug', 'info', 'warning', 'error', 'critical'\n    ))\n);\n\n-- Indexes for efficient querying\nCREATE INDEX idx_events_app_name_timestamp ON events(app_name, timestamp DESC);\nCREATE INDEX idx_events_type_timestamp ON events(event_type, timestamp DESC);\nCREATE INDEX idx_events_timestamp ON events(timestamp DESC);\nCREATE INDEX idx_events_severity ON events(severity, timestamp DESC);\nCREATE INDEX idx_events_category ON events(event_category, timestamp DESC);\nCREATE INDEX idx_events_container ON events(container_id, timestamp DESC);\n\n-- Partial index for recent events (performance optimization)\nCREATE INDEX idx_events_recent ON events(timestamp DESC) \nWHERE timestamp &gt; NOW() - INTERVAL '7 days';\n</code></pre> <p>Event Types:</p> Type Description Example Details <code>registration</code> App registered/updated <code>{\"image\": \"nginx:alpine\", \"replicas\": 3}</code> <code>scaling</code> Scaling operation <code>{\"from\": 2, \"to\": 5, \"reason\": \"high_cpu\"}</code> <code>health</code> Health status change <code>{\"status\": \"unhealthy\", \"failures\": 3}</code> <code>config</code> Configuration change <code>{\"field\": \"replicas\", \"old\": 2, \"new\": 3}</code> <code>deployment</code> Deployment operation <code>{\"action\": \"deploy\", \"version\": \"v1.2.0\"}</code> <code>error</code> Error occurred <code>{\"error\": \"ImagePullBackOff\", \"code\": \"E001\"}</code>"},{"location":"developer-guide/database/#metrics-table-time-series","title":"Metrics Table (Time Series)","text":"<p>Historical performance and resource metrics.</p> <pre><code>CREATE TABLE metrics (\n    -- Primary key\n    id SERIAL PRIMARY KEY,\n\n    -- Metric identification\n    app_name VARCHAR(253) NOT NULL REFERENCES applications(name) ON DELETE CASCADE,\n    metric_type VARCHAR(50) NOT NULL,           -- Type of metric\n\n    -- Time series data\n    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    value REAL NOT NULL,                        -- Metric value\n\n    -- Additional metadata\n    labels JSONB,                               -- Key-value labels\n    unit VARCHAR(20),                           -- Metric unit (%, bytes, ms, etc.)\n\n    -- Aggregation level\n    aggregation_level VARCHAR(20) DEFAULT 'instance', -- instance, app, system\n\n    -- Constraints\n    CONSTRAINT valid_metric_type CHECK (metric_type IN (\n        'cpu_percent', 'memory_percent', 'memory_bytes', 'rps', \n        'latency_p50', 'latency_p95', 'latency_p99', 'active_connections',\n        'error_rate', 'response_time', 'queue_length', 'disk_usage'\n    )),\n    CONSTRAINT valid_aggregation_level CHECK (aggregation_level IN (\n        'instance', 'app', 'system'\n    ))\n);\n\n-- Time series indexes (critical for performance)\nCREATE INDEX idx_metrics_app_timestamp ON metrics(app_name, timestamp DESC);\nCREATE INDEX idx_metrics_type_timestamp ON metrics(metric_type, timestamp DESC);\nCREATE INDEX idx_metrics_timestamp ON metrics(timestamp DESC);\nCREATE INDEX idx_metrics_app_type_time ON metrics(app_name, metric_type, timestamp DESC);\n\n-- Partitioning for large datasets (optional)\n-- CREATE TABLE metrics_2024_01 PARTITION OF metrics\n-- FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');\n</code></pre>"},{"location":"developer-guide/database/#scaling-policies-table","title":"Scaling Policies Table","text":"<p>Stores scaling policies and configurations.</p> <pre><code>CREATE TABLE scaling_policies (\n    -- Primary key\n    app_name VARCHAR(253) PRIMARY KEY REFERENCES applications(name) ON DELETE CASCADE,\n\n    -- Basic scaling parameters\n    min_replicas INTEGER NOT NULL DEFAULT 1,\n    max_replicas INTEGER NOT NULL DEFAULT 5,\n\n    -- Performance targets\n    target_rps_per_replica INTEGER DEFAULT 50,\n    max_p95_latency_ms INTEGER DEFAULT 250,\n    max_cpu_percent REAL DEFAULT 70.0,\n    max_memory_percent REAL DEFAULT 75.0,\n    max_connections_per_replica INTEGER DEFAULT 100,\n\n    -- Scaling behavior\n    scale_out_threshold_pct INTEGER DEFAULT 80,\n    scale_in_threshold_pct INTEGER DEFAULT 30,\n    cooldown_seconds INTEGER DEFAULT 180,\n    evaluation_window_seconds INTEGER DEFAULT 60,\n\n    -- Advanced settings\n    max_scale_out_step INTEGER DEFAULT 0,       -- 0 means no limit\n    max_scale_in_step INTEGER DEFAULT 1,\n    stabilization_window_seconds INTEGER DEFAULT 300,\n\n    -- Metric weights (for future use)\n    cpu_weight REAL DEFAULT 1.0,\n    memory_weight REAL DEFAULT 1.0,\n    rps_weight REAL DEFAULT 1.0,\n    latency_weight REAL DEFAULT 1.5,\n    connection_weight REAL DEFAULT 0.8,\n\n    -- Timestamps\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n\n    -- Constraints\n    CONSTRAINT valid_replica_bounds CHECK (min_replicas &lt;= max_replicas),\n    CONSTRAINT valid_min_replicas CHECK (min_replicas &gt;= 0),\n    CONSTRAINT valid_max_replicas CHECK (max_replicas &gt;= 1),\n    CONSTRAINT valid_thresholds CHECK (scale_in_threshold_pct &lt; scale_out_threshold_pct),\n    CONSTRAINT valid_percentages CHECK (\n        scale_out_threshold_pct BETWEEN 1 AND 100 AND\n        scale_in_threshold_pct BETWEEN 1 AND 100\n    ),\n    CONSTRAINT valid_weights CHECK (\n        cpu_weight &gt;= 0 AND memory_weight &gt;= 0 AND rps_weight &gt;= 0 AND\n        latency_weight &gt;= 0 AND connection_weight &gt;= 0\n    )\n);\n\n-- Index for policy lookups\nCREATE INDEX idx_scaling_policies_updated_at ON scaling_policies(updated_at DESC);\n</code></pre>"},{"location":"developer-guide/database/#health-checks-table","title":"Health Checks Table","text":"<p>Configuration and status of health checks.</p> <pre><code>CREATE TABLE health_checks (\n    -- Primary key\n    id SERIAL PRIMARY KEY,\n\n    -- Application relationship\n    app_name VARCHAR(253) NOT NULL REFERENCES applications(name) ON DELETE CASCADE,\n\n    -- Health check configuration\n    protocol VARCHAR(10) NOT NULL DEFAULT 'HTTP',\n    path VARCHAR(500),                          -- HTTP path\n    port INTEGER NOT NULL,\n    method VARCHAR(10) DEFAULT 'GET',           -- HTTP method\n    headers JSONB,                              -- HTTP headers\n    body TEXT,                                  -- Request body\n    expected_status_codes INTEGER[] DEFAULT ARRAY[200],\n\n    -- Timing configuration\n    initial_delay_seconds INTEGER DEFAULT 30,\n    period_seconds INTEGER DEFAULT 30,\n    timeout_seconds INTEGER DEFAULT 5,\n    failure_threshold INTEGER DEFAULT 3,\n    success_threshold INTEGER DEFAULT 1,\n\n    -- Status\n    enabled BOOLEAN DEFAULT true,\n\n    -- Timestamps\n    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),\n\n    -- Constraints\n    CONSTRAINT valid_protocol CHECK (protocol IN ('HTTP', 'TCP')),\n    CONSTRAINT valid_method CHECK (method IN ('GET', 'POST', 'PUT', 'HEAD')),\n    CONSTRAINT valid_port CHECK (port &gt; 0 AND port &lt;= 65535),\n    CONSTRAINT valid_timings CHECK (\n        initial_delay_seconds &gt;= 0 AND\n        period_seconds &gt; 0 AND\n        timeout_seconds &gt; 0 AND\n        failure_threshold &gt; 0 AND\n        success_threshold &gt; 0\n    ),\n\n    -- Unique health check per app\n    UNIQUE(app_name)\n);\n\n-- Index for health check lookups\nCREATE INDEX idx_health_checks_app_name ON health_checks(app_name);\nCREATE INDEX idx_health_checks_enabled ON health_checks(enabled);\n</code></pre>"},{"location":"developer-guide/database/#data-models-python","title":"Data Models (Python)","text":""},{"location":"developer-guide/database/#application-record","title":"Application Record","text":"<pre><code>@dataclass\nclass AppRecord:\n    \"\"\"Application record data model.\"\"\"\n    name: str\n    spec: Dict[str, Any]\n    status: str\n    created_at: float\n    updated_at: float\n    replicas: int = 0\n    desired_replicas: int = 0\n    last_scaled_at: Optional[float] = None\n    mode: str = 'auto'\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n        return {\n            'name': self.name,\n            'spec': self.spec,\n            'status': self.status,\n            'created_at': self.created_at,\n            'updated_at': self.updated_at,\n            'replicas': self.replicas,\n            'desired_replicas': self.desired_replicas,\n            'last_scaled_at': self.last_scaled_at,\n            'mode': self.mode\n        }\n\n    @classmethod\n    def from_db_row(cls, row) -&gt; 'AppRecord':\n        \"\"\"Create from database row.\"\"\"\n        return cls(\n            name=row['name'],\n            spec=json.loads(row['spec']) if isinstance(row['spec'], str) else row['spec'],\n            status=row['status'],\n            created_at=row['created_at'].timestamp(),\n            updated_at=row['updated_at'].timestamp(),\n            replicas=row['replicas'],\n            desired_replicas=row.get('desired_replicas', 0),\n            last_scaled_at=row['last_scaled_at'].timestamp() if row['last_scaled_at'] else None,\n            mode=row['mode']\n        )\n</code></pre>"},{"location":"developer-guide/database/#instance-record","title":"Instance Record","text":"<pre><code>@dataclass\nclass InstanceRecord:\n    \"\"\"Container instance record data model.\"\"\"\n    id: Optional[int]\n    app_name: str\n    container_id: str\n    container_name: str\n    replica_index: int\n    ip: str\n    port: int\n    status: str\n    health_status: str\n    created_at: float\n    updated_at: float\n    started_at: Optional[float] = None\n    last_health_check: Optional[float] = None\n    failure_count: int = 0\n    consecutive_failures: int = 0\n    last_failure_at: Optional[float] = None\n    cpu_percent: float = 0.0\n    memory_percent: float = 0.0\n    memory_usage_bytes: int = 0\n\n    def is_healthy(self) -&gt; bool:\n        \"\"\"Check if instance is healthy.\"\"\"\n        return (self.status == 'running' and \n                self.health_status == 'healthy' and\n                self.consecutive_failures &lt; 3)\n\n    def is_ready_for_traffic(self) -&gt; bool:\n        \"\"\"Check if instance can receive traffic.\"\"\"\n        return (self.status == 'running' and \n                self.health_status in ['healthy', 'starting'] and\n                self.consecutive_failures &lt; 5)\n</code></pre>"},{"location":"developer-guide/database/#event-record","title":"Event Record","text":"<pre><code>@dataclass\nclass EventRecord:\n    \"\"\"System event record data model.\"\"\"\n    id: Optional[int]\n    event_type: str\n    event_category: str\n    app_name: Optional[str]\n    container_id: Optional[str]\n    message: str\n    details: Optional[Dict[str, Any]]\n    severity: str\n    timestamp: float\n    source: str = 'controller'\n    node_id: Optional[str] = None\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert to dictionary for API responses.\"\"\"\n        return {\n            'id': self.id,\n            'event_type': self.event_type,\n            'event_category': self.event_category,\n            'app_name': self.app_name,\n            'container_id': self.container_id,\n            'message': self.message,\n            'details': self.details,\n            'severity': self.severity,\n            'timestamp': self.timestamp,\n            'source': self.source,\n            'node_id': self.node_id\n        }\n</code></pre>"},{"location":"developer-guide/database/#database-operations","title":"Database Operations","text":""},{"location":"developer-guide/database/#connection-management_1","title":"Connection Management","text":"<pre><code>class DatabasePool:\n    \"\"\"Database connection pool manager.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.primary_pool = None\n        self.replica_pool = None\n        self._locks = {\n            'primary': asyncio.Lock(),\n            'replica': asyncio.Lock()\n        }\n\n    async def initialize_primary(self):\n        \"\"\"Initialize primary database connection pool.\"\"\"\n        async with self._locks['primary']:\n            if self.primary_pool is None:\n                self.primary_pool = await asyncpg.create_pool(\n                    host=self.config['primary']['host'],\n                    port=self.config['primary']['port'],\n                    user=self.config['primary']['user'],\n                    password=self.config['primary']['password'],\n                    database=self.config['primary']['database'],\n                    min_size=self.config.get('pool_min_size', 5),\n                    max_size=self.config.get('pool_max_size', 20),\n                    command_timeout=self.config.get('command_timeout', 30),\n                    server_settings={\n                        'application_name': 'orchestry_controller',\n                        'jit': 'off'  # Disable JIT for better predictability\n                    }\n                )\n\n    async def initialize_replica(self):\n        \"\"\"Initialize replica database connection pool.\"\"\"\n        if not self.config.get('replica', {}).get('enabled', False):\n            return\n\n        async with self._locks['replica']:\n            if self.replica_pool is None:\n                try:\n                    self.replica_pool = await asyncpg.create_pool(\n                        host=self.config['replica']['host'],\n                        port=self.config['replica']['port'],\n                        user=self.config['replica']['user'],\n                        password=self.config['replica']['password'],\n                        database=self.config['replica']['database'],\n                        min_size=self.config.get('pool_min_size', 3),\n                        max_size=self.config.get('pool_max_size', 10),\n                        command_timeout=self.config.get('command_timeout', 30),\n                        server_settings={\n                            'application_name': 'orchestry_controller_read',\n                            'default_transaction_isolation': 'repeatable_read'\n                        }\n                    )\n                except Exception as e:\n                    logger.warning(f\"Failed to initialize replica pool: {e}\")\n</code></pre>"},{"location":"developer-guide/database/#query-patterns","title":"Query Patterns","text":"<pre><code>class ApplicationQueries:\n    \"\"\"Optimized queries for application operations.\"\"\"\n\n    @staticmethod\n    async def get_app_with_instances(conn, app_name: str) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"Get application with all instances in a single query.\"\"\"\n        query = \"\"\"\n        SELECT \n            a.*,\n            COALESCE(\n                json_agg(\n                    json_build_object(\n                        'id', i.id,\n                        'container_id', i.container_id,\n                        'container_name', i.container_name,\n                        'replica_index', i.replica_index,\n                        'ip', i.ip,\n                        'port', i.port,\n                        'status', i.status,\n                        'health_status', i.health_status,\n                        'cpu_percent', i.cpu_percent,\n                        'memory_percent', i.memory_percent,\n                        'failure_count', i.failure_count,\n                        'last_health_check', EXTRACT(EPOCH FROM i.last_health_check)\n                    ) ORDER BY i.replica_index\n                ) FILTER (WHERE i.id IS NOT NULL),\n                '[]'::json\n            ) as instances\n        FROM applications a\n        LEFT JOIN instances i ON a.name = i.app_name AND i.status != 'stopped'\n        WHERE a.name = $1\n        GROUP BY a.name\n        \"\"\"\n\n        row = await conn.fetchrow(query, app_name)\n        if not row:\n            return None\n\n        return {\n            'app': AppRecord.from_db_row(row),\n            'instances': [InstanceRecord(**instance) for instance in row['instances']]\n        }\n\n    @staticmethod\n    async def get_apps_summary(conn, status_filter: Optional[str] = None) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get summary of all applications with instance counts.\"\"\"\n        conditions = []\n        params = []\n\n        if status_filter:\n            conditions.append(\"a.status = $1\")\n            params.append(status_filter)\n\n        where_clause = f\"WHERE {' AND '.join(conditions)}\" if conditions else \"\"\n\n        query = f\"\"\"\n        SELECT \n            a.name,\n            a.status,\n            a.replicas,\n            a.desired_replicas,\n            a.mode,\n            a.created_at,\n            a.updated_at,\n            a.last_scaled_at,\n            COUNT(i.id) FILTER (WHERE i.status = 'running') as running_instances,\n            COUNT(i.id) FILTER (WHERE i.health_status = 'healthy') as healthy_instances,\n            AVG(i.cpu_percent) FILTER (WHERE i.status = 'running') as avg_cpu_percent,\n            AVG(i.memory_percent) FILTER (WHERE i.status = 'running') as avg_memory_percent\n        FROM applications a\n        LEFT JOIN instances i ON a.name = i.app_name\n        {where_clause}\n        GROUP BY a.name, a.status, a.replicas, a.desired_replicas, a.mode, \n                 a.created_at, a.updated_at, a.last_scaled_at\n        ORDER BY a.name\n        \"\"\"\n\n        rows = await conn.fetch(query, *params)\n        return [dict(row) for row in rows]\n</code></pre>"},{"location":"developer-guide/database/#metrics-aggregation","title":"Metrics Aggregation","text":"<pre><code>class MetricsQueries:\n    \"\"\"Optimized queries for metrics operations.\"\"\"\n\n    @staticmethod\n    async def get_app_metrics_window(conn, app_name: str, window_minutes: int = 5) -&gt; Dict[str, Any]:\n        \"\"\"Get aggregated metrics for an application over a time window.\"\"\"\n        query = \"\"\"\n        SELECT \n            metric_type,\n            AVG(value) as avg_value,\n            MIN(value) as min_value,\n            MAX(value) as max_value,\n            PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY value) as p50_value,\n            PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY value) as p95_value,\n            COUNT(*) as data_points\n        FROM metrics\n        WHERE app_name = $1 \n          AND timestamp &gt;= NOW() - INTERVAL '%s minutes'\n          AND metric_type IN ('cpu_percent', 'memory_percent', 'rps', 'latency_p95', 'active_connections')\n        GROUP BY metric_type\n        \"\"\" % window_minutes\n\n        rows = await conn.fetch(query, app_name)\n\n        metrics = {}\n        for row in rows:\n            metrics[row['metric_type']] = {\n                'avg': float(row['avg_value']) if row['avg_value'] else 0,\n                'min': float(row['min_value']) if row['min_value'] else 0,\n                'max': float(row['max_value']) if row['max_value'] else 0,\n                'p50': float(row['p50_value']) if row['p50_value'] else 0,\n                'p95': float(row['p95_value']) if row['p95_value'] else 0,\n                'data_points': row['data_points']\n            }\n\n        return metrics\n\n    @staticmethod\n    async def cleanup_old_metrics(conn, retention_hours: int = 168):\n        \"\"\"Clean up metrics older than retention period.\"\"\"\n        query = \"\"\"\n        DELETE FROM metrics \n        WHERE timestamp &lt; NOW() - INTERVAL '%s hours'\n        \"\"\" % retention_hours\n\n        result = await conn.execute(query)\n        deleted_count = int(result.split()[1])\n        return deleted_count\n</code></pre>"},{"location":"developer-guide/database/#performance-optimization","title":"Performance Optimization","text":""},{"location":"developer-guide/database/#indexing-strategy","title":"Indexing Strategy","text":"<pre><code>-- Composite indexes for common query patterns\nCREATE INDEX idx_instances_app_status_health ON instances(app_name, status, health_status);\nCREATE INDEX idx_events_app_type_severity ON events(app_name, event_type, severity, timestamp DESC);\nCREATE INDEX idx_metrics_app_type_recent ON metrics(app_name, metric_type, timestamp DESC)\nWHERE timestamp &gt; NOW() - INTERVAL '24 hours';\n\n-- Partial indexes for active data\nCREATE INDEX idx_applications_active ON applications(name, status, updated_at)\nWHERE status IN ('running', 'starting', 'updating');\n\nCREATE INDEX idx_instances_active ON instances(app_name, status, health_status, updated_at)\nWHERE status IN ('running', 'starting');\n</code></pre>"},{"location":"developer-guide/database/#query-optimization","title":"Query Optimization","text":"<pre><code>class QueryOptimizer:\n    \"\"\"Database query optimization utilities.\"\"\"\n\n    @staticmethod\n    async def explain_query(conn, query: str, params: List[Any] = None) -&gt; str:\n        \"\"\"Get query execution plan.\"\"\"\n        explain_query = f\"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) {query}\"\n        result = await conn.fetch(explain_query, *(params or []))\n        return json.dumps(result[0]['QUERY PLAN'], indent=2)\n\n    @staticmethod\n    async def get_slow_queries(conn, min_duration_ms: int = 1000) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get slow queries from pg_stat_statements.\"\"\"\n        query = \"\"\"\n        SELECT \n            query,\n            calls,\n            total_time,\n            mean_time,\n            stddev_time,\n            rows,\n            100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent\n        FROM pg_stat_statements\n        WHERE mean_time &gt; $1\n        ORDER BY mean_time DESC\n        LIMIT 20\n        \"\"\"\n\n        rows = await conn.fetch(query, min_duration_ms)\n        return [dict(row) for row in rows]\n</code></pre>"},{"location":"developer-guide/database/#connection-pool-tuning","title":"Connection Pool Tuning","text":"<pre><code># Optimal pool configuration\nPOOL_CONFIG = {\n    'primary': {\n        'min_size': 5,          # Always keep 5 connections open\n        'max_size': 20,         # Maximum 20 connections\n        'command_timeout': 30,   # 30 second query timeout\n        'max_queries': 50000,    # Recycle connections after 50k queries\n        'max_inactive_time': 300 # Close inactive connections after 5 minutes\n    },\n    'replica': {\n        'min_size': 3,          # Fewer connections for read replica\n        'max_size': 10,         # Lower maximum for read workload\n        'command_timeout': 60,   # Longer timeout for analytical queries\n        'max_queries': 100000,   # Recycle less frequently\n        'max_inactive_time': 600 # Keep connections longer for batch operations\n    }\n}\n</code></pre>"},{"location":"developer-guide/database/#data-retention-and-archival","title":"Data Retention and Archival","text":""},{"location":"developer-guide/database/#automatic-cleanup","title":"Automatic Cleanup","text":"<pre><code>-- Function to clean up old data\nCREATE OR REPLACE FUNCTION cleanup_old_data()\nRETURNS TABLE(table_name TEXT, deleted_count INTEGER) AS $$\nBEGIN\n    -- Clean up old events (keep 30 days)\n    DELETE FROM events WHERE timestamp &lt; NOW() - INTERVAL '30 days';\n    GET DIAGNOSTICS deleted_count = ROW_COUNT;\n    table_name := 'events';\n    RETURN NEXT;\n\n    -- Clean up old metrics (keep 7 days for instance level, 30 days for app level)\n    DELETE FROM metrics \n    WHERE timestamp &lt; NOW() - INTERVAL '7 days' \n      AND aggregation_level = 'instance';\n    GET DIAGNOSTICS deleted_count = ROW_COUNT;\n    table_name := 'metrics (instance)';\n    RETURN NEXT;\n\n    DELETE FROM metrics \n    WHERE timestamp &lt; NOW() - INTERVAL '30 days' \n      AND aggregation_level = 'app';\n    GET DIAGNOSTICS deleted_count = ROW_COUNT;\n    table_name := 'metrics (app)';\n    RETURN NEXT;\n\n    -- Clean up stopped instances (keep 7 days)\n    DELETE FROM instances \n    WHERE status = 'stopped' \n      AND updated_at &lt; NOW() - INTERVAL '7 days';\n    GET DIAGNOSTICS deleted_count = ROW_COUNT;\n    table_name := 'instances (stopped)';\n    RETURN NEXT;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Schedule cleanup (requires pg_cron extension)\nSELECT cron.schedule('cleanup-old-data', '0 2 * * *', 'SELECT cleanup_old_data();');\n</code></pre>"},{"location":"developer-guide/database/#archival-strategy","title":"Archival Strategy","text":"<pre><code>class DataArchival:\n    \"\"\"Data archival and retention management.\"\"\"\n\n    async def archive_old_metrics(self, cutoff_date: datetime, archive_table: str):\n        \"\"\"Archive old metrics to separate table.\"\"\"\n        async with self.get_write_connection() as conn:\n            # Create archive table if it doesn't exist\n            await conn.execute(f\"\"\"\n                CREATE TABLE IF NOT EXISTS {archive_table} \n                (LIKE metrics INCLUDING ALL)\n            \"\"\")\n\n            # Move old data to archive\n            await conn.execute(f\"\"\"\n                WITH moved_data AS (\n                    DELETE FROM metrics \n                    WHERE timestamp &lt; $1 \n                    RETURNING *\n                )\n                INSERT INTO {archive_table} \n                SELECT * FROM moved_data\n            \"\"\", cutoff_date)\n\n    async def compress_old_events(self, days_old: int = 90):\n        \"\"\"Compress old events to reduce storage.\"\"\"\n        async with self.get_write_connection() as conn:\n            # Aggregate old events by hour\n            await conn.execute(\"\"\"\n                INSERT INTO events_compressed (\n                    hour_bucket, app_name, event_type, event_count, \n                    severity_counts, sample_messages\n                )\n                SELECT \n                    date_trunc('hour', timestamp) as hour_bucket,\n                    app_name,\n                    event_type,\n                    COUNT(*) as event_count,\n                    json_object_agg(severity, severity_count) as severity_counts,\n                    array_agg(DISTINCT message ORDER BY timestamp DESC LIMIT 5) as sample_messages\n                FROM events\n                CROSS JOIN LATERAL (\n                    SELECT severity, COUNT(*) as severity_count\n                    FROM events e2\n                    WHERE e2.timestamp = events.timestamp\n                      AND e2.app_name = events.app_name\n                      AND e2.event_type = events.event_type\n                    GROUP BY severity\n                ) severity_agg\n                WHERE timestamp &lt; NOW() - INTERVAL '%s days'\n                GROUP BY date_trunc('hour', timestamp), app_name, event_type\n            \"\"\" % days_old)\n\n            # Delete original events after compression\n            result = await conn.execute(\n                \"DELETE FROM events WHERE timestamp &lt; NOW() - INTERVAL '%s days'\" % days_old\n            )\n            return int(result.split()[1])\n</code></pre> <p>Next Steps: Learn about Load Balancing and Nginx integration.</p>"},{"location":"developer-guide/development/","title":"Development Environment Setup","text":"<p>Complete guide for setting up a development environment for Orchestry, including local development, testing, and contribution workflows.</p>"},{"location":"developer-guide/development/#prerequisites","title":"Prerequisites","text":""},{"location":"developer-guide/development/#system-requirements","title":"System Requirements","text":"<ul> <li>Operating System: Linux (Ubuntu 20.04+, CentOS 8+, or similar)</li> <li>Python: 3.9 or higher</li> <li>Docker: 20.10 or higher with Docker Compose</li> <li>PostgreSQL: 13 or higher (for development database)</li> <li>Nginx: 1.18 or higher (optional, for load balancer testing)</li> <li>Git: For version control</li> </ul>"},{"location":"developer-guide/development/#development-tools","title":"Development Tools","text":"<pre><code># Essential development packages\nsudo apt update\nsudo apt install -y \\\n    python3.11 \\\n    python3.11-dev \\\n    python3.11-venv \\\n    postgresql-client \\\n    docker.io \\\n    docker-compose \\\n    nginx \\\n    git \\\n    curl \\\n    wget \\\n    build-essential \\\n    libpq-dev\n\n# Start Docker service\nsudo systemctl start docker\nsudo systemctl enable docker\nsudo usermod -a -G docker $USER\n</code></pre>"},{"location":"developer-guide/development/#environment-setup","title":"Environment Setup","text":""},{"location":"developer-guide/development/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code># Clone the ORCHESTRY repository\ngit clone https://github.com/admincodes7/Orchestry.git\ncd Orchestry\n\n# Create development branch\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"developer-guide/development/#2-python-environment","title":"2. Python Environment","text":"<pre><code># Create virtual environment\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Upgrade pip and install development dependencies\npip install --upgrade pip\npip install -e .[dev]\n\n# Install pre-commit hooks\npre-commit install\n</code></pre>"},{"location":"developer-guide/development/#3-development-dependencies","title":"3. Development Dependencies","text":"<p>The <code>pyproject.toml</code> includes development dependencies:</p> <pre><code>[project.optional-dependencies]\ndev = [\n    # Testing\n    \"pytest&gt;=7.0.0\",\n    \"pytest-asyncio&gt;=0.21.0\",\n    \"pytest-cov&gt;=4.0.0\",\n    \"pytest-mock&gt;=3.10.0\",\n\n    # Code quality\n    \"black&gt;=23.0.0\",\n    \"isort&gt;=5.12.0\",\n    \"flake8&gt;=6.0.0\",\n    \"mypy&gt;=1.0.0\",\n    \"pre-commit&gt;=3.0.0\",\n\n    # Documentation\n    \"mkdocs&gt;=1.4.0\",\n    \"mkdocs-material&gt;=9.0.0\",\n    \"mkdocstrings[python]&gt;=0.20.0\",\n\n    # Development utilities\n    \"ipython&gt;=8.0.0\",\n    \"debugpy&gt;=1.6.0\",\n    \"httpx&gt;=0.24.0\",\n    \"factory-boy&gt;=3.2.0\"\n]\n</code></pre>"},{"location":"developer-guide/development/#4-database-setup","title":"4. Database Setup","text":"<pre><code># Start PostgreSQL with Docker\ndocker run -d \\\n    --name orchestry-postgres \\\n    -e POSTGRES_DB=orchestry_dev \\\n    -e POSTGRES_USER=orchestry \\\n    -e POSTGRES_PASSWORD=development_password \\\n    -p 5432:5432 \\\n    postgres:15\n\n# Wait for database to be ready\nsleep 10\n\n# Initialize database schema\npython -m cli.main db init --connection-string \"postgresql://orchestry:development_password@localhost:5432/orchestry_dev\"\n</code></pre>"},{"location":"developer-guide/development/#5-configuration","title":"5. Configuration","text":"<p>Create development configuration file:</p> <pre><code># Create config directory\nmkdir -p ~/.config/orchestry\n\n# Development configuration\ncat &gt; ~/.config/orchestry/development.yml &lt;&lt; EOF\n# Orchestry Development Configuration\n\ndatabase:\n  primary:\n    host: localhost\n    port: 5432\n    user: orchestry\n    password: development_password\n    database: orchestry_dev\n\n  replica:\n    enabled: false\n\ndocker:\n  socket: \"unix://var/run/docker.sock\"\n  network: \"orchestry-dev\"\n\ncontroller:\n  port: 8000\n  host: \"0.0.0.0\"\n  workers: 1\n  debug: true\n\nnginx:\n  config_dir: \"/tmp/orchestry-nginx\"\n  reload_command: \"echo 'Nginx reload simulated'\"\n\nlogging:\n  level: DEBUG\n  format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n\nmetrics:\n  enabled: true\n  retention_hours: 24\n\nhealth_checks:\n  default_timeout: 5\n  default_interval: 30\n\nscaling:\n  default_min_replicas: 1\n  default_max_replicas: 5\n  evaluation_interval: 60\nEOF\n</code></pre>"},{"location":"developer-guide/development/#development-workflow","title":"Development Workflow","text":""},{"location":"developer-guide/development/#directory-structure","title":"Directory Structure","text":"<pre><code>orchestry/\n\u251c\u2500\u2500 app_spec/          # Application specification models\n\u251c\u2500\u2500 cli/               # Command-line interface\n\u251c\u2500\u2500 controller/        # Main controller components\n\u251c\u2500\u2500 state/            # Database and state management\n\u251c\u2500\u2500 metrics/          # Metrics collection and export\n\u251c\u2500\u2500 configs/          # Configuration templates\n\u251c\u2500\u2500 tests/            # Test suite\n\u251c\u2500\u2500 docs/             # Documentation\n\u251c\u2500\u2500 examples/         # Example applications\n\u251c\u2500\u2500 scripts/          # Development scripts\n\u2514\u2500\u2500 docker/           # Docker configurations\n</code></pre>"},{"location":"developer-guide/development/#code-organization","title":"Code Organization","text":"<pre><code># File naming conventions\ncontroller/\n\u251c\u2500\u2500 __init__.py       # Package initialization\n\u251c\u2500\u2500 main.py          # Main entry point\n\u251c\u2500\u2500 api.py           # FastAPI REST API\n\u251c\u2500\u2500 manager.py       # Application management\n\u251c\u2500\u2500 scaler.py        # Auto-scaling logic\n\u251c\u2500\u2500 health.py        # Health monitoring\n\u2514\u2500\u2500 nginx.py         # Nginx integration\n\n# Import organization (following isort configuration)\n# 1. Standard library imports\nimport asyncio\nimport logging\nfrom typing import Dict, List, Optional\n\n# 2. Third-party imports\nimport aiohttp\nimport asyncpg\nfrom fastapi import FastAPI\n\n# 3. Local imports\nfrom app_spec.models import AppSpec\nfrom state.db import DatabaseManager\n</code></pre>"},{"location":"developer-guide/development/#running-development-server","title":"Running Development Server","text":"<pre><code># Activate virtual environment\nsource venv/bin/activate\n\n# Set development environment\nexport ORCHESTRY_ENV=development\nexport ORCHESTRY_CONFIG=~/.config/orchestry/development.yml\n\n# Start the controller in development mode\npython -m controller.main --reload --debug\n\n# Or use the development script\n./scripts/dev-server.sh\n</code></pre>"},{"location":"developer-guide/development/#development-scripts","title":"Development Scripts","text":"<p>Create helpful development scripts in <code>scripts/</code>:</p> <p><code>scripts/dev-server.sh</code>: <pre><code>#!/bin/bash\n# Development server with auto-reload\n\nset -e\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Set development environment variables\nexport ORCHESTRY_ENV=development\nexport ORCHESTRY_CONFIG=~/.config/orchestry/development.yml\nexport PYTHONPATH=$PWD:$PYTHONPATH\n\n# Start development server\necho \"Starting Orchestry development server...\"\nuvicorn controller.api:app \\\n    --reload \\\n    --host 0.0.0.0 \\\n    --port 8000 \\\n    --log-level debug \\\n    --reload-dir controller \\\n    --reload-dir app_spec \\\n    --reload-dir state\n</code></pre></p> <p><code>scripts/test.sh</code>: <pre><code>#!/bin/bash\n# Run test suite with coverage\n\nset -e\n\nsource venv/bin/activate\n\necho \"Running tests with coverage...\"\npytest \\\n    --cov=controller \\\n    --cov=app_spec \\\n    --cov=state \\\n    --cov=cli \\\n    --cov-report=html \\\n    --cov-report=term-missing \\\n    --cov-fail-under=80 \\\n    tests/\n\necho \"Coverage report generated in htmlcov/\"\n</code></pre></p> <p><code>scripts/lint.sh</code>: <pre><code>#!/bin/bash\n# Code quality checks\n\nset -e\n\nsource venv/bin/activate\n\necho \"Running code formatting...\"\nblack .\nisort .\n\necho \"Running linting...\"\nflake8 controller/ app_spec/ state/ cli/\n\necho \"Running type checking...\"\nmypy controller/ app_spec/ state/ cli/\n\necho \"All checks passed!\"\n</code></pre></p>"},{"location":"developer-guide/development/#testing","title":"Testing","text":""},{"location":"developer-guide/development/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py              # Pytest fixtures\n\u251c\u2500\u2500 unit/                   # Unit tests\n\u2502   \u251c\u2500\u2500 test_models.py\n\u2502   \u251c\u2500\u2500 test_manager.py\n\u2502   \u251c\u2500\u2500 test_scaler.py\n\u2502   \u2514\u2500\u2500 test_health.py\n\u251c\u2500\u2500 integration/            # Integration tests\n\u2502   \u251c\u2500\u2500 test_api.py\n\u2502   \u251c\u2500\u2500 test_database.py\n\u2502   \u2514\u2500\u2500 test_docker.py\n\u251c\u2500\u2500 e2e/                   # End-to-end tests\n\u2502   \u251c\u2500\u2500 test_deployment.py\n\u2502   \u2514\u2500\u2500 test_scaling.py\n\u2514\u2500\u2500 fixtures/              # Test data\n    \u251c\u2500\u2500 app_specs/\n    \u2514\u2500\u2500 responses/\n</code></pre>"},{"location":"developer-guide/development/#test-configuration","title":"Test Configuration","text":"<p><code>tests/conftest.py</code>: <pre><code>import asyncio\nimport pytest\nimport pytest_asyncio\nfrom unittest.mock import AsyncMock, MagicMock\nfrom fastapi.testclient import TestClient\n\nfrom controller.api import app\nfrom controller.manager import AppManager\nfrom state.db import DatabaseManager\nfrom app_spec.models import AppSpec\n\n@pytest.fixture(scope=\"session\")\ndef event_loop():\n    \"\"\"Create event loop for async tests.\"\"\"\n    policy = asyncio.get_event_loop_policy()\n    loop = policy.new_event_loop()\n    yield loop\n    loop.close()\n\n@pytest_asyncio.fixture\nasync def db_manager():\n    \"\"\"Mock database manager.\"\"\"\n    manager = MagicMock(spec=DatabaseManager)\n\n    # Mock async methods\n    manager.get_application = AsyncMock()\n    manager.list_applications = AsyncMock()\n    manager.save_application = AsyncMock()\n    manager.delete_application = AsyncMock()\n\n    return manager\n\n@pytest.fixture\ndef docker_client():\n    \"\"\"Mock Docker client.\"\"\"\n    client = MagicMock()\n\n    # Mock containers\n    client.containers.list = MagicMock(return_value=[])\n    client.containers.run = MagicMock()\n    client.containers.get = MagicMock()\n\n    return client\n\n@pytest_asyncio.fixture\nasync def app_manager(db_manager, docker_client):\n    \"\"\"App manager with mocked dependencies.\"\"\"\n    manager = AppManager(\n        db=db_manager,\n        docker_client=docker_client\n    )\n    return manager\n\n@pytest.fixture\ndef test_client():\n    \"\"\"FastAPI test client.\"\"\"\n    return TestClient(app)\n\n@pytest.fixture\ndef sample_app_spec():\n    \"\"\"Sample application specification.\"\"\"\n    return {\n        \"apiVersion\": \"orchestry.dev/v1\",\n        \"kind\": \"Application\",\n        \"metadata\": {\n            \"name\": \"test-app\",\n            \"labels\": {\n                \"environment\": \"test\"\n            }\n        },\n        \"spec\": {\n            \"image\": \"nginx:alpine\",\n            \"replicas\": 2,\n            \"port\": 80,\n            \"env\": {},\n            \"resources\": {\n                \"cpu\": \"100m\",\n                \"memory\": \"128Mi\"\n            },\n            \"networking\": {\n                \"external_port\": 8080\n            },\n            \"health_check\": {\n                \"path\": \"/health\",\n                \"interval\": 30,\n                \"timeout\": 5\n            },\n            \"scaling\": {\n                \"min_replicas\": 1,\n                \"max_replicas\": 5,\n                \"target_cpu\": 70\n            }\n        }\n    }\n\n@pytest.fixture\ndef sample_instances():\n    \"\"\"Sample instance records.\"\"\"\n    return [\n        {\n            \"id\": 1,\n            \"app_name\": \"test-app\",\n            \"container_id\": \"container1\",\n            \"container_name\": \"test-app-0\",\n            \"replica_index\": 0,\n            \"ip\": \"172.17.0.2\",\n            \"port\": 80,\n            \"status\": \"running\",\n            \"health_status\": \"healthy\"\n        },\n        {\n            \"id\": 2,\n            \"app_name\": \"test-app\",\n            \"container_id\": \"container2\",\n            \"container_name\": \"test-app-1\",\n            \"replica_index\": 1,\n            \"ip\": \"172.17.0.3\",\n            \"port\": 80,\n            \"status\": \"running\",\n            \"health_status\": \"healthy\"\n        }\n    ]\n</code></pre></p>"},{"location":"developer-guide/development/#unit-tests","title":"Unit Tests","text":"<p><code>tests/unit/test_manager.py</code>: <pre><code>import pytest\nfrom unittest.mock import AsyncMock, MagicMock, patch\n\nfrom controller.manager import AppManager\nfrom app_spec.models import AppSpec\n\n@pytest.mark.asyncio\nasync def test_deploy_application(app_manager, sample_app_spec):\n    \"\"\"Test application deployment.\"\"\"\n    # Setup\n    app_spec = AppSpec.from_dict(sample_app_spec)\n    app_manager.db.get_application.return_value = None\n    app_manager.db.save_application = AsyncMock()\n\n    with patch.object(app_manager, 'create_instance', new_callable=AsyncMock) as mock_create:\n        mock_create.return_value = True\n\n        # Execute\n        result = await app_manager.deploy_application(app_spec)\n\n        # Verify\n        assert result is True\n        app_manager.db.save_application.assert_called_once()\n        assert mock_create.call_count == app_spec.spec.replicas\n\n@pytest.mark.asyncio\nasync def test_scale_application(app_manager, sample_instances):\n    \"\"\"Test application scaling.\"\"\"\n    # Setup\n    app_name = \"test-app\"\n    target_replicas = 3\n\n    app_manager.db.get_application.return_value = MagicMock(replicas=2)\n    app_manager.db.list_instances.return_value = sample_instances\n\n    with patch.object(app_manager, 'create_instance', new_callable=AsyncMock) as mock_create:\n        mock_create.return_value = True\n\n        # Execute\n        result = await app_manager.scale_application(app_name, target_replicas)\n\n        # Verify\n        assert result is True\n        mock_create.assert_called_once()\n\n@pytest.mark.asyncio\nasync def test_remove_application(app_manager, sample_instances):\n    \"\"\"Test application removal.\"\"\"\n    # Setup\n    app_name = \"test-app\"\n    app_manager.db.list_instances.return_value = sample_instances\n\n    with patch.object(app_manager, 'stop_container', new_callable=AsyncMock) as mock_stop:\n        mock_stop.return_value = True\n        app_manager.db.delete_application = AsyncMock()\n\n        # Execute\n        result = await app_manager.remove_application(app_name)\n\n        # Verify\n        assert result is True\n        assert mock_stop.call_count == len(sample_instances)\n        app_manager.db.delete_application.assert_called_once_with(app_name)\n</code></pre></p>"},{"location":"developer-guide/development/#integration-tests","title":"Integration Tests","text":"<p><code>tests/integration/test_api.py</code>: <pre><code>import pytest\nfrom unittest.mock import AsyncMock, patch\n\ndef test_list_applications(test_client):\n    \"\"\"Test listing applications endpoint.\"\"\"\n    with patch('controller.api.app_manager') as mock_manager:\n        mock_manager.list_applications = AsyncMock(return_value=[])\n\n        response = test_client.get(\"/api/v1/applications\")\n\n        assert response.status_code == 200\n        assert response.json() == {\"applications\": []}\n\ndef test_deploy_application(test_client, sample_app_spec):\n    \"\"\"Test deploy application endpoint.\"\"\"\n    with patch('controller.api.app_manager') as mock_manager:\n        mock_manager.deploy_application = AsyncMock(return_value=True)\n\n        response = test_client.post(\n            \"/api/v1/applications\",\n            json=sample_app_spec\n        )\n\n        assert response.status_code == 201\n        assert \"name\" in response.json()\n\ndef test_get_application_status(test_client):\n    \"\"\"Test get application status endpoint.\"\"\"\n    app_name = \"test-app\"\n\n    with patch('controller.api.app_manager') as mock_manager:\n        mock_manager.get_application_status = AsyncMock(return_value={\n            \"name\": app_name,\n            \"status\": \"running\",\n            \"replicas\": 2,\n            \"healthy_instances\": 2\n        })\n\n        response = test_client.get(f\"/api/v1/applications/{app_name}\")\n\n        assert response.status_code == 200\n        data = response.json()\n        assert data[\"name\"] == app_name\n        assert data[\"status\"] == \"running\"\n</code></pre></p>"},{"location":"developer-guide/development/#end-to-end-tests","title":"End-to-End Tests","text":"<p><code>tests/e2e/test_deployment.py</code>: <pre><code>import pytest\nimport asyncio\nimport aiohttp\nfrom unittest.mock import patch\n\n@pytest.mark.asyncio\n@pytest.mark.e2e\nasync def test_full_deployment_workflow():\n    \"\"\"Test complete deployment workflow.\"\"\"\n    app_spec = {\n        \"apiVersion\": \"orchestry.dev/v1\",\n        \"kind\": \"Application\",\n        \"metadata\": {\"name\": \"e2e-test-app\"},\n        \"spec\": {\n            \"image\": \"nginx:alpine\",\n            \"replicas\": 1,\n            \"port\": 80,\n            \"health_check\": {\"path\": \"/\", \"interval\": 10}\n        }\n    }\n\n    # Deploy application\n    async with aiohttp.ClientSession() as session:\n        # 1. Deploy application\n        async with session.post(\n            \"http://localhost:8000/api/v1/applications\",\n            json=app_spec\n        ) as response:\n            assert response.status == 201\n            deployment_data = await response.json()\n            assert deployment_data[\"name\"] == \"e2e-test-app\"\n\n        # 2. Wait for deployment to complete\n        await asyncio.sleep(30)\n\n        # 3. Check application status\n        async with session.get(\n            \"http://localhost:8000/api/v1/applications/e2e-test-app\"\n        ) as response:\n            assert response.status == 200\n            status_data = await response.json()\n            assert status_data[\"status\"] == \"running\"\n            assert status_data[\"healthy_instances\"] &gt;= 1\n\n        # 4. Test scaling\n        async with session.put(\n            \"http://localhost:8000/api/v1/applications/e2e-test-app/scale\",\n            json={\"replicas\": 2}\n        ) as response:\n            assert response.status == 200\n\n        # 5. Wait for scaling to complete\n        await asyncio.sleep(20)\n\n        # 6. Verify scaling\n        async with session.get(\n            \"http://localhost:8000/api/v1/applications/e2e-test-app\"\n        ) as response:\n            assert response.status == 200\n            status_data = await response.json()\n            assert status_data[\"replicas\"] == 2\n\n        # 7. Clean up\n        async with session.delete(\n            \"http://localhost:8000/api/v1/applications/e2e-test-app\"\n        ) as response:\n            assert response.status == 204\n</code></pre></p>"},{"location":"developer-guide/development/#debugging","title":"Debugging","text":""},{"location":"developer-guide/development/#vs-code-configuration","title":"VS Code Configuration","text":"<p>Create <code>.vscode/launch.json</code>:</p> <pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Orchestry Controller\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"module\": \"controller.main\",\n            \"args\": [\"--debug\"],\n            \"console\": \"integratedTerminal\",\n            \"env\": {\n                \"ORCHESTRY_ENV\": \"development\",\n                \"ORCHESTRY_CONFIG\": \"${env:HOME}/.config/orchestry/development.yml\",\n                \"PYTHONPATH\": \"${workspaceFolder}\"\n            },\n            \"cwd\": \"${workspaceFolder}\",\n            \"justMyCode\": false\n        },\n        {\n            \"name\": \"CLI Tool\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"module\": \"cli.main\",\n            \"args\": [\"--help\"],\n            \"console\": \"integratedTerminal\",\n            \"env\": {\n                \"ORCHESTRY_ENV\": \"development\",\n                \"ORCHESTRY_CONFIG\": \"${env:HOME}/.config/orchestry/development.yml\"\n            },\n            \"cwd\": \"${workspaceFolder}\"\n        },\n        {\n            \"name\": \"Pytest Current File\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"module\": \"pytest\",\n            \"args\": [\"${file}\", \"-v\"],\n            \"console\": \"integratedTerminal\",\n            \"cwd\": \"${workspaceFolder}\"\n        }\n    ]\n}\n</code></pre>"},{"location":"developer-guide/development/#logging-configuration","title":"Logging Configuration","text":"<p>Development logging setup:</p> <pre><code>import logging\nimport sys\n\ndef setup_development_logging():\n    \"\"\"Configure logging for development.\"\"\"\n    # Create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'\n    )\n\n    # Console handler\n    console_handler = logging.StreamHandler(sys.stdout)\n    console_handler.setLevel(logging.DEBUG)\n    console_handler.setFormatter(formatter)\n\n    # File handler\n    file_handler = logging.FileHandler('orchestry-dev.log')\n    file_handler.setLevel(logging.DEBUG)\n    file_handler.setFormatter(formatter)\n\n    # Root logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.DEBUG)\n    root_logger.addHandler(console_handler)\n    root_logger.addHandler(file_handler)\n\n    # Third-party loggers\n    logging.getLogger('urllib3').setLevel(logging.WARNING)\n    logging.getLogger('docker').setLevel(logging.INFO)\n    logging.getLogger('asyncpg').setLevel(logging.INFO)\n</code></pre>"},{"location":"developer-guide/development/#remote-debugging","title":"Remote Debugging","text":"<p>For remote debugging with debugpy:</p> <pre><code>import debugpy\n\n# Enable remote debugging\ndebugpy.listen((\"0.0.0.0\", 5678))\nprint(\"Waiting for debugger to attach...\")\ndebugpy.wait_for_client()\nprint(\"Debugger attached!\")\n</code></pre>"},{"location":"developer-guide/development/#contributing","title":"Contributing","text":""},{"location":"developer-guide/development/#code-style","title":"Code Style","text":"<p>Orchestry follows these code style guidelines:</p> <ol> <li>PEP 8 compliance with line length of 100 characters</li> <li>Black for code formatting</li> <li>isort for import sorting</li> <li>Type hints for all public functions</li> <li>Docstrings in Google style</li> </ol>"},{"location":"developer-guide/development/#pre-commit-configuration","title":"Pre-commit Configuration","text":"<p><code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.4.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n      - id: check-merge-conflict\n\n  - repo: https://github.com/psf/black\n    rev: 23.3.0\n    hooks:\n      - id: black\n        language_version: python3.11\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.12.0\n    hooks:\n      - id: isort\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 6.0.0\n    hooks:\n      - id: flake8\n        additional_dependencies: [flake8-docstrings]\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.3.0\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-all]\n</code></pre>"},{"location":"developer-guide/development/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork and Branch: Create a feature branch from <code>main</code></li> <li>Development: Implement changes following code style guidelines</li> <li>Testing: Ensure all tests pass and add tests for new functionality</li> <li>Documentation: Update documentation for new features</li> <li>Pull Request: Submit PR with clear description and link to issues</li> </ol>"},{"location":"developer-guide/development/#commit-message-format","title":"Commit Message Format","text":"<p>Follow conventional commit format:</p> <pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre> <p>Types: <code>feat</code>, <code>fix</code>, <code>docs</code>, <code>style</code>, <code>refactor</code>, <code>test</code>, <code>chore</code></p> <p>Examples: <pre><code>feat(scaler): add memory-based scaling algorithm\nfix(health): handle timeout errors gracefully\ndocs(api): update deployment endpoint documentation\n</code></pre></p>"},{"location":"developer-guide/development/#performance-profiling","title":"Performance Profiling","text":""},{"location":"developer-guide/development/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Install memory profiler\npip install memory-profiler\n\n# Profile memory usage\npython -m memory_profiler controller/main.py\n</code></pre>"},{"location":"developer-guide/development/#cpu-profiling","title":"CPU Profiling","text":"<pre><code>import cProfile\nimport pstats\n\n# Profile application startup\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# Your code here\nawait app_manager.initialize()\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative').print_stats(20)\n</code></pre>"},{"location":"developer-guide/development/#async-profiling","title":"Async Profiling","text":"<pre><code># Install async profiler\npip install py-spy\n\n# Profile running application\npy-spy top --pid &lt;process_id&gt;\npy-spy record -o profile.svg --pid &lt;process_id&gt;\n</code></pre> <p>Next: Learn about Extensions and Plugins for extending ORCHESTRY functionality.</p>"},{"location":"developer-guide/extensions/","title":"Extensions and Plugins","text":"<p>Guide for extending ORCHESTRY functionality through plugins, custom components, and integration points.</p>"},{"location":"developer-guide/extensions/#overview","title":"Overview","text":"<p>ORCHESTRY is designed with extensibility in mind, providing multiple extension points:</p> <ul> <li>Custom Scalers: Implement domain-specific scaling algorithms</li> <li>Health Check Providers: Add custom health check protocols</li> <li>Load Balancer Integrations: Support additional load balancers beyond Nginx</li> <li>Metrics Exporters: Export metrics to various monitoring systems</li> <li>Event Handlers: React to system events with custom logic</li> <li>Authentication Providers: Integrate with enterprise authentication systems</li> <li>Storage Backends: Use alternative storage systems for state management</li> </ul>"},{"location":"developer-guide/extensions/#plugin-architecture","title":"Plugin Architecture","text":""},{"location":"developer-guide/extensions/#plugin-system-design","title":"Plugin System Design","text":"<pre><code>from abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional\nimport logging\n\nclass Plugin(ABC):\n    \"\"\"Base class for all ORCHESTRY plugins.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.logger = logging.getLogger(f\"plugin.{self.__class__.__name__}\")\n        self._enabled = config.get('enabled', True)\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Plugin name.\"\"\"\n        return self.__class__.__name__.lower().replace('plugin', '')\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Plugin version.\"\"\"\n        return getattr(self, '__version__', '1.0.0')\n\n    @property\n    def enabled(self) -&gt; bool:\n        \"\"\"Check if plugin is enabled.\"\"\"\n        return self._enabled\n\n    @abstractmethod\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize the plugin.\"\"\"\n        pass\n\n    @abstractmethod\n    async def cleanup(self) -&gt; None:\n        \"\"\"Clean up plugin resources.\"\"\"\n        pass\n\n    def validate_config(self) -&gt; List[str]:\n        \"\"\"Validate plugin configuration. Return list of errors.\"\"\"\n        return []\n\nclass PluginManager:\n    \"\"\"Manages plugin lifecycle and registration.\"\"\"\n\n    def __init__(self):\n        self.plugins: Dict[str, Plugin] = {}\n        self.plugin_registry: Dict[str, type] = {}\n\n    def register_plugin(self, plugin_class: type) -&gt; None:\n        \"\"\"Register a plugin class.\"\"\"\n        plugin_name = plugin_class.__name__.lower().replace('plugin', '')\n        self.plugin_registry[plugin_name] = plugin_class\n\n    async def load_plugin(self, plugin_name: str, config: Dict[str, Any]) -&gt; bool:\n        \"\"\"Load and initialize a plugin.\"\"\"\n        if plugin_name not in self.plugin_registry:\n            raise ValueError(f\"Plugin '{plugin_name}' not registered\")\n\n        plugin_class = self.plugin_registry[plugin_name]\n        plugin = plugin_class(config)\n\n        # Validate configuration\n        config_errors = plugin.validate_config()\n        if config_errors:\n            raise ValueError(f\"Plugin configuration errors: {config_errors}\")\n\n        # Initialize plugin\n        try:\n            success = await plugin.initialize()\n            if success:\n                self.plugins[plugin_name] = plugin\n                logging.info(f\"Successfully loaded plugin: {plugin_name}\")\n                return True\n            else:\n                logging.error(f\"Failed to initialize plugin: {plugin_name}\")\n                return False\n        except Exception as e:\n            logging.error(f\"Error loading plugin {plugin_name}: {e}\")\n            return False\n\n    async def unload_plugin(self, plugin_name: str) -&gt; None:\n        \"\"\"Unload a plugin.\"\"\"\n        if plugin_name in self.plugins:\n            plugin = self.plugins[plugin_name]\n            await plugin.cleanup()\n            del self.plugins[plugin_name]\n            logging.info(f\"Unloaded plugin: {plugin_name}\")\n\n    def get_plugin(self, plugin_name: str) -&gt; Optional[Plugin]:\n        \"\"\"Get a loaded plugin by name.\"\"\"\n        return self.plugins.get(plugin_name)\n\n    def list_plugins(self) -&gt; List[str]:\n        \"\"\"List all loaded plugins.\"\"\"\n        return list(self.plugins.keys())\n</code></pre>"},{"location":"developer-guide/extensions/#custom-scalers","title":"Custom Scalers","text":""},{"location":"developer-guide/extensions/#scaler-plugin-interface","title":"Scaler Plugin Interface","text":"<pre><code>from abc import abstractmethod\nfrom dataclasses import dataclass\nfrom typing import Dict, Any, List\n\n@dataclass\nclass ScalingDecision:\n    \"\"\"Represents a scaling decision made by a scaler.\"\"\"\n    app_name: str\n    current_replicas: int\n    target_replicas: int\n    reason: str\n    confidence: float  # 0.0 to 1.0\n    metadata: Dict[str, Any]\n\nclass CustomScaler(Plugin):\n    \"\"\"Base class for custom scaling algorithms.\"\"\"\n\n    @abstractmethod\n    async def should_scale(self, app_name: str, metrics: Dict[str, Any], \n                          current_replicas: int) -&gt; Optional[ScalingDecision]:\n        \"\"\"Determine if scaling is needed.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_required_metrics(self) -&gt; List[str]:\n        \"\"\"Return list of required metrics for this scaler.\"\"\"\n        pass\n\n# Example: Custom ML-based scaler\nclass MLScalerPlugin(CustomScaler):\n    \"\"\"Machine learning-based auto scaler.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.model_path = config.get('model_path')\n        self.prediction_window = config.get('prediction_window', 300)  # 5 minutes\n        self.model = None\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize ML model.\"\"\"\n        try:\n            import joblib\n            self.model = joblib.load(self.model_path)\n            self.logger.info(f\"Loaded ML model from {self.model_path}\")\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to load ML model: {e}\")\n            return False\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources.\"\"\"\n        self.model = None\n\n    def get_required_metrics(self) -&gt; List[str]:\n        \"\"\"Required metrics for ML prediction.\"\"\"\n        return [\n            'cpu_percent',\n            'memory_percent', \n            'rps',\n            'latency_p95',\n            'active_connections',\n            'error_rate'\n        ]\n\n    async def should_scale(self, app_name: str, metrics: Dict[str, Any], \n                          current_replicas: int) -&gt; Optional[ScalingDecision]:\n        \"\"\"Use ML model to predict scaling needs.\"\"\"\n        if not self.model:\n            return None\n\n        try:\n            # Prepare feature vector\n            features = self._prepare_features(metrics, current_replicas)\n\n            # Predict optimal replica count\n            predicted_replicas = self.model.predict([features])[0]\n            predicted_replicas = max(1, min(20, int(round(predicted_replicas))))\n\n            # Calculate confidence based on prediction probability\n            confidence = self._calculate_confidence(features)\n\n            if predicted_replicas != current_replicas and confidence &gt; 0.7:\n                return ScalingDecision(\n                    app_name=app_name,\n                    current_replicas=current_replicas,\n                    target_replicas=predicted_replicas,\n                    reason=f\"ML prediction: {predicted_replicas} replicas (confidence: {confidence:.2f})\",\n                    confidence=confidence,\n                    metadata={\n                        'model_prediction': predicted_replicas,\n                        'features': dict(zip(self.get_required_metrics() + ['current_replicas'], features)),\n                        'scaler_type': 'ml'\n                    }\n                )\n        except Exception as e:\n            self.logger.error(f\"ML scaling prediction failed: {e}\")\n\n        return None\n\n    def _prepare_features(self, metrics: Dict[str, Any], current_replicas: int) -&gt; List[float]:\n        \"\"\"Prepare feature vector for ML model.\"\"\"\n        features = []\n        for metric_name in self.get_required_metrics():\n            metric_data = metrics.get(metric_name, {})\n            # Use average value, defaulting to 0 if not available\n            value = metric_data.get('avg', 0) if isinstance(metric_data, dict) else metric_data\n            features.append(float(value))\n\n        features.append(float(current_replicas))\n        return features\n\n    def _calculate_confidence(self, features: List[float]) -&gt; float:\n        \"\"\"Calculate prediction confidence.\"\"\"\n        # This would use model-specific confidence calculation\n        # For example, using prediction probabilities from ensemble models\n        return 0.8  # Placeholder\n\n# Example: Time-based scaler\nclass TimeBasedScalerPlugin(CustomScaler):\n    \"\"\"Scales based on time patterns and scheduled events.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.schedule = config.get('schedule', {})\n        # Schedule format: {\"09:00\": 5, \"18:00\": 2, \"22:00\": 1}\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize time-based scaler.\"\"\"\n        return True\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"No cleanup needed.\"\"\"\n        pass\n\n    def get_required_metrics(self) -&gt; List[str]:\n        \"\"\"No specific metrics required.\"\"\"\n        return []\n\n    async def should_scale(self, app_name: str, metrics: Dict[str, Any], \n                          current_replicas: int) -&gt; Optional[ScalingDecision]:\n        \"\"\"Scale based on time schedule.\"\"\"\n        from datetime import datetime\n\n        current_time = datetime.now().strftime(\"%H:%M\")\n\n        # Find the most recent schedule entry\n        target_replicas = None\n        for time_str, replicas in sorted(self.schedule.items()):\n            if current_time &gt;= time_str:\n                target_replicas = replicas\n\n        if target_replicas and target_replicas != current_replicas:\n            return ScalingDecision(\n                app_name=app_name,\n                current_replicas=current_replicas,\n                target_replicas=target_replicas,\n                reason=f\"Scheduled scaling at {current_time}: {target_replicas} replicas\",\n                confidence=1.0,\n                metadata={\n                    'schedule_time': current_time,\n                    'scaler_type': 'time_based'\n                }\n            )\n\n        return None\n</code></pre>"},{"location":"developer-guide/extensions/#custom-health-check-providers","title":"Custom Health Check Providers","text":""},{"location":"developer-guide/extensions/#health-check-plugin-interface","title":"Health Check Plugin Interface","text":"<pre><code>from dataclasses import dataclass\nfrom enum import Enum\n\nclass HealthStatus(Enum):\n    \"\"\"Health check status values.\"\"\"\n    HEALTHY = \"healthy\"\n    UNHEALTHY = \"unhealthy\"\n    UNKNOWN = \"unknown\"\n\n@dataclass\nclass HealthCheckResult:\n    \"\"\"Health check result.\"\"\"\n    status: HealthStatus\n    response_time_ms: float\n    message: str\n    details: Dict[str, Any]\n    timestamp: float\n\nclass HealthCheckProvider(Plugin):\n    \"\"\"Base class for custom health check providers.\"\"\"\n\n    @abstractmethod\n    async def check_health(self, instance: 'InstanceRecord') -&gt; HealthCheckResult:\n        \"\"\"Perform health check on an instance.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_protocol(self) -&gt; str:\n        \"\"\"Return the protocol this provider handles.\"\"\"\n        pass\n\n# Example: gRPC health check provider\nclass GRPCHealthCheckPlugin(HealthCheckProvider):\n    \"\"\"gRPC health check implementation.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.timeout = config.get('timeout', 5.0)\n        self.service_name = config.get('service_name', '')\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize gRPC client.\"\"\"\n        try:\n            import grpc\n            from grpc_health.v1 import health_pb2, health_pb2_grpc\n            self.grpc = grpc\n            self.health_pb2 = health_pb2\n            self.health_pb2_grpc = health_pb2_grpc\n            return True\n        except ImportError as e:\n            self.logger.error(f\"gRPC libraries not available: {e}\")\n            return False\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"No cleanup needed.\"\"\"\n        pass\n\n    def get_protocol(self) -&gt; str:\n        \"\"\"Return protocol name.\"\"\"\n        return \"grpc\"\n\n    async def check_health(self, instance) -&gt; HealthCheckResult:\n        \"\"\"Perform gRPC health check.\"\"\"\n        start_time = time.time()\n\n        try:\n            # Create gRPC channel\n            channel = self.grpc.aio.insecure_channel(f\"{instance.ip}:{instance.port}\")\n            stub = self.health_pb2_grpc.HealthStub(channel)\n\n            # Create health check request\n            request = self.health_pb2.HealthCheckRequest(service=self.service_name)\n\n            # Perform health check with timeout\n            response = await asyncio.wait_for(\n                stub.Check(request),\n                timeout=self.timeout\n            )\n\n            response_time = (time.time() - start_time) * 1000\n\n            # Map gRPC health status to our status\n            if response.status == self.health_pb2.HealthCheckResponse.SERVING:\n                status = HealthStatus.HEALTHY\n                message = \"Service is serving\"\n            else:\n                status = HealthStatus.UNHEALTHY\n                message = f\"Service status: {response.status}\"\n\n            await channel.close()\n\n            return HealthCheckResult(\n                status=status,\n                response_time_ms=response_time,\n                message=message,\n                details={\n                    'grpc_status': response.status,\n                    'service_name': self.service_name\n                },\n                timestamp=time.time()\n            )\n\n        except asyncio.TimeoutError:\n            return HealthCheckResult(\n                status=HealthStatus.UNHEALTHY,\n                response_time_ms=(time.time() - start_time) * 1000,\n                message=\"Health check timeout\",\n                details={'error': 'timeout'},\n                timestamp=time.time()\n            )\n        except Exception as e:\n            return HealthCheckResult(\n                status=HealthStatus.UNHEALTHY,\n                response_time_ms=(time.time() - start_time) * 1000,\n                message=f\"Health check failed: {str(e)}\",\n                details={'error': str(e)},\n                timestamp=time.time()\n            )\n\n# Example: Redis health check provider\nclass RedisHealthCheckPlugin(HealthCheckProvider):\n    \"\"\"Redis-based health check for applications using Redis.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.redis_url = config.get('redis_url', 'redis://localhost:6379')\n        self.key_prefix = config.get('key_prefix', 'health:')\n        self.redis_client = None\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize Redis connection.\"\"\"\n        try:\n            import aioredis\n            self.redis_client = aioredis.from_url(self.redis_url)\n            await self.redis_client.ping()\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to connect to Redis: {e}\")\n            return False\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"Clean up Redis connection.\"\"\"\n        if self.redis_client:\n            await self.redis_client.close()\n\n    def get_protocol(self) -&gt; str:\n        \"\"\"Return protocol name.\"\"\"\n        return \"redis\"\n\n    async def check_health(self, instance) -&gt; HealthCheckResult:\n        \"\"\"Check health by looking up status in Redis.\"\"\"\n        start_time = time.time()\n\n        try:\n            # Look up health status in Redis\n            health_key = f\"{self.key_prefix}{instance.app_name}:{instance.container_id}\"\n            status_data = await self.redis_client.get(health_key)\n\n            response_time = (time.time() - start_time) * 1000\n\n            if status_data:\n                status_info = json.loads(status_data)\n                last_update = status_info.get('timestamp', 0)\n\n                # Check if status is recent (within last 60 seconds)\n                if time.time() - last_update &lt; 60:\n                    status = HealthStatus.HEALTHY if status_info.get('healthy', False) else HealthStatus.UNHEALTHY\n                    message = status_info.get('message', 'Redis health check')\n                else:\n                    status = HealthStatus.UNKNOWN\n                    message = \"Stale health data in Redis\"\n            else:\n                status = HealthStatus.UNKNOWN\n                message = \"No health data found in Redis\"\n\n            return HealthCheckResult(\n                status=status,\n                response_time_ms=response_time,\n                message=message,\n                details={'redis_key': health_key},\n                timestamp=time.time()\n            )\n\n        except Exception as e:\n            return HealthCheckResult(\n                status=HealthStatus.UNHEALTHY,\n                response_time_ms=(time.time() - start_time) * 1000,\n                message=f\"Redis health check failed: {str(e)}\",\n                details={'error': str(e)},\n                timestamp=time.time()\n            )\n</code></pre>"},{"location":"developer-guide/extensions/#metrics-exporters","title":"Metrics Exporters","text":""},{"location":"developer-guide/extensions/#metrics-plugin-interface","title":"Metrics Plugin Interface","text":"<pre><code>class MetricsExporter(Plugin):\n    \"\"\"Base class for metrics exporters.\"\"\"\n\n    @abstractmethod\n    async def export_metrics(self, metrics: List[Dict[str, Any]]) -&gt; bool:\n        \"\"\"Export metrics to external system.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_supported_formats(self) -&gt; List[str]:\n        \"\"\"Return list of supported metric formats.\"\"\"\n        pass\n\n# Example: Prometheus exporter\nclass PrometheusExporterPlugin(MetricsExporter):\n    \"\"\"Export metrics to Prometheus.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.gateway_url = config.get('gateway_url', 'http://localhost:9091')\n        self.job_name = config.get('job_name', 'orchestry')\n        self.instance_id = config.get('instance_id', 'orchestry-controller')\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize Prometheus client.\"\"\"\n        try:\n            from prometheus_client import CollectorRegistry, Gauge, Counter, push_to_gateway\n            self.registry = CollectorRegistry()\n            self.push_to_gateway = push_to_gateway\n\n            # Create metric objects\n            self.metrics = {\n                'app_replicas': Gauge('orchestry_app_replicas', 'Number of replicas', ['app_name'], registry=self.registry),\n                'app_healthy_instances': Gauge('orchestry_app_healthy_instances', 'Healthy instances', ['app_name'], registry=self.registry),\n                'app_cpu_percent': Gauge('orchestry_app_cpu_percent', 'CPU usage percentage', ['app_name'], registry=self.registry),\n                'app_memory_percent': Gauge('orchestry_app_memory_percent', 'Memory usage percentage', ['app_name'], registry=self.registry),\n                'app_rps': Gauge('orchestry_app_rps', 'Requests per second', ['app_name'], registry=self.registry),\n                'scaling_events': Counter('orchestry_scaling_events_total', 'Scaling events', ['app_name', 'direction'], registry=self.registry),\n                'health_check_failures': Counter('orchestry_health_check_failures_total', 'Health check failures', ['app_name'], registry=self.registry)\n            }\n\n            return True\n        except ImportError as e:\n            self.logger.error(f\"Prometheus client not available: {e}\")\n            return False\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"No cleanup needed.\"\"\"\n        pass\n\n    def get_supported_formats(self) -&gt; List[str]:\n        \"\"\"Supported formats.\"\"\"\n        return ['prometheus']\n\n    async def export_metrics(self, metrics: List[Dict[str, Any]]) -&gt; bool:\n        \"\"\"Export metrics to Prometheus pushgateway.\"\"\"\n        try:\n            # Group metrics by application\n            app_metrics = {}\n            for metric in metrics:\n                app_name = metric.get('app_name')\n                if not app_name:\n                    continue\n\n                if app_name not in app_metrics:\n                    app_metrics[app_name] = {}\n\n                app_metrics[app_name][metric['metric_type']] = metric['value']\n\n            # Update Prometheus metrics\n            for app_name, metric_data in app_metrics.items():\n                for metric_type, value in metric_data.items():\n                    if metric_type == 'replicas':\n                        self.metrics['app_replicas'].labels(app_name=app_name).set(value)\n                    elif metric_type == 'healthy_instances':\n                        self.metrics['app_healthy_instances'].labels(app_name=app_name).set(value)\n                    elif metric_type == 'cpu_percent':\n                        self.metrics['app_cpu_percent'].labels(app_name=app_name).set(value)\n                    elif metric_type == 'memory_percent':\n                        self.metrics['app_memory_percent'].labels(app_name=app_name).set(value)\n                    elif metric_type == 'rps':\n                        self.metrics['app_rps'].labels(app_name=app_name).set(value)\n\n            # Push to gateway\n            self.push_to_gateway(\n                self.gateway_url,\n                job=self.job_name,\n                registry=self.registry,\n                grouping_key={'instance': self.instance_id}\n            )\n\n            return True\n\n        except Exception as e:\n            self.logger.error(f\"Failed to export metrics to Prometheus: {e}\")\n            return False\n\n# Example: InfluxDB exporter\nclass InfluxDBExporterPlugin(MetricsExporter):\n    \"\"\"Export metrics to InfluxDB.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.url = config.get('url', 'http://localhost:8086')\n        self.token = config.get('token')\n        self.org = config.get('org')\n        self.bucket = config.get('bucket', 'orchestry')\n        self.client = None\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize InfluxDB client.\"\"\"\n        try:\n            from influxdb_client.client.influxdb_client_async import InfluxDBClientAsync\n            self.client = InfluxDBClientAsync(\n                url=self.url,\n                token=self.token,\n                org=self.org\n            )\n            return True\n        except ImportError as e:\n            self.logger.error(f\"InfluxDB client not available: {e}\")\n            return False\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"Clean up InfluxDB client.\"\"\"\n        if self.client:\n            await self.client.close()\n\n    def get_supported_formats(self) -&gt; List[str]:\n        \"\"\"Supported formats.\"\"\"\n        return ['influxdb']\n\n    async def export_metrics(self, metrics: List[Dict[str, Any]]) -&gt; bool:\n        \"\"\"Export metrics to InfluxDB.\"\"\"\n        try:\n            write_api = self.client.write_api()\n\n            points = []\n            for metric in metrics:\n                # Convert to InfluxDB line protocol\n                point = {\n                    'measurement': metric['metric_type'],\n                    'tags': {\n                        'app_name': metric.get('app_name', ''),\n                        'source': 'orchestry'\n                    },\n                    'fields': {\n                        'value': float(metric['value'])\n                    },\n                    'time': int(metric.get('timestamp', time.time()) * 1000000000)  # nanoseconds\n                }\n\n                # Add additional labels as tags\n                if 'labels' in metric:\n                    point['tags'].update(metric['labels'])\n\n                points.append(point)\n\n            # Write points to InfluxDB\n            await write_api.write(bucket=self.bucket, record=points)\n            return True\n\n        except Exception as e:\n            self.logger.error(f\"Failed to export metrics to InfluxDB: {e}\")\n            return False\n</code></pre>"},{"location":"developer-guide/extensions/#event-handlers","title":"Event Handlers","text":""},{"location":"developer-guide/extensions/#event-handler-plugin-interface","title":"Event Handler Plugin Interface","text":"<pre><code>from enum import Enum\n\nclass EventType(Enum):\n    \"\"\"System event types.\"\"\"\n    APPLICATION_DEPLOYED = \"application_deployed\"\n    APPLICATION_SCALED = \"application_scaled\"\n    APPLICATION_REMOVED = \"application_removed\"\n    INSTANCE_STARTED = \"instance_started\"\n    INSTANCE_STOPPED = \"instance_stopped\"\n    HEALTH_CHECK_FAILED = \"health_check_failed\"\n    SCALING_DECISION = \"scaling_decision\"\n\n@dataclass\nclass SystemEvent:\n    \"\"\"System event data.\"\"\"\n    event_type: EventType\n    app_name: str\n    timestamp: float\n    data: Dict[str, Any]\n    source: str = \"controller\"\n\nclass EventHandler(Plugin):\n    \"\"\"Base class for event handlers.\"\"\"\n\n    @abstractmethod\n    async def handle_event(self, event: SystemEvent) -&gt; None:\n        \"\"\"Handle a system event.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_supported_events(self) -&gt; List[EventType]:\n        \"\"\"Return list of event types this handler supports.\"\"\"\n        pass\n\n# Example: Slack notification handler\nclass SlackNotificationPlugin(EventHandler):\n    \"\"\"Send notifications to Slack for important events.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.webhook_url = config.get('webhook_url')\n        self.channel = config.get('channel', '#alerts')\n        self.severity_levels = config.get('severity_levels', ['error', 'warning'])\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize Slack client.\"\"\"\n        return self.webhook_url is not None\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"No cleanup needed.\"\"\"\n        pass\n\n    def get_supported_events(self) -&gt; List[EventType]:\n        \"\"\"Events we handle.\"\"\"\n        return [\n            EventType.APPLICATION_DEPLOYED,\n            EventType.APPLICATION_SCALED,\n            EventType.HEALTH_CHECK_FAILED,\n            EventType.SCALING_DECISION\n        ]\n\n    async def handle_event(self, event: SystemEvent) -&gt; None:\n        \"\"\"Send Slack notification for event.\"\"\"\n        try:\n            message = self._format_message(event)\n            if message:\n                await self._send_slack_message(message)\n        except Exception as e:\n            self.logger.error(f\"Failed to send Slack notification: {e}\")\n\n    def _format_message(self, event: SystemEvent) -&gt; Optional[str]:\n        \"\"\"Format event as Slack message.\"\"\"\n        if event.event_type == EventType.APPLICATION_DEPLOYED:\n            return f\"\ud83d\ude80 Application `{event.app_name}` deployed successfully\"\n\n        elif event.event_type == EventType.APPLICATION_SCALED:\n            old_replicas = event.data.get('old_replicas', 0)\n            new_replicas = event.data.get('new_replicas', 0)\n            direction = \"up\" if new_replicas &gt; old_replicas else \"down\"\n            return f\"\ud83d\udcc8 Application `{event.app_name}` scaled {direction}: {old_replicas} \u2192 {new_replicas} replicas\"\n\n        elif event.event_type == EventType.HEALTH_CHECK_FAILED:\n            instance_id = event.data.get('instance_id', 'unknown')\n            return f\"\u26a0\ufe0f Health check failed for `{event.app_name}` instance `{instance_id}`\"\n\n        elif event.event_type == EventType.SCALING_DECISION:\n            reason = event.data.get('reason', 'Unknown reason')\n            return f\"\ud83d\udd04 Scaling decision for `{event.app_name}`: {reason}\"\n\n        return None\n\n    async def _send_slack_message(self, message: str) -&gt; None:\n        \"\"\"Send message to Slack.\"\"\"\n        import aiohttp\n\n        payload = {\n            'channel': self.channel,\n            'text': message,\n            'username': 'Orchestry',\n            'icon_emoji': ':robot_face:'\n        }\n\n        async with aiohttp.ClientSession() as session:\n            async with session.post(self.webhook_url, json=payload) as response:\n                if response.status != 200:\n                    self.logger.error(f\"Slack API error: {response.status}\")\n</code></pre>"},{"location":"developer-guide/extensions/#load-balancer-integrations","title":"Load Balancer Integrations","text":""},{"location":"developer-guide/extensions/#load-balancer-plugin-interface","title":"Load Balancer Plugin Interface","text":"<pre><code>class LoadBalancer(Plugin):\n    \"\"\"Base class for load balancer integrations.\"\"\"\n\n    @abstractmethod\n    async def add_upstream(self, app_name: str, instances: List['InstanceRecord']) -&gt; bool:\n        \"\"\"Add upstream configuration for an application.\"\"\"\n        pass\n\n    @abstractmethod\n    async def remove_upstream(self, app_name: str) -&gt; bool:\n        \"\"\"Remove upstream configuration.\"\"\"\n        pass\n\n    @abstractmethod\n    async def update_upstream(self, app_name: str, instances: List['InstanceRecord']) -&gt; bool:\n        \"\"\"Update upstream configuration.\"\"\"\n        pass\n\n    @abstractmethod\n    async def get_upstream_status(self, app_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Get upstream status information.\"\"\"\n        pass\n\n# Example: HAProxy integration\nclass HAProxyPlugin(LoadBalancer):\n    \"\"\"HAProxy load balancer integration.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        super().__init__(config)\n        self.config_path = config.get('config_path', '/etc/haproxy/haproxy.cfg')\n        self.stats_url = config.get('stats_url', 'http://localhost:8404/stats')\n        self.reload_command = config.get('reload_command', 'systemctl reload haproxy')\n\n    async def initialize(self) -&gt; bool:\n        \"\"\"Initialize HAProxy integration.\"\"\"\n        # Check if HAProxy is available\n        try:\n            import subprocess\n            result = subprocess.run(['haproxy', '-v'], capture_output=True)\n            return result.returncode == 0\n        except FileNotFoundError:\n            self.logger.error(\"HAProxy not found\")\n            return False\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"No cleanup needed.\"\"\"\n        pass\n\n    async def add_upstream(self, app_name: str, instances: List['InstanceRecord']) -&gt; bool:\n        \"\"\"Add HAProxy backend for application.\"\"\"\n        try:\n            config = await self._generate_backend_config(app_name, instances)\n            await self._update_haproxy_config(app_name, config)\n            await self._reload_haproxy()\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to add HAProxy upstream: {e}\")\n            return False\n\n    async def remove_upstream(self, app_name: str) -&gt; bool:\n        \"\"\"Remove HAProxy backend.\"\"\"\n        try:\n            await self._remove_backend_config(app_name)\n            await self._reload_haproxy()\n            return True\n        except Exception as e:\n            self.logger.error(f\"Failed to remove HAProxy upstream: {e}\")\n            return False\n\n    async def update_upstream(self, app_name: str, instances: List['InstanceRecord']) -&gt; bool:\n        \"\"\"Update HAProxy backend.\"\"\"\n        return await self.add_upstream(app_name, instances)\n\n    async def get_upstream_status(self, app_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Get HAProxy backend status.\"\"\"\n        try:\n            import aiohttp\n            async with aiohttp.ClientSession() as session:\n                async with session.get(f\"{self.stats_url};csv\") as response:\n                    csv_data = await response.text()\n                    return self._parse_haproxy_stats(csv_data, app_name)\n        except Exception as e:\n            self.logger.error(f\"Failed to get HAProxy status: {e}\")\n            return {}\n\n    async def _generate_backend_config(self, app_name: str, instances: List['InstanceRecord']) -&gt; str:\n        \"\"\"Generate HAProxy backend configuration.\"\"\"\n        config_lines = [\n            f\"backend {app_name}_backend\",\n            \"    balance roundrobin\",\n            \"    option httpchk GET /health\"\n        ]\n\n        for i, instance in enumerate(instances):\n            if instance.status == 'running' and instance.health_status == 'healthy':\n                config_lines.append(\n                    f\"    server {app_name}-{i} {instance.ip}:{instance.port} check\"\n                )\n\n        return '\\n'.join(config_lines)\n</code></pre>"},{"location":"developer-guide/extensions/#plugin-configuration","title":"Plugin Configuration","text":""},{"location":"developer-guide/extensions/#configuration-management","title":"Configuration Management","text":"<pre><code># Plugin configuration in main Orchestry config\nPLUGIN_CONFIG = {\n    'plugins': {\n        'ml_scaler': {\n            'enabled': True,\n            'model_path': '/opt/orchestry/models/scaling_model.pkl',\n            'prediction_window': 300,\n            'confidence_threshold': 0.7\n        },\n        'prometheus_exporter': {\n            'enabled': True,\n            'gateway_url': 'http://localhost:9091',\n            'job_name': 'orchestry',\n            'export_interval': 30\n        },\n        'slack_notifications': {\n            'enabled': True,\n            'webhook_url': 'https://hooks.slack.com/services/...',\n            'channel': '#orchestry-alerts',\n            'severity_levels': ['error', 'warning']\n        },\n        'grpc_health_check': {\n            'enabled': True,\n            'timeout': 5.0,\n            'service_name': 'health'\n        }\n    }\n}\n\nclass ExtensibleController:\n    \"\"\"Controller with plugin support.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.plugin_manager = PluginManager()\n        self.custom_scalers: List[CustomScaler] = []\n        self.health_check_providers: Dict[str, HealthCheckProvider] = {}\n        self.metrics_exporters: List[MetricsExporter] = []\n        self.event_handlers: List[EventHandler] = []\n\n    async def initialize_plugins(self):\n        \"\"\"Initialize all configured plugins.\"\"\"\n        plugin_configs = self.config.get('plugins', {})\n\n        for plugin_name, plugin_config in plugin_configs.items():\n            if plugin_config.get('enabled', False):\n                try:\n                    await self.plugin_manager.load_plugin(plugin_name, plugin_config)\n                    plugin = self.plugin_manager.get_plugin(plugin_name)\n\n                    # Register plugin with appropriate manager\n                    if isinstance(plugin, CustomScaler):\n                        self.custom_scalers.append(plugin)\n                    elif isinstance(plugin, HealthCheckProvider):\n                        self.health_check_providers[plugin.get_protocol()] = plugin\n                    elif isinstance(plugin, MetricsExporter):\n                        self.metrics_exporters.append(plugin)\n                    elif isinstance(plugin, EventHandler):\n                        self.event_handlers.append(plugin)\n\n                except Exception as e:\n                    logging.error(f\"Failed to load plugin {plugin_name}: {e}\")\n\n    async def emit_event(self, event: SystemEvent):\n        \"\"\"Emit event to all registered handlers.\"\"\"\n        for handler in self.event_handlers:\n            if event.event_type in handler.get_supported_events():\n                try:\n                    await handler.handle_event(event)\n                except Exception as e:\n                    logging.error(f\"Event handler error: {e}\")\n\n    async def export_metrics(self, metrics: List[Dict[str, Any]]):\n        \"\"\"Export metrics using all registered exporters.\"\"\"\n        for exporter in self.metrics_exporters:\n            try:\n                await exporter.export_metrics(metrics)\n            except Exception as e:\n                logging.error(f\"Metrics export error: {e}\")\n</code></pre> <p>This completes the comprehensive Orchestry documentation! The documentation now covers:</p>"},{"location":"developer-guide/extensions/#summary-of-documentation-created","title":"Summary of Documentation Created","text":""},{"location":"developer-guide/extensions/#user-guide-docsuser-guide","title":"User Guide (<code>docs/user-guide/</code>)","text":"<ol> <li>Quick Start - Get up and running quickly</li> <li>CLI Reference - Complete command-line interface documentation  </li> <li>Application Specification - YAML/JSON app configuration format</li> <li>API Reference - REST API endpoints and usage</li> <li>Configuration - System configuration options</li> <li>Troubleshooting - Common issues and solutions</li> </ol>"},{"location":"developer-guide/extensions/#developer-guide-docsdeveloper-guide","title":"Developer Guide (<code>docs/developer-guide/</code>)","text":"<ol> <li>Architecture - System design and component overview</li> <li>Components - Detailed component documentation</li> <li>Scaling - Auto-scaling algorithms and implementation</li> <li>Database - Schema, queries, and data management</li> <li>Health Monitoring - Health checks and failure detection</li> <li>Load Balancing - Nginx integration and traffic management</li> <li>Development - Development environment and workflows</li> <li>Extensions - Plugin system and extensibility</li> </ol>"},{"location":"developer-guide/extensions/#examples-docsexamples","title":"Examples (<code>docs/examples/</code>)","text":"<ol> <li>Applications - Sample application configurations</li> </ol>"},{"location":"developer-guide/extensions/#main-documentation-docs","title":"Main Documentation (<code>docs/</code>)","text":"<ol> <li>README.md - Documentation overview and navigation</li> </ol> <p>This documentation provides comprehensive coverage for both users wanting to deploy applications and developers wanting to understand or extend Orchestry's functionality. It includes practical examples, troubleshooting guides, and detailed technical implementation information suitable for deployment and ongoing maintenance.</p>"},{"location":"developer-guide/health/","title":"Health Monitoring System","text":"<p>Complete documentation of Orchestry's health monitoring system, including health checks, failure detection, and recovery mechanisms.</p>"},{"location":"developer-guide/health/#overview","title":"Overview","text":"<p>Orchestry's health monitoring system ensures application reliability through:</p> <ul> <li>Proactive Health Checks: Regular HTTP/TCP health probes</li> <li>Failure Detection: Multi-level failure tracking and classification</li> <li>Automatic Recovery: Self-healing mechanisms for common issues</li> <li>Circuit Breaking: Protection against cascading failures</li> <li>Performance Monitoring: Real-time performance metrics collection</li> <li>Alerting Integration: Configurable notifications and escalation</li> </ul>"},{"location":"developer-guide/health/#system-architecture","title":"System Architecture","text":""},{"location":"developer-guide/health/#health-check-flow","title":"Health Check Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Health Checker    \u2502    \u2502   Instance Manager  \u2502    \u2502   Load Balancer     \u2502\n\u2502                     \u2502    \u2502                     \u2502    \u2502                     \u2502\n\u2502  \u2022 Periodic probes  \u2502\u2500\u2500\u2500\u25ba\u2502  \u2022 Status tracking  \u2502\u2500\u2500\u2500\u25ba\u2502  \u2022 Traffic routing  \u2502\n\u2502  \u2022 Failure tracking \u2502    \u2502  \u2022 Recovery actions \u2502    \u2502  \u2022 Health-based LB  \u2502\n\u2502  \u2022 Status updates   \u2502    \u2502  \u2022 Event logging    \u2502    \u2502  \u2022 Circuit breaking \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502                           \u2502                           \u2502\n           \u25bc                           \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           Database (State Persistence)                      \u2502\n\u2502  \u2022 Health status          \u2022 Failure counts         \u2022 Recovery attempts      \u2502\n\u2502  \u2022 Check history         \u2022 Performance metrics    \u2022 Configuration           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/health/#component-integration","title":"Component Integration","text":"<pre><code>class HealthMonitoringSystem:\n    \"\"\"Orchestrates all health monitoring components.\"\"\"\n\n    def __init__(self):\n        self.health_checker = HealthChecker()\n        self.failure_detector = FailureDetector()\n        self.recovery_manager = RecoveryManager()\n        self.circuit_breaker = CircuitBreaker()\n        self.metrics_collector = MetricsCollector()\n\n    async def monitor_application(self, app_name: str):\n        \"\"\"Main monitoring loop for an application.\"\"\"\n        while True:\n            try:\n                # Collect health status from all instances\n                health_results = await self.health_checker.check_all_instances(app_name)\n\n                # Detect and classify failures\n                failures = await self.failure_detector.analyze_results(health_results)\n\n                # Trigger recovery actions if needed\n                if failures:\n                    await self.recovery_manager.handle_failures(failures)\n\n                # Update circuit breaker states\n                await self.circuit_breaker.update_states(health_results)\n\n                # Collect performance metrics\n                await self.metrics_collector.collect_app_metrics(app_name)\n\n                await asyncio.sleep(self.config.health_check_interval)\n\n            except Exception as e:\n                logger.error(f\"Health monitoring error for {app_name}: {e}\")\n                await asyncio.sleep(self.config.error_retry_interval)\n</code></pre>"},{"location":"developer-guide/health/#health-check-implementation","title":"Health Check Implementation","text":""},{"location":"developer-guide/health/#http-health-checks","title":"HTTP Health Checks","text":"<pre><code>class HTTPHealthChecker:\n    \"\"\"HTTP-based health check implementation.\"\"\"\n\n    def __init__(self, config: HealthCheckConfig):\n        self.config = config\n        self.session = None\n        self.timeout = aiohttp.ClientTimeout(total=config.timeout_seconds)\n\n    async def initialize(self):\n        \"\"\"Initialize HTTP session with proper configuration.\"\"\"\n        connector = aiohttp.TCPConnector(\n            limit=100,                    # Connection pool limit\n            limit_per_host=20,           # Per-host connection limit  \n            ttl_dns_cache=300,           # DNS cache TTL\n            use_dns_cache=True,          # Enable DNS caching\n            keepalive_timeout=30,        # Keep connections alive\n            enable_cleanup_closed=True    # Clean up closed connections\n        )\n\n        self.session = aiohttp.ClientSession(\n            connector=connector,\n            timeout=self.timeout,\n            headers={\n                'User-Agent': 'Orchestry-HealthChecker/1.0',\n                'Accept': 'application/json, text/plain, */*'\n            }\n        )\n\n    async def check_instance(self, instance: InstanceRecord) -&gt; HealthCheckResult:\n        \"\"\"Perform HTTP health check on a single instance.\"\"\"\n        start_time = time.time()\n\n        try:\n            # Build health check URL\n            url = f\"http://{instance.ip}:{instance.port}{self.config.path}\"\n\n            # Prepare request\n            headers = self.config.headers.copy() if self.config.headers else {}\n\n            # Add custom health check headers\n            headers.update({\n                'X-Health-Check': 'true',\n                'X-Instance-ID': instance.container_id[:12],\n                'X-App-Name': instance.app_name\n            })\n\n            # Perform request\n            async with self.session.request(\n                method=self.config.method,\n                url=url,\n                headers=headers,\n                data=self.config.body if self.config.body else None,\n                ssl=False  # Internal network, no SSL needed\n            ) as response:\n\n                response_time = (time.time() - start_time) * 1000  # Convert to milliseconds\n                response_text = await response.text()\n\n                # Check if status code is expected\n                is_healthy = response.status in self.config.expected_status_codes\n\n                return HealthCheckResult(\n                    instance_id=instance.container_id,\n                    app_name=instance.app_name,\n                    check_type='http',\n                    is_healthy=is_healthy,\n                    response_time_ms=response_time,\n                    status_code=response.status,\n                    response_body=response_text[:1000],  # Limit response size\n                    headers=dict(response.headers),\n                    timestamp=time.time(),\n                    error=None if is_healthy else f\"Unexpected status code: {response.status}\"\n                )\n\n        except asyncio.TimeoutError:\n            return HealthCheckResult(\n                instance_id=instance.container_id,\n                app_name=instance.app_name,\n                check_type='http',\n                is_healthy=False,\n                response_time_ms=(time.time() - start_time) * 1000,\n                timestamp=time.time(),\n                error=\"Request timeout\"\n            )\n\n        except aiohttp.ClientError as e:\n            return HealthCheckResult(\n                instance_id=instance.container_id,\n                app_name=instance.app_name,\n                check_type='http',\n                is_healthy=False,\n                response_time_ms=(time.time() - start_time) * 1000,\n                timestamp=time.time(),\n                error=f\"Client error: {str(e)}\"\n            )\n\n        except Exception as e:\n            return HealthCheckResult(\n                instance_id=instance.container_id,\n                app_name=instance.app_name,\n                check_type='http',\n                is_healthy=False,\n                response_time_ms=(time.time() - start_time) * 1000,\n                timestamp=time.time(),\n                error=f\"Unexpected error: {str(e)}\"\n            )\n</code></pre>"},{"location":"developer-guide/health/#tcp-health-checks","title":"TCP Health Checks","text":"<pre><code>class TCPHealthChecker:\n    \"\"\"TCP-based health check implementation.\"\"\"\n\n    async def check_instance(self, instance: InstanceRecord) -&gt; HealthCheckResult:\n        \"\"\"Perform TCP health check on a single instance.\"\"\"\n        start_time = time.time()\n\n        try:\n            # Create TCP connection\n            future = asyncio.open_connection(\n                host=instance.ip,\n                port=instance.port\n            )\n\n            # Apply timeout\n            reader, writer = await asyncio.wait_for(\n                future, \n                timeout=self.config.timeout_seconds\n            )\n\n            response_time = (time.time() - start_time) * 1000\n\n            # Optional: Send custom probe data\n            if self.config.probe_data:\n                writer.write(self.config.probe_data.encode())\n                await writer.drain()\n\n                # Read response if expected\n                if self.config.expected_response:\n                    response = await asyncio.wait_for(\n                        reader.read(1024),\n                        timeout=2.0\n                    )\n\n                    if self.config.expected_response.encode() not in response:\n                        writer.close()\n                        await writer.wait_closed()\n                        return HealthCheckResult(\n                            instance_id=instance.container_id,\n                            app_name=instance.app_name,\n                            check_type='tcp',\n                            is_healthy=False,\n                            response_time_ms=response_time,\n                            timestamp=time.time(),\n                            error=\"Unexpected response content\"\n                        )\n\n            # Close connection\n            writer.close()\n            await writer.wait_closed()\n\n            return HealthCheckResult(\n                instance_id=instance.container_id,\n                app_name=instance.app_name,\n                check_type='tcp',\n                is_healthy=True,\n                response_time_ms=response_time,\n                timestamp=time.time(),\n                error=None\n            )\n\n        except asyncio.TimeoutError:\n            return HealthCheckResult(\n                instance_id=instance.container_id,\n                app_name=instance.app_name,\n                check_type='tcp',\n                is_healthy=False,\n                response_time_ms=(time.time() - start_time) * 1000,\n                timestamp=time.time(),\n                error=\"Connection timeout\"\n            )\n\n        except Exception as e:\n            return HealthCheckResult(\n                instance_id=instance.container_id,\n                app_name=instance.app_name,\n                check_type='tcp',\n                is_healthy=False,\n                response_time_ms=(time.time() - start_time) * 1000,\n                timestamp=time.time(),\n                error=f\"Connection error: {str(e)}\"\n            )\n</code></pre>"},{"location":"developer-guide/health/#health-check-configuration","title":"Health Check Configuration","text":"<pre><code>@dataclass\nclass HealthCheckConfig:\n    \"\"\"Health check configuration.\"\"\"\n\n    # Protocol configuration\n    protocol: str = 'HTTP'                    # 'HTTP' or 'TCP'\n    path: str = '/health'                     # HTTP path\n    port: int = 8000                          # Target port\n    method: str = 'GET'                       # HTTP method\n    headers: Optional[Dict[str, str]] = None  # HTTP headers\n    body: Optional[str] = None                # Request body\n    expected_status_codes: List[int] = field(default_factory=lambda: [200])\n\n    # TCP-specific configuration\n    probe_data: Optional[str] = None          # Data to send for TCP probes\n    expected_response: Optional[str] = None   # Expected TCP response\n\n    # Timing configuration\n    initial_delay_seconds: int = 30           # Wait before first check\n    period_seconds: int = 30                  # Interval between checks\n    timeout_seconds: int = 5                  # Request timeout\n    failure_threshold: int = 3                # Failures before marking unhealthy\n    success_threshold: int = 1                # Successes before marking healthy\n\n    # Advanced configuration\n    enabled: bool = True                      # Enable/disable health checks\n    follow_redirects: bool = False            # Follow HTTP redirects\n    verify_ssl: bool = True                   # Verify SSL certificates\n    max_retries: int = 0                      # Number of retries on failure\n\n    def validate(self) -&gt; List[str]:\n        \"\"\"Validate configuration and return list of errors.\"\"\"\n        errors = []\n\n        if self.protocol not in ['HTTP', 'TCP']:\n            errors.append(\"Protocol must be 'HTTP' or 'TCP'\")\n\n        if self.port &lt; 1 or self.port &gt; 65535:\n            errors.append(\"Port must be between 1 and 65535\")\n\n        if self.timeout_seconds &lt; 1:\n            errors.append(\"Timeout must be at least 1 second\")\n\n        if self.period_seconds &lt; self.timeout_seconds:\n            errors.append(\"Period must be greater than timeout\")\n\n        if self.failure_threshold &lt; 1:\n            errors.append(\"Failure threshold must be at least 1\")\n\n        if self.success_threshold &lt; 1:\n            errors.append(\"Success threshold must be at least 1\")\n\n        if self.protocol == 'HTTP':\n            if not self.path.startswith('/'):\n                errors.append(\"HTTP path must start with '/'\")\n\n            if self.method not in ['GET', 'POST', 'PUT', 'HEAD']:\n                errors.append(\"HTTP method must be GET, POST, PUT, or HEAD\")\n\n        return errors\n</code></pre>"},{"location":"developer-guide/health/#failure-detection-and-classification","title":"Failure Detection and Classification","text":""},{"location":"developer-guide/health/#failure-types","title":"Failure Types","text":"<pre><code>class FailureType(Enum):\n    \"\"\"Types of failures that can be detected.\"\"\"\n\n    # Health check failures\n    HEALTH_CHECK_FAILED = \"health_check_failed\"\n    HEALTH_CHECK_TIMEOUT = \"health_check_timeout\"\n    HEALTH_CHECK_ERROR = \"health_check_error\"\n\n    # Performance failures\n    HIGH_RESPONSE_TIME = \"high_response_time\"\n    HIGH_ERROR_RATE = \"high_error_rate\"\n    HIGH_RESOURCE_USAGE = \"high_resource_usage\"\n\n    # Container failures\n    CONTAINER_STOPPED = \"container_stopped\"\n    CONTAINER_RESTART_LOOP = \"container_restart_loop\"\n    CONTAINER_OOM_KILLED = \"container_oom_killed\"\n\n    # Network failures\n    NETWORK_UNREACHABLE = \"network_unreachable\"\n    PORT_NOT_LISTENING = \"port_not_listening\"\n    DNS_RESOLUTION_FAILED = \"dns_resolution_failed\"\n\n    # Application failures\n    APPLICATION_STARTUP_FAILED = \"application_startup_failed\"\n    APPLICATION_DEADLOCK = \"application_deadlock\"\n    APPLICATION_MEMORY_LEAK = \"application_memory_leak\"\n\n@dataclass\nclass FailureEvent:\n    \"\"\"Represents a detected failure.\"\"\"\n\n    failure_type: FailureType\n    instance_id: str\n    app_name: str\n    severity: str                    # 'low', 'medium', 'high', 'critical'\n    message: str\n    details: Dict[str, Any]\n    timestamp: float\n    consecutive_count: int = 1       # Number of consecutive failures\n    total_count: int = 1             # Total failures in time window\n    first_occurrence: Optional[float] = None\n\n    def is_critical(self) -&gt; bool:\n        \"\"\"Check if this is a critical failure requiring immediate action.\"\"\"\n        critical_types = {\n            FailureType.CONTAINER_STOPPED,\n            FailureType.CONTAINER_OOM_KILLED,\n            FailureType.APPLICATION_STARTUP_FAILED\n        }\n        return (self.failure_type in critical_types or \n                self.severity == 'critical' or \n                self.consecutive_count &gt;= 5)\n</code></pre>"},{"location":"developer-guide/health/#failure-detector-implementation","title":"Failure Detector Implementation","text":"<pre><code>class FailureDetector:\n    \"\"\"Detects and classifies various types of failures.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.failure_history: Dict[str, List[FailureEvent]] = {}\n        self.thresholds = self._load_thresholds()\n\n    def _load_thresholds(self) -&gt; Dict[str, Any]:\n        \"\"\"Load failure detection thresholds.\"\"\"\n        return {\n            'max_response_time_ms': self.config.get('max_response_time_ms', 5000),\n            'max_error_rate_percent': self.config.get('max_error_rate_percent', 5.0),\n            'max_cpu_percent': self.config.get('max_cpu_percent', 90.0),\n            'max_memory_percent': self.config.get('max_memory_percent', 90.0),\n            'consecutive_failure_limit': self.config.get('consecutive_failure_limit', 3),\n            'failure_rate_window_minutes': self.config.get('failure_rate_window_minutes', 10),\n            'max_restart_count': self.config.get('max_restart_count', 5)\n        }\n\n    async def analyze_health_result(self, result: HealthCheckResult) -&gt; List[FailureEvent]:\n        \"\"\"Analyze a health check result for failures.\"\"\"\n        failures = []\n\n        if not result.is_healthy:\n            # Classify the type of failure\n            failure_type = self._classify_health_failure(result)\n\n            # Determine severity\n            severity = self._determine_severity(result, failure_type)\n\n            # Create failure event\n            failure = FailureEvent(\n                failure_type=failure_type,\n                instance_id=result.instance_id,\n                app_name=result.app_name,\n                severity=severity,\n                message=self._generate_failure_message(result, failure_type),\n                details={\n                    'response_time_ms': result.response_time_ms,\n                    'status_code': result.status_code,\n                    'error': result.error,\n                    'check_type': result.check_type\n                },\n                timestamp=result.timestamp\n            )\n\n            # Track consecutive failures\n            failure = self._track_consecutive_failures(failure)\n            failures.append(failure)\n\n        # Check for performance-related failures\n        if result.response_time_ms &gt; self.thresholds['max_response_time_ms']:\n            failures.append(FailureEvent(\n                failure_type=FailureType.HIGH_RESPONSE_TIME,\n                instance_id=result.instance_id,\n                app_name=result.app_name,\n                severity='medium',\n                message=f\"High response time: {result.response_time_ms:.0f}ms\",\n                details={'response_time_ms': result.response_time_ms, 'threshold': self.thresholds['max_response_time_ms']},\n                timestamp=result.timestamp\n            ))\n\n        return failures\n\n    def _classify_health_failure(self, result: HealthCheckResult) -&gt; FailureType:\n        \"\"\"Classify the type of health check failure.\"\"\"\n        if result.error:\n            if 'timeout' in result.error.lower():\n                return FailureType.HEALTH_CHECK_TIMEOUT\n            elif 'connection' in result.error.lower():\n                return FailureType.NETWORK_UNREACHABLE\n            elif 'dns' in result.error.lower():\n                return FailureType.DNS_RESOLUTION_FAILED\n            else:\n                return FailureType.HEALTH_CHECK_ERROR\n        else:\n            return FailureType.HEALTH_CHECK_FAILED\n\n    def _determine_severity(self, result: HealthCheckResult, failure_type: FailureType) -&gt; str:\n        \"\"\"Determine the severity of a failure.\"\"\"\n        # Critical failures\n        if failure_type in [FailureType.CONTAINER_STOPPED, FailureType.CONTAINER_OOM_KILLED]:\n            return 'critical'\n\n        # High severity failures\n        if failure_type in [FailureType.APPLICATION_STARTUP_FAILED, FailureType.CONTAINER_RESTART_LOOP]:\n            return 'high'\n\n        # Medium severity failures\n        if failure_type in [FailureType.HEALTH_CHECK_TIMEOUT, FailureType.HIGH_RESPONSE_TIME]:\n            return 'medium'\n\n        # Default to low severity\n        return 'low'\n\n    def _track_consecutive_failures(self, failure: FailureEvent) -&gt; FailureEvent:\n        \"\"\"Track consecutive failures for an instance.\"\"\"\n        instance_key = f\"{failure.app_name}:{failure.instance_id}\"\n\n        if instance_key not in self.failure_history:\n            self.failure_history[instance_key] = []\n\n        history = self.failure_history[instance_key]\n\n        # Clean up old failures (outside time window)\n        cutoff_time = failure.timestamp - (self.thresholds['failure_rate_window_minutes'] * 60)\n        history = [f for f in history if f.timestamp &gt; cutoff_time]\n\n        # Count consecutive failures of the same type\n        consecutive = 1\n        for prev_failure in reversed(history):\n            if prev_failure.failure_type == failure.failure_type:\n                consecutive += 1\n            else:\n                break\n\n        failure.consecutive_count = consecutive\n        failure.total_count = len([f for f in history if f.failure_type == failure.failure_type]) + 1\n\n        if history:\n            failure.first_occurrence = history[0].timestamp\n        else:\n            failure.first_occurrence = failure.timestamp\n\n        # Add to history\n        history.append(failure)\n        self.failure_history[instance_key] = history\n\n        return failure\n\n    async def analyze_container_metrics(self, instance: InstanceRecord) -&gt; List[FailureEvent]:\n        \"\"\"Analyze container metrics for resource-related failures.\"\"\"\n        failures = []\n\n        # Check CPU usage\n        if instance.cpu_percent &gt; self.thresholds['max_cpu_percent']:\n            failures.append(FailureEvent(\n                failure_type=FailureType.HIGH_RESOURCE_USAGE,\n                instance_id=instance.container_id,\n                app_name=instance.app_name,\n                severity='medium',\n                message=f\"High CPU usage: {instance.cpu_percent:.1f}%\",\n                details={\n                    'cpu_percent': instance.cpu_percent,\n                    'threshold': self.thresholds['max_cpu_percent'],\n                    'metric': 'cpu'\n                },\n                timestamp=time.time()\n            ))\n\n        # Check memory usage\n        if instance.memory_percent &gt; self.thresholds['max_memory_percent']:\n            failures.append(FailureEvent(\n                failure_type=FailureType.HIGH_RESOURCE_USAGE,\n                instance_id=instance.container_id,\n                app_name=instance.app_name,\n                severity='high' if instance.memory_percent &gt; 95 else 'medium',\n                message=f\"High memory usage: {instance.memory_percent:.1f}%\",\n                details={\n                    'memory_percent': instance.memory_percent,\n                    'memory_bytes': instance.memory_usage_bytes,\n                    'threshold': self.thresholds['max_memory_percent'],\n                    'metric': 'memory'\n                },\n                timestamp=time.time()\n            ))\n\n        return failures\n</code></pre>"},{"location":"developer-guide/health/#recovery-management","title":"Recovery Management","text":""},{"location":"developer-guide/health/#recovery-strategies","title":"Recovery Strategies","text":"<pre><code>class RecoveryStrategy(Enum):\n    \"\"\"Available recovery strategies.\"\"\"\n\n    # Container-level recovery\n    RESTART_CONTAINER = \"restart_container\"\n    RECREATE_CONTAINER = \"recreate_container\"\n    REPLACE_INSTANCE = \"replace_instance\"\n\n    # Application-level recovery\n    SCALE_OUT = \"scale_out\"\n    DRAIN_INSTANCE = \"drain_instance\"\n    ROLLING_RESTART = \"rolling_restart\"\n\n    # Traffic management\n    REMOVE_FROM_LB = \"remove_from_lb\"\n    REDIRECT_TRAFFIC = \"redirect_traffic\"\n\n    # System-level recovery\n    CLEAR_CACHE = \"clear_cache\"\n    RESTART_DEPENDENCIES = \"restart_dependencies\"\n    FAILOVER_TO_BACKUP = \"failover_to_backup\"\n\nclass RecoveryManager:\n    \"\"\"Manages automatic recovery actions for failures.\"\"\"\n\n    def __init__(self, app_manager, load_balancer):\n        self.app_manager = app_manager\n        self.load_balancer = load_balancer\n        self.recovery_history: Dict[str, List[RecoveryAction]] = {}\n        self.strategy_map = self._build_strategy_map()\n\n    def _build_strategy_map(self) -&gt; Dict[FailureType, List[RecoveryStrategy]]:\n        \"\"\"Map failure types to recovery strategies (in order of preference).\"\"\"\n        return {\n            FailureType.HEALTH_CHECK_FAILED: [\n                RecoveryStrategy.REMOVE_FROM_LB,\n                RecoveryStrategy.RESTART_CONTAINER,\n                RecoveryStrategy.RECREATE_CONTAINER\n            ],\n            FailureType.HEALTH_CHECK_TIMEOUT: [\n                RecoveryStrategy.REMOVE_FROM_LB,\n                RecoveryStrategy.RESTART_CONTAINER\n            ],\n            FailureType.HIGH_RESPONSE_TIME: [\n                RecoveryStrategy.REMOVE_FROM_LB,\n                RecoveryStrategy.SCALE_OUT,\n                RecoveryStrategy.RESTART_CONTAINER\n            ],\n            FailureType.HIGH_RESOURCE_USAGE: [\n                RecoveryStrategy.SCALE_OUT,\n                RecoveryStrategy.RESTART_CONTAINER,\n                RecoveryStrategy.REPLACE_INSTANCE\n            ],\n            FailureType.CONTAINER_STOPPED: [\n                RecoveryStrategy.RECREATE_CONTAINER,\n                RecoveryStrategy.REPLACE_INSTANCE\n            ],\n            FailureType.CONTAINER_OOM_KILLED: [\n                RecoveryStrategy.REPLACE_INSTANCE,\n                RecoveryStrategy.SCALE_OUT\n            ],\n            FailureType.NETWORK_UNREACHABLE: [\n                RecoveryStrategy.REMOVE_FROM_LB,\n                RecoveryStrategy.RECREATE_CONTAINER\n            ]\n        }\n\n    async def handle_failure(self, failure: FailureEvent) -&gt; List[RecoveryAction]:\n        \"\"\"Handle a detected failure with appropriate recovery actions.\"\"\"\n        strategies = self.strategy_map.get(failure.failure_type, [])\n        actions = []\n\n        for strategy in strategies:\n            # Check if strategy is applicable and hasn't been tried recently\n            if await self._should_apply_strategy(failure, strategy):\n                action = await self._execute_recovery_strategy(failure, strategy)\n                if action:\n                    actions.append(action)\n\n                    # If action was successful, we might not need to try other strategies\n                    if action.success and not self._requires_multiple_strategies(failure.failure_type):\n                        break\n\n        return actions\n\n    async def _should_apply_strategy(self, failure: FailureEvent, strategy: RecoveryStrategy) -&gt; bool:\n        \"\"\"Check if a recovery strategy should be applied.\"\"\"\n        instance_key = f\"{failure.app_name}:{failure.instance_id}\"\n\n        # Get recent recovery history\n        recent_actions = [\n            action for action in self.recovery_history.get(instance_key, [])\n            if action.timestamp &gt; failure.timestamp - 300  # Last 5 minutes\n        ]\n\n        # Check strategy-specific conditions\n        if strategy == RecoveryStrategy.RESTART_CONTAINER:\n            # Don't restart too frequently\n            restart_count = len([a for a in recent_actions if a.strategy == strategy])\n            return restart_count &lt; 3\n\n        elif strategy == RecoveryStrategy.SCALE_OUT:\n            # Only scale out if we haven't recently\n            scale_count = len([a for a in recent_actions if a.strategy == strategy])\n            return scale_count &lt; 1 and failure.consecutive_count &gt;= 2\n\n        elif strategy == RecoveryStrategy.REMOVE_FROM_LB:\n            # Always remove unhealthy instances from load balancer\n            return True\n\n        elif strategy == RecoveryStrategy.RECREATE_CONTAINER:\n            # Recreate if restart didn't work\n            restart_attempts = len([a for a in recent_actions if a.strategy == RecoveryStrategy.RESTART_CONTAINER])\n            return restart_attempts &gt; 0 or failure.failure_type == FailureType.CONTAINER_STOPPED\n\n        return True\n\n    async def _execute_recovery_strategy(self, failure: FailureEvent, strategy: RecoveryStrategy) -&gt; Optional[RecoveryAction]:\n        \"\"\"Execute a specific recovery strategy.\"\"\"\n        start_time = time.time()\n\n        try:\n            if strategy == RecoveryStrategy.RESTART_CONTAINER:\n                success = await self._restart_container(failure.instance_id)\n\n            elif strategy == RecoveryStrategy.RECREATE_CONTAINER:\n                success = await self._recreate_container(failure.app_name, failure.instance_id)\n\n            elif strategy == RecoveryStrategy.REMOVE_FROM_LB:\n                success = await self._remove_from_load_balancer(failure.instance_id)\n\n            elif strategy == RecoveryStrategy.SCALE_OUT:\n                success = await self._scale_out_application(failure.app_name)\n\n            elif strategy == RecoveryStrategy.REPLACE_INSTANCE:\n                success = await self._replace_instance(failure.app_name, failure.instance_id)\n\n            else:\n                logger.warning(f\"Unknown recovery strategy: {strategy}\")\n                return None\n\n            action = RecoveryAction(\n                strategy=strategy,\n                failure_type=failure.failure_type,\n                instance_id=failure.instance_id,\n                app_name=failure.app_name,\n                success=success,\n                timestamp=start_time,\n                duration_ms=(time.time() - start_time) * 1000,\n                details={}\n            )\n\n            # Record the action\n            instance_key = f\"{failure.app_name}:{failure.instance_id}\"\n            if instance_key not in self.recovery_history:\n                self.recovery_history[instance_key] = []\n            self.recovery_history[instance_key].append(action)\n\n            return action\n\n        except Exception as e:\n            logger.error(f\"Recovery strategy {strategy} failed: {e}\")\n            return RecoveryAction(\n                strategy=strategy,\n                failure_type=failure.failure_type,\n                instance_id=failure.instance_id,\n                app_name=failure.app_name,\n                success=False,\n                timestamp=start_time,\n                duration_ms=(time.time() - start_time) * 1000,\n                error=str(e)\n            )\n\n    async def _restart_container(self, container_id: str) -&gt; bool:\n        \"\"\"Restart a specific container.\"\"\"\n        try:\n            # Use Docker API to restart container\n            container = await self.app_manager.docker_client.containers.get(container_id)\n            await container.restart(timeout=30)\n\n            # Wait for container to be running\n            for _ in range(10):  # Wait up to 30 seconds\n                await asyncio.sleep(3)\n                await container.reload()\n                if container.status == 'running':\n                    return True\n\n            return False\n        except Exception as e:\n            logger.error(f\"Failed to restart container {container_id}: {e}\")\n            return False\n\n    async def _recreate_container(self, app_name: str, container_id: str) -&gt; bool:\n        \"\"\"Recreate a container with fresh configuration.\"\"\"\n        try:\n            # Get the application specification\n            app_record = await self.app_manager.db.get_application(app_name)\n            if not app_record:\n                return False\n\n            # Get instance information\n            instance = await self.app_manager.db.get_instance_by_container_id(container_id)\n            if not instance:\n                return False\n\n            # Stop and remove the old container\n            try:\n                container = await self.app_manager.docker_client.containers.get(container_id)\n                await container.stop(timeout=30)\n                await container.remove()\n            except Exception as e:\n                logger.warning(f\"Error removing old container: {e}\")\n\n            # Create new container\n            success = await self.app_manager.create_instance(\n                app_record, \n                instance.replica_index\n            )\n\n            return success\n\n        except Exception as e:\n            logger.error(f\"Failed to recreate container {container_id}: {e}\")\n            return False\n\n    async def _remove_from_load_balancer(self, container_id: str) -&gt; bool:\n        \"\"\"Remove instance from load balancer.\"\"\"\n        try:\n            instance = await self.app_manager.db.get_instance_by_container_id(container_id)\n            if not instance:\n                return False\n\n            # Remove from Nginx upstream\n            await self.load_balancer.remove_upstream(instance.app_name, f\"{instance.ip}:{instance.port}\")\n\n            # Update instance status to indicate it's draining\n            await self.app_manager.db.update_instance_status(instance.id, 'draining')\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Failed to remove instance from load balancer: {e}\")\n            return False\n\n    async def _scale_out_application(self, app_name: str) -&gt; bool:\n        \"\"\"Scale out the application by adding replicas.\"\"\"\n        try:\n            # Get current application state\n            app_record = await self.app_manager.db.get_application(app_name)\n            if not app_record:\n                return False\n\n            # Check if scaling is allowed\n            scaling_policy = await self.app_manager.db.get_scaling_policy(app_name)\n            if scaling_policy and app_record.replicas &gt;= scaling_policy.max_replicas:\n                return False\n\n            # Scale out by 1 replica\n            new_replica_count = app_record.replicas + 1\n            await self.app_manager.scale_application(app_name, new_replica_count, reason=\"failure_recovery\")\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Failed to scale out application {app_name}: {e}\")\n            return False\n</code></pre>"},{"location":"developer-guide/health/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<pre><code>class CircuitBreakerState(Enum):\n    \"\"\"Circuit breaker states.\"\"\"\n    CLOSED = \"closed\"      # Normal operation\n    OPEN = \"open\"          # Failing, blocking requests\n    HALF_OPEN = \"half_open\"  # Testing if service recovered\n\nclass CircuitBreaker:\n    \"\"\"Circuit breaker implementation for preventing cascading failures.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.breakers: Dict[str, CircuitBreakerInfo] = {}\n\n    async def should_allow_request(self, app_name: str, instance_id: str) -&gt; bool:\n        \"\"\"Check if request should be allowed through circuit breaker.\"\"\"\n        breaker_key = f\"{app_name}:{instance_id}\"\n        breaker = self.breakers.get(breaker_key)\n\n        if not breaker:\n            return True  # No breaker configured, allow request\n\n        if breaker.state == CircuitBreakerState.CLOSED:\n            return True\n\n        elif breaker.state == CircuitBreakerState.OPEN:\n            # Check if we should transition to half-open\n            if time.time() - breaker.last_failure_time &gt; breaker.recovery_timeout:\n                breaker.state = CircuitBreakerState.HALF_OPEN\n                breaker.consecutive_failures = 0\n                return True\n            return False\n\n        elif breaker.state == CircuitBreakerState.HALF_OPEN:\n            # Allow limited number of test requests\n            return breaker.test_request_count &lt; breaker.max_test_requests\n\n    async def record_success(self, app_name: str, instance_id: str):\n        \"\"\"Record a successful request.\"\"\"\n        breaker_key = f\"{app_name}:{instance_id}\"\n        breaker = self.breakers.get(breaker_key)\n\n        if breaker:\n            if breaker.state == CircuitBreakerState.HALF_OPEN:\n                breaker.consecutive_successes += 1\n                if breaker.consecutive_successes &gt;= breaker.success_threshold:\n                    # Close the circuit breaker\n                    breaker.state = CircuitBreakerState.CLOSED\n                    breaker.consecutive_failures = 0\n                    breaker.consecutive_successes = 0\n                    breaker.test_request_count = 0\n\n            elif breaker.state == CircuitBreakerState.CLOSED:\n                breaker.consecutive_failures = 0  # Reset failure count\n\n    async def record_failure(self, app_name: str, instance_id: str):\n        \"\"\"Record a failed request.\"\"\"\n        breaker_key = f\"{app_name}:{instance_id}\"\n\n        if breaker_key not in self.breakers:\n            self.breakers[breaker_key] = CircuitBreakerInfo(\n                app_name=app_name,\n                instance_id=instance_id,\n                failure_threshold=self.config.get('failure_threshold', 5),\n                success_threshold=self.config.get('success_threshold', 3),\n                recovery_timeout=self.config.get('recovery_timeout', 60),\n                max_test_requests=self.config.get('max_test_requests', 3)\n            )\n\n        breaker = self.breakers[breaker_key]\n        breaker.consecutive_failures += 1\n        breaker.last_failure_time = time.time()\n\n        if breaker.state == CircuitBreakerState.CLOSED:\n            if breaker.consecutive_failures &gt;= breaker.failure_threshold:\n                # Open the circuit breaker\n                breaker.state = CircuitBreakerState.OPEN\n                breaker.consecutive_successes = 0\n\n        elif breaker.state == CircuitBreakerState.HALF_OPEN:\n            # Return to open state on any failure\n            breaker.state = CircuitBreakerState.OPEN\n            breaker.consecutive_successes = 0\n            breaker.test_request_count = 0\n\n@dataclass\nclass CircuitBreakerInfo:\n    \"\"\"Circuit breaker state information.\"\"\"\n    app_name: str\n    instance_id: str\n    state: CircuitBreakerState = CircuitBreakerState.CLOSED\n    failure_threshold: int = 5\n    success_threshold: int = 3\n    recovery_timeout: int = 60  # seconds\n    max_test_requests: int = 3\n    consecutive_failures: int = 0\n    consecutive_successes: int = 0\n    test_request_count: int = 0\n    last_failure_time: float = 0\n    created_at: float = field(default_factory=time.time)\n</code></pre>"},{"location":"developer-guide/health/#performance-metrics-collection","title":"Performance Metrics Collection","text":"<pre><code>class HealthMetricsCollector:\n    \"\"\"Collects health and performance metrics.\"\"\"\n\n    def __init__(self, db_manager):\n        self.db = db_manager\n\n    async def collect_health_metrics(self, health_results: List[HealthCheckResult]):\n        \"\"\"Collect metrics from health check results.\"\"\"\n        metrics = []\n\n        for result in health_results:\n            # Response time metric\n            metrics.append({\n                'app_name': result.app_name,\n                'metric_type': 'health_check_response_time',\n                'value': result.response_time_ms,\n                'unit': 'ms',\n                'labels': {\n                    'instance_id': result.instance_id,\n                    'check_type': result.check_type,\n                    'success': str(result.is_healthy).lower()\n                },\n                'timestamp': result.timestamp\n            })\n\n            # Health status metric (0 = unhealthy, 1 = healthy)\n            metrics.append({\n                'app_name': result.app_name,\n                'metric_type': 'health_check_status',\n                'value': 1.0 if result.is_healthy else 0.0,\n                'unit': 'status',\n                'labels': {\n                    'instance_id': result.instance_id,\n                    'check_type': result.check_type\n                },\n                'timestamp': result.timestamp\n            })\n\n            # Error details if unhealthy\n            if not result.is_healthy and result.error:\n                metrics.append({\n                    'app_name': result.app_name,\n                    'metric_type': 'health_check_errors',\n                    'value': 1.0,\n                    'unit': 'count',\n                    'labels': {\n                        'instance_id': result.instance_id,\n                        'error_type': self._classify_error(result.error),\n                        'status_code': str(result.status_code) if result.status_code else 'none'\n                    },\n                    'timestamp': result.timestamp\n                })\n\n        # Bulk insert metrics\n        await self.db.insert_metrics(metrics)\n\n    def _classify_error(self, error_message: str) -&gt; str:\n        \"\"\"Classify error message into categories.\"\"\"\n        error_lower = error_message.lower()\n\n        if 'timeout' in error_lower:\n            return 'timeout'\n        elif 'connection' in error_lower:\n            return 'connection'\n        elif 'dns' in error_lower:\n            return 'dns'\n        elif 'ssl' in error_lower or 'tls' in error_lower:\n            return 'ssl'\n        elif 'http' in error_lower:\n            return 'http'\n        else:\n            return 'unknown'\n\n    async def generate_health_report(self, app_name: str, hours: int = 24) -&gt; Dict[str, Any]:\n        \"\"\"Generate comprehensive health report for an application.\"\"\"\n        # Get health check metrics\n        health_metrics = await self.db.get_metrics_window(\n            app_name, \n            ['health_check_status', 'health_check_response_time', 'health_check_errors'],\n            hours * 60\n        )\n\n        # Calculate uptime percentage\n        status_metrics = [m for m in health_metrics if m['metric_type'] == 'health_check_status']\n        if status_metrics:\n            total_checks = len(status_metrics)\n            healthy_checks = len([m for m in status_metrics if m['value'] == 1.0])\n            uptime_percent = (healthy_checks / total_checks) * 100\n        else:\n            uptime_percent = 0\n\n        # Calculate average response time\n        response_time_metrics = [m for m in health_metrics if m['metric_type'] == 'health_check_response_time']\n        if response_time_metrics:\n            avg_response_time = sum(m['value'] for m in response_time_metrics) / len(response_time_metrics)\n            p95_response_time = sorted([m['value'] for m in response_time_metrics])[int(len(response_time_metrics) * 0.95)]\n        else:\n            avg_response_time = 0\n            p95_response_time = 0\n\n        # Count errors by type\n        error_metrics = [m for m in health_metrics if m['metric_type'] == 'health_check_errors']\n        error_counts = {}\n        for metric in error_metrics:\n            error_type = metric.get('labels', {}).get('error_type', 'unknown')\n            error_counts[error_type] = error_counts.get(error_type, 0) + 1\n\n        return {\n            'app_name': app_name,\n            'report_period_hours': hours,\n            'uptime_percent': uptime_percent,\n            'total_health_checks': len(status_metrics),\n            'successful_checks': len([m for m in status_metrics if m['value'] == 1.0]),\n            'failed_checks': len([m for m in status_metrics if m['value'] == 0.0]),\n            'avg_response_time_ms': avg_response_time,\n            'p95_response_time_ms': p95_response_time,\n            'error_breakdown': error_counts,\n            'generated_at': time.time()\n        }\n</code></pre> <p>Next Steps: Learn about Load Balancing and Nginx integration.</p>"},{"location":"developer-guide/leader-election/","title":"Leader Election and Distributed Controller","text":"<p>Orchestry implements a distributed controller architecture with leader election to eliminate single points of failure and provide high availability for the control plane.</p>"},{"location":"developer-guide/leader-election/#overview","title":"Overview","text":"<p>The distributed controller system uses a 3-node cluster architecture with PostgreSQL-based leader election to ensure that only one controller node actively manages applications at any given time, while maintaining seamless failover capabilities.</p>"},{"location":"developer-guide/leader-election/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           External Traffic                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Nginx Load Balancer (Port 8000)                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502  Upstream Configuration (Dynamic Leader Routing)                    \u2502    \u2502\n\u2502  \u2502  \u2022 Write Operations \u2192 Leader Only                                   \u2502    \u2502\n\u2502  \u2502  \u2022 Read Operations \u2192 All Healthy Nodes                              \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Controller Cluster                                       \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502  \u2502 Controller-1    \u2502 \u2502 Controller-2    \u2502 \u2502 Controller-3    \u2502                \u2502\n\u2502  \u2502   (Leader)      \u2502 \u2502  (Follower)     \u2502 \u2502  (Follower)     \u2502                \u2502\n\u2502  \u2502   Port 8001     \u2502 \u2502   Port 8002     \u2502 \u2502   Port 8003     \u2502                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502           \u2502                  \u2502                      \u2502                       \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                              \u2502                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PostgreSQL HA Cluster                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502  \u2502    Primary      \u2502\u25c4\u2500\u2500\u2500\u2500 Replication  \u2500\u2500\u2500\u2500\u25ba\u2502     Replica     \u2502             \u2502\n\u2502  \u2502   (Read/Write)  \u2502                        \u2502   (Read Only)   \u2502             \u2502\n\u2502  \u2502  Leader Election\u2502                        \u2502   Coordination  \u2502             \u2502\n\u2502  \u2502   Coordination  \u2502                        \u2502      Data       \u2502             \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/leader-election/#leader-election-algorithm","title":"Leader Election Algorithm","text":"<p>Orchestry implements a simplified Raft-like consensus algorithm using PostgreSQL as the coordination backend. This approach leverages the database's ACID properties to ensure consistent leader election.</p>"},{"location":"developer-guide/leader-election/#core-concepts","title":"Core Concepts","text":""},{"location":"developer-guide/leader-election/#1-node-states","title":"1. Node States","text":"<p>Each controller node can be in one of four states:</p> <pre><code>class NodeState(Enum):\n    FOLLOWER = \"follower\"      # Default state, follows leader\n    CANDIDATE = \"candidate\"    # Attempting to become leader\n    LEADER = \"leader\"         # Actively managing applications\n    STOPPED = \"stopped\"       # Node is shutting down\n</code></pre>"},{"location":"developer-guide/leader-election/#2-leadership-lease","title":"2. Leadership Lease","text":"<p>The leader election uses a time-based lease system stored in PostgreSQL:</p> <pre><code>@dataclass\nclass LeaderLease:\n    leader_id: str          # Unique node identifier\n    term: int              # Election term number\n    acquired_at: float     # Timestamp when lease was acquired\n    expires_at: float      # Timestamp when lease expires\n    renewed_at: float      # Last renewal timestamp\n    hostname: str          # Leader's hostname\n    api_url: str          # Leader's API endpoint\n</code></pre>"},{"location":"developer-guide/leader-election/#3-database-schema","title":"3. Database Schema","text":"<pre><code>-- Cluster nodes table\nCREATE TABLE cluster_nodes (\n    node_id VARCHAR(255) PRIMARY KEY,\n    hostname VARCHAR(255) NOT NULL,\n    port INTEGER NOT NULL,\n    api_url VARCHAR(512) NOT NULL,\n    state VARCHAR(50) NOT NULL,\n    term INTEGER NOT NULL DEFAULT 0,\n    last_heartbeat TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    is_healthy BOOLEAN NOT NULL DEFAULT true,\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Leader lease table (single row)\nCREATE TABLE leader_lease (\n    id INTEGER PRIMARY KEY DEFAULT 1,\n    leader_id VARCHAR(255) NOT NULL,\n    term INTEGER NOT NULL,\n    acquired_at TIMESTAMP NOT NULL,\n    expires_at TIMESTAMP NOT NULL,\n    renewed_at TIMESTAMP NOT NULL,\n    hostname VARCHAR(255) NOT NULL,\n    api_url VARCHAR(512) NOT NULL,\n    CONSTRAINT single_lease CHECK (id = 1)\n);\n\n-- Cluster events log\nCREATE TABLE cluster_events (\n    id SERIAL PRIMARY KEY,\n    node_id VARCHAR(255) NOT NULL,\n    event_type VARCHAR(100) NOT NULL,\n    event_data JSONB,\n    timestamp TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"developer-guide/leader-election/#leader-election-process","title":"Leader Election Process","text":""},{"location":"developer-guide/leader-election/#1-node-startup-and-registration","title":"1. Node Startup and Registration","text":"<p>When a controller node starts up:</p> <pre><code>def start(self):\n    \"\"\"Start the distributed controller cluster\"\"\"\n    if self._running:\n        return\n\n    logger.info(f\"\ud83d\ude80 Starting distributed controller node {self.node_id}\")\n\n    # Initialize database tables\n    self._init_cluster_tables()\n\n    # Register this node\n    self._register_node()\n\n    # Start background coordination tasks\n    self._start_background_tasks()\n\n    self._running = True\n    logger.info(f\"\u2705 Distributed controller node {self.node_id} started\")\n</code></pre>"},{"location":"developer-guide/leader-election/#2-election-triggers","title":"2. Election Triggers","text":"<p>Elections are triggered when: - No valid leader exists (lease expired) - Node startup (check for existing leader) - Leader failure detection - Manual leadership release</p> <pre><code>def _should_start_election(self) -&gt; bool:\n    \"\"\"Check if we should start a leader election\"\"\"\n    try:\n        # Check if there's a current valid leader\n        current_lease = self._get_current_lease()\n        if current_lease and current_lease.expires_at &gt; time.time():\n            # Valid leader exists\n            if current_lease.leader_id != self.leader_id:\n                self.leader_id = current_lease.leader_id\n                logger.info(f\"\ud83d\udc51 Acknowledged leader: {self.leader_id}\")\n            return False\n\n        # No valid leader - check if we should start election\n        if self.state == NodeState.FOLLOWER:\n            logger.info(\"\ud83d\uddf3\ufe0f  No valid leader found, considering election...\")\n            return True\n\n    except Exception as e:\n        logger.error(f\"\u274c Error checking election conditions: {e}\")\n\n    return False\n</code></pre>"},{"location":"developer-guide/leader-election/#3-lease-acquisition","title":"3. Lease Acquisition","text":"<p>The core of leader election is atomic lease acquisition:</p> <pre><code>def _try_acquire_leadership(self) -&gt; bool:\n    \"\"\"Try to acquire leadership lease atomically\"\"\"\n    try:\n        with self._get_db_connection() as conn:\n            with conn.cursor() as cursor:\n                # Try to acquire or update lease atomically\n                cursor.execute(\"\"\"\n                    INSERT INTO leader_lease \n                    (id, leader_id, term, acquired_at, expires_at, renewed_at, hostname, api_url)\n                    VALUES (1, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP + INTERVAL '%s seconds', CURRENT_TIMESTAMP, %s, %s)\n                    ON CONFLICT (id) DO UPDATE SET\n                        leader_id = EXCLUDED.leader_id,\n                        term = EXCLUDED.term,\n                        acquired_at = CURRENT_TIMESTAMP,\n                        expires_at = CURRENT_TIMESTAMP + INTERVAL '%s seconds',\n                        renewed_at = CURRENT_TIMESTAMP,\n                        hostname = EXCLUDED.hostname,\n                        api_url = EXCLUDED.api_url\n                    WHERE leader_lease.expires_at &lt;= CURRENT_TIMESTAMP \n                       OR leader_lease.term &lt; EXCLUDED.term\n                \"\"\", (\n                    self.node_id,\n                    self.current_term,\n                    self.lease_ttl,\n                    self.hostname,\n                    self.api_url,\n                    self.lease_ttl\n                ))\n\n                # Check if we actually acquired the lease\n                if cursor.rowcount &gt; 0:\n                    conn.commit()\n                    logger.info(f\"\u2705 Acquired leadership lease for term {self.current_term}\")\n                    return True\n                else:\n                    conn.rollback()\n                    return False\n\n    except Exception as e:\n        logger.error(f\"\u274c Failed to acquire leadership lease: {e}\")\n        return False\n</code></pre>"},{"location":"developer-guide/leader-election/#4-leadership-maintenance","title":"4. Leadership Maintenance","text":"<p>Once elected, the leader must continuously renew its lease:</p> <pre><code>def _renew_leadership_lease(self):\n    \"\"\"Renew leadership lease to maintain leadership\"\"\"\n    if not self.is_leader:\n        return\n\n    try:\n        with self._get_db_connection() as conn:\n            with conn.cursor() as cursor:\n                cursor.execute(\"\"\"\n                    UPDATE leader_lease \n                    SET expires_at = CURRENT_TIMESTAMP + INTERVAL '%s seconds',\n                        renewed_at = CURRENT_TIMESTAMP\n                    WHERE leader_id = %s AND term = %s\n                \"\"\", (self.lease_ttl, self.node_id, self.current_term))\n\n                if cursor.rowcount == 0:\n                    # We lost the lease somehow\n                    logger.warning(\"\u26a0\ufe0f  Lost leadership lease during renewal\")\n                    conn.rollback()\n                    self._lose_leadership()\n                else:\n                    conn.commit()\n\n    except Exception as e:\n        logger.error(f\"\u274c Failed to renew leadership lease: {e}\")\n        self._lose_leadership()\n</code></pre>"},{"location":"developer-guide/leader-election/#background-processes","title":"Background Processes","text":"<p>The distributed controller runs three main background processes:</p>"},{"location":"developer-guide/leader-election/#1-heartbeat-loop","title":"1. Heartbeat Loop","text":"<p>Maintains node presence and leader lease renewal:</p> <pre><code>def _heartbeat_loop(self):\n    \"\"\"Background heartbeat to maintain node presence\"\"\"\n    logger.info(\"\ud83d\udc93 Starting heartbeat loop...\")\n\n    while self._running:\n        try:\n            self._send_heartbeat()\n\n            # If we're the leader, renew our lease\n            if self.is_leader:\n                self._renew_leadership_lease()\n\n        except Exception as e:\n            logger.error(f\"\u274c Heartbeat error: {e}\")\n\n        time.sleep(self.heartbeat_interval)  # Default: 10 seconds\n</code></pre>"},{"location":"developer-guide/leader-election/#2-election-loop","title":"2. Election Loop","text":"<p>Monitors leader health and triggers elections:</p> <pre><code>def _election_loop(self):\n    \"\"\"Background election monitoring and leadership checks\"\"\"\n    logger.info(\"\ud83d\uddf3\ufe0f  Starting election monitoring loop...\")\n\n    while self._running:\n        try:\n            if not self.is_leader:\n                # Check if we need to start an election\n                if self._should_start_election():\n                    self._start_leader_election()\n\n            # Check leader health and lease validity\n            self._check_leader_health()\n\n        except Exception as e:\n            logger.error(f\"\u274c Election loop error: {e}\")\n\n        time.sleep(5)  # Check every 5 seconds\n</code></pre>"},{"location":"developer-guide/leader-election/#3-cluster-monitoring-loop","title":"3. Cluster Monitoring Loop","text":"<p>Manages cluster membership and cleanup:</p> <pre><code>def _cluster_monitor_loop(self):\n    \"\"\"Monitor cluster membership and health\"\"\"\n    logger.info(\"\ud83d\udd0d Starting cluster monitoring loop...\")\n\n    while self._running:\n        try:\n            self._update_cluster_membership()\n            self._cleanup_stale_nodes()\n\n        except Exception as e:\n            logger.error(f\"\u274c Cluster monitoring error: {e}\")\n\n        time.sleep(15)  # Check every 15 seconds\n</code></pre>"},{"location":"developer-guide/leader-election/#api-integration","title":"API Integration","text":"<p>The leader election system integrates with the REST API through decorators and middleware:</p>"},{"location":"developer-guide/leader-election/#leader-only-operations","title":"Leader-Only Operations","text":"<p>Critical write operations are restricted to the leader:</p> <pre><code>def leader_required(f):\n    \"\"\"Decorator to ensure only the leader can execute certain operations\"\"\"\n    @wraps(f)\n    async def decorated_function(*args, **kwargs):\n        if cluster_controller and not cluster_controller.is_leader:\n            leader_info = cluster_controller.get_leader_info()\n            if leader_info:\n                raise HTTPException(\n                    status_code=307, \n                    detail=f\"Request must be sent to leader node: {leader_info['api_url']}\",\n                    headers={\"Location\": leader_info['api_url']}\n                )\n            else:\n                raise HTTPException(\n                    status_code=503, \n                    detail=\"No leader elected, cluster not ready\"\n                )\n        return await f(*args, **kwargs)\n    return decorated_function\n\n# Usage\n@app.post(\"/apps\")\n@leader_required\nasync def register_app(app_spec: AppSpec):\n    \"\"\"Register a new application (leader only)\"\"\"\n    return await app_manager.register_app(app_spec.dict())\n</code></pre>"},{"location":"developer-guide/leader-election/#cluster-status-endpoints","title":"Cluster Status Endpoints","text":"<pre><code>@app.get(\"/cluster/status\")\nasync def get_cluster_status():\n    \"\"\"Get comprehensive cluster status\"\"\"\n    if not cluster_controller:\n        raise HTTPException(status_code=503, detail=\"Clustering not enabled\")\n\n    return cluster_controller.get_cluster_status()\n\n@app.get(\"/cluster/leader\")\nasync def get_cluster_leader():\n    \"\"\"Get current cluster leader information\"\"\"\n    if not cluster_controller:\n        raise HTTPException(status_code=503, detail=\"Clustering not enabled\")\n\n    leader_info = cluster_controller.get_leader_info()\n    if leader_info:\n        return leader_info\n    else:\n        raise HTTPException(status_code=503, detail=\"No leader elected\")\n\n@app.get(\"/cluster/health\")\nasync def cluster_health_check():\n    \"\"\"Cluster-aware health check that includes leadership status\"\"\"\n    if not cluster_controller:\n        return {\n            \"status\": \"healthy\",\n            \"clustering\": \"disabled\",\n            \"timestamp\": time.time(),\n            \"version\": \"1.0.0\"\n        }\n\n    cluster_status = cluster_controller.get_cluster_status()\n    is_ready = cluster_controller.is_cluster_ready()\n\n    return {\n        \"status\": \"healthy\" if is_ready else \"degraded\",\n        \"clustering\": \"enabled\",\n        \"node_id\": cluster_status[\"node_id\"],\n        \"state\": cluster_status[\"state\"],\n        \"is_leader\": cluster_status[\"is_leader\"],\n        \"leader_id\": cluster_status[\"leader_id\"],\n        \"cluster_size\": cluster_status[\"cluster_size\"],\n        \"cluster_ready\": is_ready,\n        \"timestamp\": time.time(),\n        \"version\": \"1.0.0\"\n    }\n</code></pre>"},{"location":"developer-guide/leader-election/#load-balancer-integration","title":"Load Balancer Integration","text":"<p>Nginx is configured to route traffic appropriately based on operation type:</p>"},{"location":"developer-guide/leader-election/#configuration-structure","title":"Configuration Structure","text":"<pre><code># Upstream for read operations - can distribute load to all healthy nodes\nupstream controller_cluster_read {\n    server controller-1:8001 max_fails=3 fail_timeout=30s;\n    server controller-2:8002 max_fails=3 fail_timeout=30s;\n    server controller-3:8003 max_fails=3 fail_timeout=30s;\n}\n\n# Upstream for write operations - only to current leader\nupstream controller_cluster_write {\n    server controller-1:8001 max_fails=3 fail_timeout=30s;\n    server controller-2:8002 max_fails=3 fail_timeout=30s backup;\n    server controller-3:8003 max_fails=3 fail_timeout=30s backup;\n}\n\n# Map to determine if a request needs to go to the leader\nmap $request_method $needs_leader {\n    default \"no\";\n    POST \"yes\";\n    PUT \"yes\";\n    DELETE \"yes\";\n    PATCH \"yes\";\n}\n\nserver {\n    listen 8000;\n\n    # Read operations - distribute to all healthy nodes\n    location ~ ^/(apps/[^/]+/status|apps/[^/]+/metrics|cluster/status|cluster/health)$ {\n        proxy_pass http://controller_cluster_read;\n        add_header X-Controller-Mode \"read-distributed\" always;\n    }\n\n    # Write operations - must go to leader only\n    location / {\n        proxy_pass http://controller_cluster_write;\n        add_header X-Controller-Mode \"leader-only\" always;\n    }\n}\n</code></pre>"},{"location":"developer-guide/leader-election/#failure-scenarios-and-recovery","title":"Failure Scenarios and Recovery","text":""},{"location":"developer-guide/leader-election/#1-leader-failure","title":"1. Leader Failure","text":"<p>Scenario: Current leader node crashes or becomes unresponsive</p> <p>Detection:  - Leader lease expires (not renewed within <code>lease_ttl</code>) - Health checks fail - Heartbeat timeouts</p> <p>Recovery Process: 1. Remaining nodes detect expired lease 2. Election timeout triggers on followers 3. First candidate to acquire new lease becomes leader 4. New leader broadcasts its status 5. Load balancer updates routing</p> <p>Timeline: Typically 15-30 seconds for complete failover</p>"},{"location":"developer-guide/leader-election/#2-network-partition","title":"2. Network Partition","text":"<p>Scenario: Network split isolates nodes</p> <p>Protection:  - Database-based coordination prevents split-brain - Only node with database access can be leader - Isolated nodes automatically step down</p> <p>Recovery:  - When partition heals, nodes rejoin cluster - Existing leader maintains control - Isolated nodes sync state from leader</p>"},{"location":"developer-guide/leader-election/#3-database-connectivity-issues","title":"3. Database Connectivity Issues","text":"<p>Scenario: PostgreSQL becomes unreachable</p> <p>Behavior: - Current leader steps down when lease renewal fails - No new leader can be elected - System enters degraded state - Read-only operations may continue from cached state</p> <p>Recovery: - When database connectivity restores, election resumes - New leader elected within one election cycle - Full functionality restored</p>"},{"location":"developer-guide/leader-election/#4-load-balancer-failover-mechanism","title":"4. Load Balancer Failover Mechanism","text":"<p>Problem Solved: Ensures requests reach the current leader even during leadership transitions.</p> <p>How It Works: 1. Non-Leader Response: When a non-leader controller receives a write request, it returns HTTP 503 (Service Unavailable) instead of redirecting 2. Nginx Failover: The load balancer automatically tries the next controller in the upstream pool when it receives a 503 response 3. Leader Discovery: Nginx continues trying controllers until it reaches the current leader 4. Consistent Routing: All client requests go through the load balancer, preventing direct access to individual controllers</p> <p>Key Benefits: - No Redirect Loops: Clients always interact with the load balancer, never individual controllers - Automatic Failover: No manual intervention needed during leader changes - Fast Recovery: Typically 1-3 seconds to route to new leader after election - Transparent to Clients: Client applications don't need to know about leadership changes</p> <p>Implementation Details: <pre><code># Nginx upstream configuration tries all controllers\nupstream controller_cluster_write {\n    server controller-1:8001 max_fails=1 fail_timeout=5s;\n    server controller-2:8002 max_fails=1 fail_timeout=5s; \n    server controller-3:8003 max_fails=1 fail_timeout=5s;\n}\n\n# Automatic failover on 503 responses\nproxy_next_upstream error timeout invalid_header http_503;\n</code></pre></p> <p>Controller Response Strategy: - Leader: Processes the request normally - Non-Leader: Returns <code>503 Service Unavailable</code> with leader information in headers - No Leader: All controllers return <code>503</code> until election completes</p>"},{"location":"developer-guide/leader-election/#5-split-brain-prevention","title":"5. Split-Brain Prevention","text":"<p>The system prevents split-brain scenarios through:</p> <ol> <li>Single Source of Truth: PostgreSQL database is the only authority for leader election</li> <li>Atomic Operations: Lease acquisition uses database transactions</li> <li>Lease Expiry: Time-based leases automatically expire</li> <li>Health Monitoring: Continuous validation of leader status</li> </ol>"},{"location":"developer-guide/leader-election/#configuration","title":"Configuration","text":""},{"location":"developer-guide/leader-election/#environment-variables","title":"Environment Variables","text":"<pre><code># Controller cluster configuration\nCLUSTER_NODE_ID=controller-1              # Unique node identifier\nCLUSTER_HOSTNAME=controller-1.local       # Node hostname\nORCHESTRY_PORT=8001                       # API port for this node\n\n# Timing configuration  \nCLUSTER_LEASE_TTL=30                      # Leadership lease duration (seconds)\nCLUSTER_HEARTBEAT_INTERVAL=10             # Heartbeat frequency (seconds)  \nCLUSTER_ELECTION_TIMEOUT=15               # Election timeout (seconds)\n\n# Database configuration\nDATABASE_PRIMARY_HOST=postgres-primary\nDATABASE_REPLICA_HOST=postgres-replica\nDATABASE_NAME=orchestry\nDATABASE_USER=orchestry\nDATABASE_PASSWORD=secure_password\n</code></pre>"},{"location":"developer-guide/leader-election/#startup-command","title":"Startup Command","text":"<pre><code># Start controller with clustering enabled\ndocker run -d \\\n  --name controller-1 \\\n  --network orchestry \\\n  -e CLUSTER_NODE_ID=controller-1 \\\n  -e CLUSTER_HOSTNAME=controller-1 \\\n  -e ORCHESTRY_PORT=8001 \\\n  -p 8001:8001 \\\n  orchestry-controller\n</code></pre>"},{"location":"developer-guide/leader-election/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"developer-guide/leader-election/#cluster-events","title":"Cluster Events","text":"<p>All leadership changes and cluster events are logged:</p> <pre><code>def _log_cluster_event(self, event_type: str, event_data: Dict[str, Any]):\n    \"\"\"Log cluster coordination event\"\"\"\n    try:\n        with self._get_db_connection() as conn:\n            with conn.cursor() as cursor:\n                cursor.execute(\"\"\"\n                    INSERT INTO cluster_events (node_id, event_type, event_data)\n                    VALUES (%s, %s, %s)\n                \"\"\", (self.node_id, event_type, json.dumps(event_data)))\n                conn.commit()\n    except Exception as e:\n        logger.error(f\"\u274c Failed to log cluster event: {e}\")\n</code></pre>"},{"location":"developer-guide/leader-election/#key-metrics","title":"Key Metrics","text":"<p>Monitor these metrics for cluster health:</p> <ul> <li>Leadership Duration: How long each leader serves</li> <li>Election Frequency: Rate of leadership changes</li> <li>Lease Renewal Success Rate: Health of leader lease system</li> <li>Node Health: Heartbeat success rates</li> <li>Failover Time: Time to elect new leader after failure</li> </ul>"},{"location":"developer-guide/leader-election/#log-events","title":"Log Events","text":"<p>Important cluster events to monitor:</p> <ul> <li><code>leader_elected</code>: New leader elected</li> <li><code>leader_lost</code>: Leadership lost/expired</li> <li><code>node_joined</code>: New node joined cluster</li> <li><code>node_left</code>: Node left cluster</li> <li><code>election_started</code>: Leadership election initiated</li> <li><code>lease_renewed</code>: Leadership lease renewed</li> <li><code>cluster_degraded</code>: Cluster in unhealthy state</li> </ul>"},{"location":"developer-guide/leader-election/#best-practices","title":"Best Practices","text":""},{"location":"developer-guide/leader-election/#1-cluster-sizing","title":"1. Cluster Sizing","text":"<ul> <li>Production: Use 3-node clusters for optimal fault tolerance</li> <li>Development: Single node acceptable for testing</li> <li>Scaling: Odd numbers (3, 5) prevent ties in future voting scenarios</li> </ul>"},{"location":"developer-guide/leader-election/#2-network-configuration","title":"2. Network Configuration","text":"<ul> <li>Ensure reliable network connectivity between nodes</li> <li>Use dedicated network segments for cluster communication</li> <li>Configure appropriate firewall rules for inter-node communication</li> </ul>"},{"location":"developer-guide/leader-election/#3-database-configuration","title":"3. Database Configuration","text":"<ul> <li>Use PostgreSQL High Availability setup with replication</li> <li>Configure connection pooling for efficient database access</li> <li>Monitor database performance and connectivity</li> </ul>"},{"location":"developer-guide/leader-election/#4-monitoring","title":"4. Monitoring","text":"<ul> <li>Set up alerts for leadership changes</li> <li>Monitor lease renewal success rates</li> <li>Track cluster health metrics</li> <li>Log all cluster events for troubleshooting</li> </ul>"},{"location":"developer-guide/leader-election/#5-deployment","title":"5. Deployment","text":"<ul> <li>Deploy nodes across different availability zones</li> <li>Use health checks in orchestration systems</li> <li>Implement graceful shutdown procedures</li> <li>Test failover scenarios regularly</li> </ul>"},{"location":"developer-guide/leader-election/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer-guide/leader-election/#common-issues","title":"Common Issues","text":"<ol> <li>Frequent Leadership Changes</li> <li>Check network stability between nodes</li> <li>Verify database connectivity</li> <li> <p>Review lease timeout settings</p> </li> <li> <p>Split-Brain Scenarios</p> </li> <li>Verify database is the single source of truth</li> <li>Check for network partitions</li> <li> <p>Review fencing mechanisms</p> </li> <li> <p>Slow Failover</p> </li> <li>Adjust lease TTL and election timeout values</li> <li>Check database query performance</li> <li> <p>Verify node health check intervals</p> </li> <li> <p>Cluster Not Ready</p> </li> <li>Ensure minimum number of healthy nodes</li> <li>Check database connectivity</li> <li>Verify node registration</li> </ol>"},{"location":"developer-guide/leader-election/#debugging-commands","title":"Debugging Commands","text":"<pre><code># Check cluster status\ncurl http://localhost:8000/cluster/status\n\n# Get current leader\ncurl http://localhost:8000/cluster/leader\n\n# Health check with cluster info\ncurl http://localhost:8000/cluster/health\n\n# Check database cluster events\npsql -h postgres-primary -U orchestry -d orchestry \\\n  -c \"SELECT * FROM cluster_events ORDER BY timestamp DESC LIMIT 10;\"\n\n# Check current lease\npsql -h postgres-primary -U orchestry -d orchestry \\\n  -c \"SELECT * FROM leader_lease;\"\n\n# Check node status\npsql -h postgres-primary -U orchestry -d orchestry \\\n  -c \"SELECT * FROM cluster_nodes ORDER BY last_heartbeat DESC;\"\n</code></pre> <p>Next Steps:  - Database Architecture - Learn about PostgreSQL HA setup - Load Balancing - Understand traffic routing - Health Monitoring - Explore health check systems</p>"},{"location":"developer-guide/load-balancing/","title":"Load Balancing and Traffic Management","text":"<p>Complete documentation of Orchestry's load balancing system, Nginx integration, and traffic management capabilities.</p>"},{"location":"developer-guide/load-balancing/#overview","title":"Overview","text":"<p>Orchestry uses Nginx as a dynamic load balancer to distribute traffic across application instances. The system provides:</p> <ul> <li>Dynamic Configuration: Real-time updates without service interruption</li> <li>Health-Aware Routing: Traffic only to healthy instances</li> <li>Multiple Load Balancing Algorithms: Round-robin, least connections, IP hash</li> <li>SSL Termination: HTTPS support with automatic certificate management</li> <li>Connection Pooling: Efficient upstream connection management</li> <li>Circuit Breaking: Protection against cascading failures</li> <li>Request Routing: Path-based and header-based routing rules</li> </ul>"},{"location":"developer-guide/load-balancing/#architecture-overview","title":"Architecture Overview","text":""},{"location":"developer-guide/load-balancing/#load-balancing-flow","title":"Load Balancing Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Client Request   \u2502    \u2502   Nginx Proxy       \u2502    \u2502  Application        \u2502\n\u2502                     \u2502    \u2502                     \u2502    \u2502  Instances          \u2502\n\u2502  \u2022 HTTP/HTTPS       \u2502\u2500\u2500\u2500\u25ba\u2502  \u2022 Load balancing   \u2502\u2500\u2500\u2500\u25ba\u2502                     \u2502\n\u2502  \u2022 WebSocket        \u2502    \u2502  \u2022 Health checks    \u2502    \u2502  \u2022 Instance 1       \u2502\n\u2502  \u2022 API calls        \u2502    \u2502  \u2022 SSL termination  \u2502    \u2502  \u2022 Instance 2       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  \u2022 Request routing  \u2502    \u2502  \u2022 Instance N       \u2502\n                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                      \u2502\n                                      \u25bc\n                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                           \u2502   Configuration     \u2502\n                           \u2502   Management        \u2502\n                           \u2502                     \u2502\n                           \u2502  \u2022 Dynamic updates  \u2502\n                           \u2502  \u2022 Health status    \u2502\n                           \u2502  \u2022 Routing rules    \u2502\n                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/load-balancing/#component-integration","title":"Component Integration","text":"<pre><code>class LoadBalancingSystem:\n    \"\"\"Orchestrates load balancing components.\"\"\"\n\n    def __init__(self):\n        self.nginx_manager = NginxManager()\n        self.upstream_manager = UpstreamManager()\n        self.health_monitor = HealthMonitor()\n        self.ssl_manager = SSLManager()\n        self.metrics_collector = LoadBalancerMetrics()\n\n    async def initialize(self):\n        \"\"\"Initialize the load balancing system.\"\"\"\n        await self.nginx_manager.initialize()\n        await self.upstream_manager.initialize()\n        await self.health_monitor.start()\n        await self.ssl_manager.initialize()\n\n    async def update_application_routing(self, app_name: str, instances: List[InstanceRecord]):\n        \"\"\"Update routing configuration for an application.\"\"\"\n        # Generate upstream configuration\n        upstream_config = await self.upstream_manager.generate_upstream_config(app_name, instances)\n\n        # Update Nginx configuration\n        await self.nginx_manager.update_upstream(app_name, upstream_config)\n\n        # Reload Nginx configuration\n        await self.nginx_manager.reload_config()\n\n        # Update health monitoring\n        await self.health_monitor.update_targets(app_name, instances)\n</code></pre>"},{"location":"developer-guide/load-balancing/#nginx-configuration-management","title":"Nginx Configuration Management","text":""},{"location":"developer-guide/load-balancing/#dynamic-configuration-generator","title":"Dynamic Configuration Generator","text":"<pre><code>class NginxConfigGenerator:\n    \"\"\"Generates Nginx configuration files dynamically.\"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.template_loader = jinja2.FileSystemLoader('configs/nginx/')\n        self.template_env = jinja2.Environment(loader=self.template_loader)\n\n    async def generate_main_config(self, applications: List[str]) -&gt; str:\n        \"\"\"Generate main Nginx configuration.\"\"\"\n        template = self.template_env.get_template('nginx-main.conf')\n\n        return template.render(\n            worker_processes=self.config.get('worker_processes', 'auto'),\n            worker_connections=self.config.get('worker_connections', 1024),\n            keepalive_timeout=self.config.get('keepalive_timeout', 65),\n            client_max_body_size=self.config.get('client_max_body_size', '10m'),\n            proxy_connect_timeout=self.config.get('proxy_connect_timeout', '60s'),\n            proxy_send_timeout=self.config.get('proxy_send_timeout', '60s'),\n            proxy_read_timeout=self.config.get('proxy_read_timeout', '60s'),\n            proxy_buffer_size=self.config.get('proxy_buffer_size', '4k'),\n            proxy_buffers=self.config.get('proxy_buffers', '8 4k'),\n            applications=applications,\n            timestamp=datetime.now().isoformat()\n        )\n\n    async def generate_upstream_config(self, app_name: str, instances: List[InstanceRecord], \n                                     lb_method: str = 'round_robin') -&gt; str:\n        \"\"\"Generate upstream configuration for an application.\"\"\"\n        template = self.template_env.get_template('upstream.conf')\n\n        # Filter healthy instances\n        healthy_instances = [\n            instance for instance in instances \n            if instance.status == 'running' and instance.health_status == 'healthy'\n        ]\n\n        # Prepare server entries\n        servers = []\n        for instance in healthy_instances:\n            server_config = {\n                'address': f\"{instance.ip}:{instance.port}\",\n                'weight': self._calculate_server_weight(instance),\n                'max_fails': self.config.get('max_fails', 3),\n                'fail_timeout': self.config.get('fail_timeout', '30s'),\n                'max_conns': self._calculate_max_connections(instance)\n            }\n\n            # Add server-specific parameters\n            if instance.consecutive_failures &gt; 0:\n                server_config['backup'] = True\n\n            servers.append(server_config)\n\n        return template.render(\n            app_name=app_name,\n            lb_method=lb_method,\n            servers=servers,\n            keepalive=self.config.get('upstream_keepalive', 32),\n            keepalive_requests=self.config.get('keepalive_requests', 100),\n            keepalive_timeout=self.config.get('upstream_keepalive_timeout', '60s')\n        )\n\n    async def generate_server_config(self, app_spec: Dict[str, Any]) -&gt; str:\n        \"\"\"Generate server block configuration for an application.\"\"\"\n        template = self.template_env.get_template('server.conf')\n\n        # Extract configuration from app spec\n        app_name = app_spec['metadata']['name']\n        networking = app_spec['spec'].get('networking', {})\n\n        # Determine server configuration\n        server_config = {\n            'app_name': app_name,\n            'listen_port': networking.get('external_port', 80),\n            'server_name': networking.get('domain', f\"{app_name}.orchestry.local\"),\n            'ssl_enabled': networking.get('ssl', {}).get('enabled', False),\n            'ssl_cert_path': f\"/etc/ssl/certs/{app_name}.crt\",\n            'ssl_key_path': f\"/etc/ssl/private/{app_name}.key\",\n            'proxy_pass': f\"http://{app_name}_upstream\",\n            'access_log': f\"/var/log/nginx/{app_name}_access.log\",\n            'error_log': f\"/var/log/nginx/{app_name}_error.log\",\n            'client_max_body_size': networking.get('max_body_size', '10m'),\n            'proxy_timeout': networking.get('timeout', '60s')\n        }\n\n        # Add custom headers and rules\n        custom_headers = networking.get('headers', {})\n        location_rules = networking.get('locations', [])\n\n        return template.render(\n            **server_config,\n            custom_headers=custom_headers,\n            location_rules=location_rules,\n            health_check_path='/_health',\n            status_check_path='/_status'\n        )\n\n    def _calculate_server_weight(self, instance: InstanceRecord) -&gt; int:\n        \"\"\"Calculate server weight based on performance metrics.\"\"\"\n        base_weight = 1\n\n        # Adjust based on CPU usage\n        if instance.cpu_percent &lt; 30:\n            base_weight += 2\n        elif instance.cpu_percent &gt; 70:\n            base_weight -= 1\n\n        # Adjust based on memory usage\n        if instance.memory_percent &lt; 50:\n            base_weight += 1\n        elif instance.memory_percent &gt; 80:\n            base_weight -= 1\n\n        # Adjust based on failure history\n        if instance.consecutive_failures &gt; 0:\n            base_weight = max(1, base_weight - instance.consecutive_failures)\n\n        return max(1, base_weight)\n\n    def _calculate_max_connections(self, instance: InstanceRecord) -&gt; int:\n        \"\"\"Calculate maximum connections for an instance.\"\"\"\n        # Base connection limit\n        base_limit = self.config.get('default_max_conns', 100)\n\n        # Adjust based on resource usage\n        if instance.memory_percent &gt; 80:\n            return int(base_limit * 0.5)\n        elif instance.cpu_percent &gt; 80:\n            return int(base_limit * 0.7)\n        else:\n            return base_limit\n</code></pre>"},{"location":"developer-guide/load-balancing/#nginx-template-system","title":"Nginx Template System","text":"<p>Main Configuration Template (<code>nginx-main.conf</code>):</p> <pre><code># Orchestry Nginx Configuration\n# Generated at: {{ timestamp }}\n\nuser nginx;\nworker_processes {{ worker_processes }};\nerror_log /var/log/nginx/error.log warn;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections {{ worker_connections }};\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    # Basic settings\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    # Logging format\n    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n                    '$status $body_bytes_sent \"$http_referer\" '\n                    '\"$http_user_agent\" \"$http_x_forwarded_for\" '\n                    'rt=$request_time uct=\"$upstream_connect_time\" '\n                    'uht=\"$upstream_header_time\" urt=\"$upstream_response_time\"';\n\n    # Performance optimizations\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout {{ keepalive_timeout }};\n    types_hash_max_size 2048;\n    client_max_body_size {{ client_max_body_size }};\n\n    # Proxy settings\n    proxy_connect_timeout {{ proxy_connect_timeout }};\n    proxy_send_timeout {{ proxy_send_timeout }};\n    proxy_read_timeout {{ proxy_read_timeout }};\n    proxy_buffer_size {{ proxy_buffer_size }};\n    proxy_buffers {{ proxy_buffers }};\n    proxy_busy_buffers_size 8k;\n    proxy_temp_file_write_size 8k;\n\n    # Compression\n    gzip on;\n    gzip_vary on;\n    gzip_min_length 1024;\n    gzip_proxied any;\n    gzip_comp_level 6;\n    gzip_types\n        text/plain\n        text/css\n        text/xml\n        text/javascript\n        application/json\n        application/javascript\n        application/xml+rss\n        application/atom+xml\n        image/svg+xml;\n\n    # Rate limiting zones\n    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\n    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;\n\n    # Connection limiting\n    limit_conn_zone $binary_remote_addr zone=conn_limit_per_ip:10m;\n\n    # Include upstream configurations\n    {% for app in applications %}\n    include /etc/nginx/conf.d/{{ app }}_upstream.conf;\n    {% endfor %}\n\n    # Include server configurations  \n    {% for app in applications %}\n    include /etc/nginx/conf.d/{{ app }}_server.conf;\n    {% endfor %}\n\n    # Default server (catch-all)\n    include /etc/nginx/conf.d/default.conf;\n}\n</code></pre> <p>Upstream Configuration Template (<code>upstream.conf</code>):</p> <pre><code># Upstream configuration for {{ app_name }}\nupstream {{ app_name }}_upstream {\n    {% if lb_method == 'least_conn' %}\n    least_conn;\n    {% elif lb_method == 'ip_hash' %}\n    ip_hash;\n    {% elif lb_method == 'hash' %}\n    hash $request_uri consistent;\n    {% endif %}\n\n    {% for server in servers %}\n    server {{ server.address }}{% if server.weight != 1 %} weight={{ server.weight }}{% endif %}{% if server.max_fails %} max_fails={{ server.max_fails }}{% endif %}{% if server.fail_timeout %} fail_timeout={{ server.fail_timeout }}{% endif %}{% if server.max_conns %} max_conns={{ server.max_conns }}{% endif %}{% if server.backup %} backup{% endif %};\n    {% endfor %}\n\n    # Connection pooling\n    keepalive {{ keepalive }};\n    keepalive_requests {{ keepalive_requests }};\n    keepalive_timeout {{ keepalive_timeout }};\n}\n</code></pre> <p>Server Configuration Template (<code>server.conf</code>):</p> <pre><code># Server configuration for {{ app_name }}\nserver {\n    listen {{ listen_port }}{% if ssl_enabled %} ssl http2{% endif %};\n    server_name {{ server_name }};\n\n    {% if ssl_enabled %}\n    # SSL configuration\n    ssl_certificate {{ ssl_cert_path }};\n    ssl_certificate_key {{ ssl_key_path }};\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers off;\n    ssl_session_cache shared:SSL:10m;\n    ssl_session_timeout 10m;\n    {% endif %}\n\n    # Logging\n    access_log {{ access_log }} main;\n    error_log {{ error_log }};\n\n    # Basic settings\n    client_max_body_size {{ client_max_body_size }};\n\n    # Custom headers\n    {% for header, value in custom_headers.items() %}\n    add_header {{ header }} \"{{ value }}\" always;\n    {% endfor %}\n\n    # Health check endpoint\n    location {{ health_check_path }} {\n        access_log off;\n        return 200 \"healthy\\n\";\n        add_header Content-Type text/plain;\n    }\n\n    # Status endpoint  \n    location {{ status_check_path }} {\n        access_log off;\n        stub_status on;\n        allow 127.0.0.1;\n        deny all;\n    }\n\n    # Custom location rules\n    {% for location in location_rules %}\n    location {{ location.path }} {\n        {% for directive in location.directives %}\n        {{ directive }};\n        {% endfor %}\n    }\n    {% endfor %}\n\n    # Main application proxy\n    location / {\n        # Rate limiting\n        limit_req zone=api burst=20 nodelay;\n        limit_conn conn_limit_per_ip 20;\n\n        # Proxy headers\n        proxy_pass {{ proxy_pass }};\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Forwarded-Host $server_name;\n        proxy_set_header X-Forwarded-Port $server_port;\n\n        # Timeouts\n        proxy_connect_timeout {{ proxy_timeout }};\n        proxy_send_timeout {{ proxy_timeout }};\n        proxy_read_timeout {{ proxy_timeout }};\n\n        # Buffering\n        proxy_buffering on;\n        proxy_buffer_size 4k;\n        proxy_buffers 8 4k;\n\n        # Cache control\n        proxy_cache_bypass $http_upgrade;\n        proxy_no_cache $http_upgrade;\n    }\n}\n</code></pre>"},{"location":"developer-guide/load-balancing/#upstream-management","title":"Upstream Management","text":""},{"location":"developer-guide/load-balancing/#dynamic-upstream-updates","title":"Dynamic Upstream Updates","text":"<pre><code>class UpstreamManager:\n    \"\"\"Manages Nginx upstream configurations dynamically.\"\"\"\n\n    def __init__(self, nginx_config_dir: str = \"/etc/nginx/conf.d\"):\n        self.config_dir = nginx_config_dir\n        self.config_generator = NginxConfigGenerator({})\n        self.active_upstreams: Dict[str, List[str]] = {}\n        self.upstream_lock = asyncio.Lock()\n\n    async def update_upstream(self, app_name: str, instances: List[InstanceRecord], \n                            lb_method: str = 'round_robin') -&gt; bool:\n        \"\"\"Update upstream configuration for an application.\"\"\"\n        async with self.upstream_lock:\n            try:\n                # Generate new upstream configuration\n                config_content = await self.config_generator.generate_upstream_config(\n                    app_name, instances, lb_method\n                )\n\n                # Write configuration file\n                config_file = os.path.join(self.config_dir, f\"{app_name}_upstream.conf\")\n                async with aiofiles.open(config_file, 'w') as f:\n                    await f.write(config_content)\n\n                # Track current servers\n                current_servers = [f\"{instance.ip}:{instance.port}\" for instance in instances \n                                 if instance.status == 'running' and instance.health_status == 'healthy']\n\n                # Log changes\n                previous_servers = self.active_upstreams.get(app_name, [])\n                added_servers = set(current_servers) - set(previous_servers)\n                removed_servers = set(previous_servers) - set(current_servers)\n\n                if added_servers:\n                    logger.info(f\"Added servers to {app_name}: {added_servers}\")\n                if removed_servers:\n                    logger.info(f\"Removed servers from {app_name}: {removed_servers}\")\n\n                self.active_upstreams[app_name] = current_servers\n\n                return True\n\n            except Exception as e:\n                logger.error(f\"Failed to update upstream for {app_name}: {e}\")\n                return False\n\n    async def add_server_to_upstream(self, app_name: str, server_address: str, \n                                   weight: int = 1, max_fails: int = 3) -&gt; bool:\n        \"\"\"Add a single server to an existing upstream.\"\"\"\n        try:\n            # Read current configuration\n            config_file = os.path.join(self.config_dir, f\"{app_name}_upstream.conf\")\n\n            if not os.path.exists(config_file):\n                logger.warning(f\"Upstream config for {app_name} does not exist\")\n                return False\n\n            async with aiofiles.open(config_file, 'r') as f:\n                content = await f.read()\n\n            # Parse and modify configuration\n            lines = content.split('\\n')\n            modified_lines = []\n            inside_upstream = False\n\n            for line in lines:\n                modified_lines.append(line)\n\n                if f'upstream {app_name}_upstream' in line:\n                    inside_upstream = True\n                elif inside_upstream and line.strip().startswith('server'):\n                    # Check if this is the last server line\n                    continue\n                elif inside_upstream and line.strip() == '}':\n                    # Add new server before closing brace\n                    server_line = f\"    server {server_address}\"\n                    if weight != 1:\n                        server_line += f\" weight={weight}\"\n                    if max_fails != 3:\n                        server_line += f\" max_fails={max_fails}\"\n                    server_line += \";\"\n\n                    modified_lines.insert(-1, server_line)\n                    inside_upstream = False\n\n            # Write updated configuration\n            async with aiofiles.open(config_file, 'w') as f:\n                await f.write('\\n'.join(modified_lines))\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Failed to add server to {app_name}: {e}\")\n            return False\n\n    async def remove_server_from_upstream(self, app_name: str, server_address: str) -&gt; bool:\n        \"\"\"Remove a server from an existing upstream.\"\"\"\n        try:\n            config_file = os.path.join(self.config_dir, f\"{app_name}_upstream.conf\")\n\n            if not os.path.exists(config_file):\n                return False\n\n            async with aiofiles.open(config_file, 'r') as f:\n                content = await f.read()\n\n            # Remove server line\n            lines = content.split('\\n')\n            filtered_lines = [\n                line for line in lines \n                if not (line.strip().startswith('server') and server_address in line)\n            ]\n\n            # Write updated configuration\n            async with aiofiles.open(config_file, 'w') as f:\n                await f.write('\\n'.join(filtered_lines))\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Failed to remove server from {app_name}: {e}\")\n            return False\n\n    async def get_upstream_status(self, app_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Get current upstream status and server information.\"\"\"\n        try:\n            # Use Nginx Plus API if available, otherwise parse config\n            if self._has_nginx_plus_api():\n                return await self._get_upstream_status_from_api(app_name)\n            else:\n                return await self._get_upstream_status_from_config(app_name)\n\n        except Exception as e:\n            logger.error(f\"Failed to get upstream status for {app_name}: {e}\")\n            return {}\n\n    async def _get_upstream_status_from_config(self, app_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Get upstream status by parsing configuration file.\"\"\"\n        config_file = os.path.join(self.config_dir, f\"{app_name}_upstream.conf\")\n\n        if not os.path.exists(config_file):\n            return {'error': 'Upstream configuration not found'}\n\n        async with aiofiles.open(config_file, 'r') as f:\n            content = await f.read()\n\n        servers = []\n        for line in content.split('\\n'):\n            if line.strip().startswith('server'):\n                # Parse server line\n                parts = line.strip().split()\n                if len(parts) &gt;= 2:\n                    address = parts[1].rstrip(';')\n\n                    server_info = {\n                        'address': address,\n                        'weight': 1,\n                        'max_fails': 3,\n                        'fail_timeout': '10s',\n                        'backup': False,\n                        'down': False\n                    }\n\n                    # Parse additional parameters\n                    for part in parts[2:]:\n                        if part.startswith('weight='):\n                            server_info['weight'] = int(part.split('=')[1])\n                        elif part.startswith('max_fails='):\n                            server_info['max_fails'] = int(part.split('=')[1])\n                        elif part.startswith('fail_timeout='):\n                            server_info['fail_timeout'] = part.split('=')[1]\n                        elif part == 'backup':\n                            server_info['backup'] = True\n                        elif part == 'down':\n                            server_info['down'] = True\n\n                    servers.append(server_info)\n\n        return {\n            'upstream': f\"{app_name}_upstream\",\n            'servers': servers,\n            'total_servers': len(servers),\n            'active_servers': len([s for s in servers if not s['down']]),\n            'backup_servers': len([s for s in servers if s['backup']])\n        }\n</code></pre>"},{"location":"developer-guide/load-balancing/#load-balancing-algorithms","title":"Load Balancing Algorithms","text":"<pre><code>class LoadBalancingAlgorithm(Enum):\n    \"\"\"Available load balancing algorithms.\"\"\"\n    ROUND_ROBIN = \"round_robin\"\n    LEAST_CONNECTIONS = \"least_conn\"\n    IP_HASH = \"ip_hash\"\n    HASH = \"hash\"\n    WEIGHTED_ROUND_ROBIN = \"weighted_round_robin\"\n    LEAST_TIME = \"least_time\"\n\nclass LoadBalancingStrategy:\n    \"\"\"Determines optimal load balancing strategy for applications.\"\"\"\n\n    @staticmethod\n    def recommend_algorithm(app_spec: Dict[str, Any], \n                          performance_metrics: Dict[str, Any]) -&gt; LoadBalancingAlgorithm:\n        \"\"\"Recommend load balancing algorithm based on application characteristics.\"\"\"\n\n        # Check if session affinity is required\n        if app_spec.get('spec', {}).get('session_affinity', False):\n            return LoadBalancingAlgorithm.IP_HASH\n\n        # For applications with stateful operations\n        if app_spec.get('spec', {}).get('stateful', False):\n            return LoadBalancingAlgorithm.HASH\n\n        # For high-throughput APIs\n        avg_rps = performance_metrics.get('avg_rps', 0)\n        if avg_rps &gt; 1000:\n            return LoadBalancingAlgorithm.LEAST_CONNECTIONS\n\n        # For applications with varying response times\n        response_time_variance = performance_metrics.get('response_time_variance', 0)\n        if response_time_variance &gt; 100:  # High variance in response times\n            return LoadBalancingAlgorithm.LEAST_TIME\n\n        # Default to round robin\n        return LoadBalancingAlgorithm.ROUND_ROBIN\n\n    @staticmethod\n    def get_nginx_directive(algorithm: LoadBalancingAlgorithm, \n                          params: Dict[str, Any] = None) -&gt; str:\n        \"\"\"Get Nginx directive for load balancing algorithm.\"\"\"\n        params = params or {}\n\n        if algorithm == LoadBalancingAlgorithm.LEAST_CONNECTIONS:\n            return \"least_conn;\"\n        elif algorithm == LoadBalancingAlgorithm.IP_HASH:\n            return \"ip_hash;\"\n        elif algorithm == LoadBalancingAlgorithm.HASH:\n            hash_key = params.get('hash_key', '$request_uri')\n            consistent = \"consistent\" if params.get('consistent', True) else \"\"\n            return f\"hash {hash_key} {consistent};\"\n        elif algorithm == LoadBalancingAlgorithm.LEAST_TIME:\n            # Nginx Plus feature\n            return \"least_time header;\"\n        else:\n            return \"\"  # Round robin is default, no directive needed\n</code></pre>"},{"location":"developer-guide/load-balancing/#ssltls-management","title":"SSL/TLS Management","text":""},{"location":"developer-guide/load-balancing/#certificate-management","title":"Certificate Management","text":"<pre><code>class SSLManager:\n    \"\"\"Manages SSL certificates for applications.\"\"\"\n\n    def __init__(self, cert_dir: str = \"/etc/ssl/orchestry\"):\n        self.cert_dir = cert_dir\n        self.ca_client = None  # ACME client for Let's Encrypt\n\n    async def initialize(self):\n        \"\"\"Initialize SSL management.\"\"\"\n        os.makedirs(self.cert_dir, exist_ok=True)\n        os.makedirs(f\"{self.cert_dir}/private\", mode=0o700, exist_ok=True)\n        os.makedirs(f\"{self.cert_dir}/certs\", exist_ok=True)\n\n    async def provision_certificate(self, domain: str, app_name: str) -&gt; bool:\n        \"\"\"Provision SSL certificate for a domain.\"\"\"\n        try:\n            cert_path = f\"{self.cert_dir}/certs/{app_name}.crt\"\n            key_path = f\"{self.cert_dir}/private/{app_name}.key\"\n\n            # Check if certificate already exists and is valid\n            if await self._is_certificate_valid(cert_path, domain):\n                logger.info(f\"Valid certificate already exists for {domain}\")\n                return True\n\n            # Generate certificate using ACME (Let's Encrypt)\n            if self.config.get('ssl_provider') == 'letsencrypt':\n                return await self._provision_letsencrypt_certificate(domain, cert_path, key_path)\n            else:\n                # Generate self-signed certificate for development\n                return await self._generate_self_signed_certificate(domain, cert_path, key_path)\n\n        except Exception as e:\n            logger.error(f\"Failed to provision certificate for {domain}: {e}\")\n            return False\n\n    async def _provision_letsencrypt_certificate(self, domain: str, cert_path: str, key_path: str) -&gt; bool:\n        \"\"\"Provision certificate from Let's Encrypt.\"\"\"\n        try:\n            # Use certbot or acme library\n            cmd = [\n                'certbot', 'certonly',\n                '--webroot',\n                '--webroot-path', '/var/www/html',\n                '--email', self.config.get('ssl_email', 'admin@example.com'),\n                '--agree-tos',\n                '--non-interactive',\n                '--domain', domain,\n                '--cert-path', cert_path,\n                '--key-path', key_path\n            ]\n\n            process = await asyncio.create_subprocess_exec(\n                *cmd,\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE\n            )\n\n            stdout, stderr = await process.communicate()\n\n            if process.returncode == 0:\n                logger.info(f\"Successfully provisioned Let's Encrypt certificate for {domain}\")\n                return True\n            else:\n                logger.error(f\"Certbot failed: {stderr.decode()}\")\n                return False\n\n        except Exception as e:\n            logger.error(f\"Let's Encrypt provisioning failed: {e}\")\n            return False\n\n    async def _generate_self_signed_certificate(self, domain: str, cert_path: str, key_path: str) -&gt; bool:\n        \"\"\"Generate self-signed certificate for development.\"\"\"\n        try:\n            # Generate private key\n            key_cmd = [\n                'openssl', 'genrsa',\n                '-out', key_path,\n                '2048'\n            ]\n\n            await asyncio.create_subprocess_exec(*key_cmd)\n\n            # Generate certificate\n            cert_cmd = [\n                'openssl', 'req',\n                '-new', '-x509',\n                '-key', key_path,\n                '-out', cert_path,\n                '-days', '365',\n                '-subj', f'/CN={domain}'\n            ]\n\n            process = await asyncio.create_subprocess_exec(*cert_cmd)\n            await process.communicate()\n\n            if process.returncode == 0:\n                logger.info(f\"Generated self-signed certificate for {domain}\")\n                return True\n            else:\n                return False\n\n        except Exception as e:\n            logger.error(f\"Self-signed certificate generation failed: {e}\")\n            return False\n\n    async def _is_certificate_valid(self, cert_path: str, domain: str) -&gt; bool:\n        \"\"\"Check if certificate exists and is valid.\"\"\"\n        if not os.path.exists(cert_path):\n            return False\n\n        try:\n            # Check certificate expiration\n            cmd = [\n                'openssl', 'x509',\n                '-in', cert_path,\n                '-noout',\n                '-dates'\n            ]\n\n            process = await asyncio.create_subprocess_exec(\n                *cmd,\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE\n            )\n\n            stdout, stderr = await process.communicate()\n\n            if process.returncode != 0:\n                return False\n\n            # Parse expiration date\n            output = stdout.decode()\n            for line in output.split('\\n'):\n                if line.startswith('notAfter='):\n                    expire_str = line.split('=', 1)[1]\n                    expire_date = datetime.strptime(expire_str, '%b %d %H:%M:%S %Y %Z')\n\n                    # Check if certificate expires within 30 days\n                    if expire_date - datetime.now() &lt; timedelta(days=30):\n                        return False\n\n            return True\n\n        except Exception as e:\n            logger.error(f\"Certificate validation failed: {e}\")\n            return False\n\n    async def renew_certificates(self) -&gt; Dict[str, bool]:\n        \"\"\"Renew expiring certificates.\"\"\"\n        renewal_results = {}\n\n        # Find all certificates\n        cert_dir = f\"{self.cert_dir}/certs\"\n        if not os.path.exists(cert_dir):\n            return renewal_results\n\n        for cert_file in os.listdir(cert_dir):\n            if not cert_file.endswith('.crt'):\n                continue\n\n            app_name = cert_file[:-4]  # Remove .crt extension\n            cert_path = os.path.join(cert_dir, cert_file)\n\n            try:\n                # Get domain from certificate\n                domain = await self._get_certificate_domain(cert_path)\n\n                # Check if renewal is needed\n                if not await self._is_certificate_valid(cert_path, domain):\n                    logger.info(f\"Renewing certificate for {domain}\")\n                    key_path = f\"{self.cert_dir}/private/{app_name}.key\"\n                    success = await self.provision_certificate(domain, app_name)\n                    renewal_results[domain] = success\n                else:\n                    renewal_results[domain] = True  # Still valid\n\n            except Exception as e:\n                logger.error(f\"Certificate renewal failed for {app_name}: {e}\")\n                renewal_results[app_name] = False\n\n        return renewal_results\n</code></pre>"},{"location":"developer-guide/load-balancing/#traffic-routing-and-rules","title":"Traffic Routing and Rules","text":""},{"location":"developer-guide/load-balancing/#advanced-routing-configuration","title":"Advanced Routing Configuration","text":"<pre><code>class TrafficRouter:\n    \"\"\"Manages advanced traffic routing rules.\"\"\"\n\n    def __init__(self):\n        self.routing_rules: Dict[str, List[RoutingRule]] = {}\n\n    async def add_routing_rule(self, app_name: str, rule: RoutingRule):\n        \"\"\"Add a traffic routing rule for an application.\"\"\"\n        if app_name not in self.routing_rules:\n            self.routing_rules[app_name] = []\n\n        self.routing_rules[app_name].append(rule)\n        await self._update_nginx_routing(app_name)\n\n    async def remove_routing_rule(self, app_name: str, rule_id: str):\n        \"\"\"Remove a traffic routing rule.\"\"\"\n        if app_name in self.routing_rules:\n            self.routing_rules[app_name] = [\n                rule for rule in self.routing_rules[app_name] \n                if rule.id != rule_id\n            ]\n            await self._update_nginx_routing(app_name)\n\n    async def _update_nginx_routing(self, app_name: str):\n        \"\"\"Update Nginx configuration with routing rules.\"\"\"\n        rules = self.routing_rules.get(app_name, [])\n\n        # Generate location blocks for each rule\n        location_blocks = []\n        for rule in rules:\n            location_block = self._generate_location_block(rule)\n            location_blocks.append(location_block)\n\n        # Update server configuration\n        await self._inject_location_blocks(app_name, location_blocks)\n\n    def _generate_location_block(self, rule: RoutingRule) -&gt; str:\n        \"\"\"Generate Nginx location block for a routing rule.\"\"\"\n        if rule.type == RoutingType.PATH:\n            location = f'location {rule.path}'\n        elif rule.type == RoutingType.REGEX:\n            location = f'location ~ {rule.pattern}'\n        elif rule.type == RoutingType.EXACT:\n            location = f'location = {rule.path}'\n        else:\n            location = f'location {rule.path}'\n\n        directives = []\n\n        # Add header-based routing\n        if rule.headers:\n            for header, value in rule.headers.items():\n                if rule.header_match_type == HeaderMatchType.EXACT:\n                    directives.append(f'if ($http_{header.lower().replace(\"-\", \"_\")} != \"{value}\") {{ return 404; }}')\n                elif rule.header_match_type == HeaderMatchType.REGEX:\n                    directives.append(f'if ($http_{header.lower().replace(\"-\", \"_\")} !~ \"{value}\") {{ return 404; }}')\n\n        # Add weight-based routing (A/B testing)\n        if rule.weight_percentage and rule.weight_percentage &lt; 100:\n            directives.append(f'split_clients $request_id $variant {{')\n            directives.append(f'    {rule.weight_percentage}% \"primary\";')\n            directives.append(f'    * \"secondary\";')\n            directives.append(f'}}')\n            directives.append(f'if ($variant = \"secondary\") {{ proxy_pass {rule.secondary_upstream}; }}')\n\n        # Add rate limiting\n        if rule.rate_limit:\n            directives.append(f'limit_req zone={rule.rate_limit.zone} burst={rule.rate_limit.burst}')\n\n        # Add custom headers\n        if rule.response_headers:\n            for header, value in rule.response_headers.items():\n                directives.append(f'add_header {header} \"{value}\" always;')\n\n        # Add proxy configuration\n        if rule.upstream:\n            directives.append(f'proxy_pass {rule.upstream};')\n        else:\n            directives.append(f'proxy_pass http://{rule.app_name}_upstream;')\n\n        # Add proxy headers\n        directives.extend([\n            'proxy_set_header Host $host;',\n            'proxy_set_header X-Real-IP $remote_addr;',\n            'proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;',\n            'proxy_set_header X-Forwarded-Proto $scheme;'\n        ])\n\n        # Build complete location block\n        block = f'{location} {{\\n'\n        for directive in directives:\n            block += f'    {directive}\\n'\n        block += '}\\n'\n\n        return block\n\n@dataclass\nclass RoutingRule:\n    \"\"\"Traffic routing rule configuration.\"\"\"\n    id: str\n    app_name: str\n    type: RoutingType\n    path: Optional[str] = None\n    pattern: Optional[str] = None\n    headers: Optional[Dict[str, str]] = None\n    header_match_type: HeaderMatchType = HeaderMatchType.EXACT\n    weight_percentage: Optional[int] = None\n    secondary_upstream: Optional[str] = None\n    rate_limit: Optional[RateLimitConfig] = None\n    response_headers: Optional[Dict[str, str]] = None\n    upstream: Optional[str] = None\n    priority: int = 100\n    enabled: bool = True\n\nclass RoutingType(Enum):\n    \"\"\"Types of routing rules.\"\"\"\n    PATH = \"path\"\n    REGEX = \"regex\"\n    EXACT = \"exact\"\n    PREFIX = \"prefix\"\n\nclass HeaderMatchType(Enum):\n    \"\"\"Header matching types.\"\"\"\n    EXACT = \"exact\"\n    REGEX = \"regex\"\n    EXISTS = \"exists\"\n\n@dataclass\nclass RateLimitConfig:\n    \"\"\"Rate limiting configuration.\"\"\"\n    zone: str\n    burst: int = 10\n    nodelay: bool = True\n</code></pre>"},{"location":"developer-guide/load-balancing/#monitoring-and-metrics","title":"Monitoring and Metrics","text":""},{"location":"developer-guide/load-balancing/#load-balancer-metrics","title":"Load Balancer Metrics","text":"<pre><code>class LoadBalancerMetrics:\n    \"\"\"Collects and reports load balancer metrics.\"\"\"\n\n    async def collect_nginx_metrics(self) -&gt; Dict[str, Any]:\n        \"\"\"Collect metrics from Nginx.\"\"\"\n        metrics = {}\n\n        # Basic Nginx metrics\n        nginx_status = await self._get_nginx_status()\n        metrics.update(nginx_status)\n\n        # Upstream metrics\n        for app_name in self.active_applications:\n            upstream_metrics = await self._get_upstream_metrics(app_name)\n            metrics[f\"upstream_{app_name}\"] = upstream_metrics\n\n        # Connection metrics\n        connection_metrics = await self._get_connection_metrics()\n        metrics[\"connections\"] = connection_metrics\n\n        # Request metrics\n        request_metrics = await self._get_request_metrics()\n        metrics[\"requests\"] = request_metrics\n\n        return metrics\n\n    async def _get_nginx_status(self) -&gt; Dict[str, Any]:\n        \"\"\"Get basic Nginx status metrics.\"\"\"\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get('http://localhost/nginx_status') as response:\n                    text = await response.text()\n\n                    # Parse Nginx status format\n                    lines = text.strip().split('\\n')\n\n                    # Active connections\n                    active_connections = int(lines[0].split(':')[1].strip())\n\n                    # Server statistics\n                    server_stats = lines[2].split()\n                    accepts = int(server_stats[0])\n                    handled = int(server_stats[1])\n                    requests = int(server_stats[2])\n\n                    # Reading, Writing, Waiting\n                    conn_stats = lines[3].split()\n                    reading = int(conn_stats[1])\n                    writing = int(conn_stats[3])\n                    waiting = int(conn_stats[5])\n\n                    return {\n                        'active_connections': active_connections,\n                        'total_accepts': accepts,\n                        'total_handled': handled,\n                        'total_requests': requests,\n                        'reading': reading,\n                        'writing': writing,\n                        'waiting': waiting,\n                        'requests_per_connection': requests / handled if handled &gt; 0 else 0\n                    }\n\n        except Exception as e:\n            logger.error(f\"Failed to get Nginx status: {e}\")\n            return {}\n\n    async def _get_upstream_metrics(self, app_name: str) -&gt; Dict[str, Any]:\n        \"\"\"Get metrics for a specific upstream.\"\"\"\n        # This would typically use Nginx Plus API or parse access logs\n        # For now, return mock data structure\n        return {\n            'total_servers': 0,\n            'active_servers': 0,\n            'requests_per_second': 0,\n            'response_time_avg': 0,\n            'response_time_p95': 0,\n            'error_rate': 0,\n            'server_stats': []\n        }\n</code></pre> <p>Next Steps: Learn about Development Setup and contribution guidelines.</p>"},{"location":"developer-guide/scaling/","title":"Scaling Algorithm","text":"<p>Deep dive into Orchestry's multi-metric auto-scaling algorithm, policies, and decision-making process.</p>"},{"location":"developer-guide/scaling/#overview","title":"Overview","text":"<p>Orchestry uses a sophisticated multi-metric scaling algorithm that considers CPU utilization, memory usage, request rate, response latency, and active connections to make intelligent scaling decisions. The algorithm is designed to be predictive, stable, and configurable.</p>"},{"location":"developer-guide/scaling/#core-algorithm","title":"Core Algorithm","text":""},{"location":"developer-guide/scaling/#scaling-decision-flow","title":"Scaling Decision Flow","text":"<pre><code>graph TD\n    A[Collect Metrics] --&gt; B[Calculate Scale Factors]\n    B --&gt; C{In Cooldown?}\n    C --&gt;|Yes| D[No Scaling]\n    C --&gt;|No| E[Evaluate Thresholds]\n    E --&gt; F{Any Metric &gt; Scale Out Threshold?}\n    F --&gt;|Yes| G[Calculate Scale Out Target]\n    F --&gt;|No| H{All Metrics &lt; Scale In Threshold?}\n    H --&gt;|Yes| I[Calculate Scale In Target]\n    H --&gt;|No| J[No Scaling Needed]\n    G --&gt; K[Apply Constraints]\n    I --&gt; K\n    K --&gt; L[Execute Scaling]\n    L --&gt; M[Log Decision]\n    D --&gt; M\n    J --&gt; M\n</code></pre>"},{"location":"developer-guide/scaling/#scale-factor-calculation","title":"Scale Factor Calculation","text":"<p>Each metric is normalized to a scale factor representing resource pressure:</p> <pre><code>def calculate_scale_factors(self, metrics: ScalingMetrics, policy: ScalingPolicy) -&gt; Dict[str, float]:\n    \"\"\"\n    Calculate normalized scale factors for each metric.\n    A factor of 1.0 means the metric is at its target.\n    A factor &gt; 1.0 indicates pressure (potential scale out).\n    A factor &lt; 1.0 indicates underutilization (potential scale in).\n    \"\"\"\n    factors = {}\n\n    # CPU Utilization Factor\n    # Target: policy.max_cpu_percent (default: 70%)\n    if policy.max_cpu_percent &gt; 0:\n        factors['cpu'] = metrics.cpu_percent / policy.max_cpu_percent\n\n    # Memory Utilization Factor  \n    # Target: policy.max_memory_percent (default: 75%)\n    if policy.max_memory_percent &gt; 0:\n        factors['memory'] = metrics.memory_percent / policy.max_memory_percent\n\n    # Requests Per Second Factor\n    # Target: policy.target_rps_per_replica RPS per healthy replica\n    if policy.target_rps_per_replica &gt; 0 and metrics.healthy_replicas &gt; 0:\n        current_rps_per_replica = metrics.rps / metrics.healthy_replicas\n        factors['rps'] = current_rps_per_replica / policy.target_rps_per_replica\n\n    # Response Latency Factor\n    # Target: policy.max_p95_latency_ms (default: 250ms)\n    if policy.max_p95_latency_ms &gt; 0:\n        factors['latency'] = metrics.p95_latency_ms / policy.max_p95_latency_ms\n\n    # Connection Count Factor\n    # Target: policy.max_conn_per_replica connections per healthy replica\n    if policy.max_conn_per_replica &gt; 0 and metrics.healthy_replicas &gt; 0:\n        current_conn_per_replica = metrics.active_connections / metrics.healthy_replicas\n        factors['connections'] = current_conn_per_replica / policy.max_conn_per_replica\n\n    return factors\n</code></pre>"},{"location":"developer-guide/scaling/#scaling-policies","title":"Scaling Policies","text":""},{"location":"developer-guide/scaling/#policy-structure","title":"Policy Structure","text":"<pre><code>@dataclass\nclass ScalingPolicy:\n    \"\"\"Comprehensive scaling policy configuration.\"\"\"\n\n    # Replica bounds\n    min_replicas: int = 1\n    max_replicas: int = 5\n\n    # Performance targets\n    target_rps_per_replica: int = 50        # Target requests/sec per replica\n    max_p95_latency_ms: int = 250          # Maximum 95th percentile latency\n    max_conn_per_replica: int = 80         # Maximum connections per replica\n    max_cpu_percent: float = 70.0          # Maximum CPU utilization %\n    max_memory_percent: float = 75.0       # Maximum memory utilization %\n\n    # Scaling thresholds\n    scale_out_threshold_pct: int = 80      # Scale out when factor &gt; 80% of target\n    scale_in_threshold_pct: int = 30       # Scale in when factor &lt; 30% of target\n\n    # Timing configuration\n    window_seconds: int = 60               # Metrics evaluation window\n    cooldown_seconds: int = 180            # Minimum time between scaling events\n\n    # Advanced settings\n    max_scale_out_step: int = 0            # Max replicas to add (0 = unlimited)\n    max_scale_in_step: int = 1             # Max replicas to remove per operation\n    stabilization_window_seconds: int = 300 # Time to wait for stability\n\n    # Metric weights (future enhancement)\n    cpu_weight: float = 1.0\n    memory_weight: float = 1.0\n    rps_weight: float = 1.0\n    latency_weight: float = 1.5            # Latency gets higher priority\n    connection_weight: float = 0.8\n</code></pre>"},{"location":"developer-guide/scaling/#policy-examples","title":"Policy Examples","text":""},{"location":"developer-guide/scaling/#latency-sensitive-application","title":"Latency-Sensitive Application","text":"<pre><code>latency_sensitive_policy = ScalingPolicy(\n    min_replicas=3,                        # Always maintain 3 replicas\n    max_replicas=20,                       # Can scale up to 20\n    target_rps_per_replica=30,             # Lower RPS target\n    max_p95_latency_ms=100,                # Strict 100ms latency limit\n    max_cpu_percent=60.0,                  # Conservative CPU target\n    scale_out_threshold_pct=70,            # Scale out early\n    scale_in_threshold_pct=20,             # Scale in conservatively\n    cooldown_seconds=120,                  # Faster scaling decisions\n    stabilization_window_seconds=180       # Shorter stability window\n)\n</code></pre>"},{"location":"developer-guide/scaling/#batch-processing-application","title":"Batch Processing Application","text":"<pre><code>batch_processing_policy = ScalingPolicy(\n    min_replicas=1,                        # Can scale to zero\n    max_replicas=50,                       # High maximum for bursts\n    target_rps_per_replica=200,            # Higher RPS tolerance\n    max_p95_latency_ms=2000,               # More latency tolerance\n    max_cpu_percent=90.0,                  # High CPU utilization OK\n    max_memory_percent=85.0,               # High memory utilization OK\n    scale_out_threshold_pct=85,            # Scale out later\n    scale_in_threshold_pct=15,             # Scale in aggressively\n    cooldown_seconds=300,                  # Slower scaling decisions\n    max_scale_out_step=5                   # Scale out in larger steps\n)\n</code></pre>"},{"location":"developer-guide/scaling/#development-environment","title":"Development Environment","text":"<pre><code>dev_policy = ScalingPolicy(\n    min_replicas=1,\n    max_replicas=3,                        # Limited scaling for dev\n    target_rps_per_replica=10,             # Low traffic expected\n    max_p95_latency_ms=1000,               # Relaxed latency\n    max_cpu_percent=80.0,\n    scale_out_threshold_pct=90,            # Scale out very late\n    scale_in_threshold_pct=10,             # Scale in very early\n    cooldown_seconds=600,                  # Long cooldown for stability\n    stabilization_window_seconds=600\n)\n</code></pre>"},{"location":"developer-guide/scaling/#scaling-decision-logic","title":"Scaling Decision Logic","text":""},{"location":"developer-guide/scaling/#scale-out-decision","title":"Scale Out Decision","text":"<pre><code>def should_scale_out(self, scale_factors: Dict[str, float], policy: ScalingPolicy) -&gt; Tuple[bool, str, List[str]]:\n    \"\"\"\n    Determine if scale out is needed.\n\n    Scale out if ANY metric exceeds the scale out threshold.\n    This ensures responsive scaling when any resource becomes constrained.\n    \"\"\"\n    threshold = policy.scale_out_threshold_pct / 100.0\n    triggered_metrics = []\n\n    for metric_name, factor in scale_factors.items():\n        if factor &gt; threshold:\n            triggered_metrics.append(metric_name)\n\n    if triggered_metrics:\n        # Find the most constrained metric\n        max_metric = max(scale_factors.items(), key=lambda x: x[1])\n        reason = f\"Scale out triggered by {max_metric[0]}: {max_metric[1]:.2f}x target\"\n        return True, reason, triggered_metrics\n\n    return False, \"All metrics below scale out threshold\", []\n</code></pre>"},{"location":"developer-guide/scaling/#scale-in-decision","title":"Scale In Decision","text":"<pre><code>def should_scale_in(self, scale_factors: Dict[str, float], policy: ScalingPolicy, current_replicas: int) -&gt; Tuple[bool, str]:\n    \"\"\"\n    Determine if scale in is needed.\n\n    Scale in only if ALL metrics are below the scale in threshold.\n    This ensures we don't scale in prematurely while any resource is under pressure.\n    \"\"\"\n    if current_replicas &lt;= policy.min_replicas:\n        return False, f\"Already at minimum replicas ({policy.min_replicas})\"\n\n    threshold = policy.scale_in_threshold_pct / 100.0\n\n    for metric_name, factor in scale_factors.items():\n        if factor &gt; threshold:\n            return False, f\"Cannot scale in: {metric_name} factor {factor:.2f} &gt; threshold {threshold:.2f}\"\n\n    # All metrics are below threshold\n    max_factor = max(scale_factors.values()) if scale_factors else 0\n    reason = f\"Scale in: All metrics below threshold (max factor: {max_factor:.2f})\"\n    return True, reason\n</code></pre>"},{"location":"developer-guide/scaling/#target-replica-calculation","title":"Target Replica Calculation","text":""},{"location":"developer-guide/scaling/#scale-out-target","title":"Scale Out Target","text":"<pre><code>def calculate_scale_out_target(self, current_replicas: int, scale_factors: Dict[str, float], \n                              policy: ScalingPolicy) -&gt; int:\n    \"\"\"\n    Calculate target replicas for scale out operation.\n\n    Uses the highest scale factor to determine how many replicas are needed\n    to bring all metrics back within acceptable ranges.\n    \"\"\"\n    if not scale_factors:\n        return current_replicas + 1\n\n    # Find the metric with highest pressure\n    max_factor = max(scale_factors.values())\n\n    # Calculate theoretical target based on max factor\n    # If factor is 1.5, we need 50% more capacity\n    theoretical_target = math.ceil(current_replicas * max_factor)\n\n    # Apply step limits\n    if policy.max_scale_out_step &gt; 0:\n        max_increase = policy.max_scale_out_step\n        theoretical_target = min(theoretical_target, current_replicas + max_increase)\n\n    # Conservative scaling: don't increase by more than 100% at once\n    max_conservative = current_replicas * 2\n    theoretical_target = min(theoretical_target, max_conservative)\n\n    # Apply absolute maximum\n    final_target = min(theoretical_target, policy.max_replicas)\n\n    # Ensure we're actually scaling out\n    return max(final_target, current_replicas + 1)\n</code></pre>"},{"location":"developer-guide/scaling/#scale-in-target","title":"Scale In Target","text":"<pre><code>def calculate_scale_in_target(self, current_replicas: int, scale_factors: Dict[str, float], \n                             policy: ScalingPolicy) -&gt; int:\n    \"\"\"\n    Calculate target replicas for scale in operation.\n\n    Uses conservative approach - remove one replica at a time unless\n    utilization is extremely low.\n    \"\"\"\n    if current_replicas &lt;= policy.min_replicas:\n        return current_replicas\n\n    # Default: scale in by 1 replica\n    target = current_replicas - 1\n\n    # If utilization is very low, consider scaling in more aggressively\n    if scale_factors:\n        max_factor = max(scale_factors.values())\n        if max_factor &lt; 0.1:  # Less than 10% utilization\n            # Can scale in more aggressively\n            theoretical_target = math.floor(current_replicas * max_factor * 2)  # 2x buffer\n            target = max(theoretical_target, policy.min_replicas)\n\n    # Apply step limits\n    if policy.max_scale_in_step &gt; 0:\n        max_decrease = policy.max_scale_in_step\n        target = max(target, current_replicas - max_decrease)\n\n    # Ensure we don't go below minimum\n    return max(target, policy.min_replicas)\n</code></pre>"},{"location":"developer-guide/scaling/#cooldown-and-stability","title":"Cooldown and Stability","text":""},{"location":"developer-guide/scaling/#cooldown-management","title":"Cooldown Management","text":"<pre><code>def is_in_cooldown(self, app_name: str, cooldown_seconds: int) -&gt; bool:\n    \"\"\"\n    Check if application is in cooldown period.\n\n    Cooldown prevents rapid scaling oscillations by enforcing\n    minimum time between scaling operations.\n    \"\"\"\n    last_scale_time = self.last_scale_time.get(app_name, 0)\n    return time.time() - last_scale_time &lt; cooldown_seconds\n\ndef update_cooldown_timer(self, app_name: str):\n    \"\"\"Update the last scaling time for cooldown calculation.\"\"\"\n    self.last_scale_time[app_name] = time.time()\n</code></pre>"},{"location":"developer-guide/scaling/#stability-window","title":"Stability Window","text":"<pre><code>def is_system_stable(self, app_name: str, policy: ScalingPolicy) -&gt; bool:\n    \"\"\"\n    Check if the system has been stable for the required period.\n\n    Stability window ensures the system has had time to adapt to\n    previous scaling decisions before making new ones.\n    \"\"\"\n    # Get recent scaling events\n    recent_events = self.get_recent_scaling_events(\n        app_name, \n        since=time.time() - policy.stabilization_window_seconds\n    )\n\n    # System is stable if no scaling events in the stability window\n    return len(recent_events) == 0\n</code></pre>"},{"location":"developer-guide/scaling/#metrics-collection-and-analysis","title":"Metrics Collection and Analysis","text":""},{"location":"developer-guide/scaling/#metrics-aggregation","title":"Metrics Aggregation","text":"<pre><code>def aggregate_metrics(self, app_name: str, window_seconds: int) -&gt; ScalingMetrics:\n    \"\"\"\n    Aggregate metrics over the specified time window.\n\n    Uses different aggregation methods for different metrics:\n    - CPU/Memory: Average over window\n    - RPS: Rate calculation over window  \n    - Latency: 95th percentile over window\n    - Connections: Current value (latest)\n    \"\"\"\n    cutoff_time = time.time() - window_seconds\n    history = self.metrics_history[app_name]\n\n    # Filter metrics within window\n    cpu_points = [p for p in history['cpu'] if p.timestamp &gt;= cutoff_time]\n    memory_points = [p for p in history['memory'] if p.timestamp &gt;= cutoff_time]\n    rps_points = [p for p in history['rps'] if p.timestamp &gt;= cutoff_time]\n    latency_points = [p for p in history['latency'] if p.timestamp &gt;= cutoff_time]\n    connection_points = [p for p in history['connections'] if p.timestamp &gt;= cutoff_time]\n    replica_points = [p for p in history['healthy_replicas'] if p.timestamp &gt;= cutoff_time]\n\n    # Calculate aggregated values\n    metrics = ScalingMetrics()\n\n    if cpu_points:\n        metrics.cpu_percent = statistics.mean([p.value for p in cpu_points])\n\n    if memory_points:\n        metrics.memory_percent = statistics.mean([p.value for p in memory_points])\n\n    if rps_points and len(rps_points) &gt;= 2:\n        # Calculate rate from first and last points\n        first_point = rps_points[0]\n        last_point = rps_points[-1]\n        time_diff = last_point.timestamp - first_point.timestamp\n        if time_diff &gt; 0:\n            metrics.rps = (last_point.value - first_point.value) / time_diff\n\n    if latency_points:\n        # Use 95th percentile\n        latencies = sorted([p.value for p in latency_points])\n        percentile_idx = int(0.95 * len(latencies))\n        metrics.p95_latency_ms = latencies[percentile_idx]\n\n    if connection_points:\n        # Use latest value\n        metrics.active_connections = connection_points[-1].value\n\n    if replica_points:\n        # Use latest healthy replica count\n        metrics.healthy_replicas = int(replica_points[-1].value)\n        metrics.total_replicas = self.get_total_replicas(app_name)\n\n    return metrics\n</code></pre>"},{"location":"developer-guide/scaling/#smoothing-and-filtering","title":"Smoothing and Filtering","text":"<pre><code>def apply_smoothing(self, current_metrics: ScalingMetrics, \n                   previous_metrics: ScalingMetrics, alpha: float = 0.3) -&gt; ScalingMetrics:\n    \"\"\"\n    Apply exponential smoothing to reduce noise in metrics.\n\n    Uses exponential weighted moving average:\n    smoothed_value = alpha * current + (1 - alpha) * previous\n    \"\"\"\n    if not previous_metrics:\n        return current_metrics\n\n    smoothed = ScalingMetrics()\n    smoothed.cpu_percent = alpha * current_metrics.cpu_percent + (1 - alpha) * previous_metrics.cpu_percent\n    smoothed.memory_percent = alpha * current_metrics.memory_percent + (1 - alpha) * previous_metrics.memory_percent\n    smoothed.rps = alpha * current_metrics.rps + (1 - alpha) * previous_metrics.rps\n    smoothed.p95_latency_ms = alpha * current_metrics.p95_latency_ms + (1 - alpha) * previous_metrics.p95_latency_ms\n    smoothed.active_connections = current_metrics.active_connections  # Don't smooth discrete values\n    smoothed.healthy_replicas = current_metrics.healthy_replicas\n    smoothed.total_replicas = current_metrics.total_replicas\n\n    return smoothed\n</code></pre>"},{"location":"developer-guide/scaling/#advanced-features","title":"Advanced Features","text":""},{"location":"developer-guide/scaling/#predictive-scaling","title":"Predictive Scaling","text":"<pre><code>def predict_future_load(self, app_name: str, lookahead_minutes: int = 5) -&gt; ScalingMetrics:\n    \"\"\"\n    Predict future load based on historical trends.\n\n    Uses linear regression on recent metrics to predict future values.\n    This enables proactive scaling before resources become constrained.\n    \"\"\"\n    history = self.metrics_history[app_name]\n    current_time = time.time()\n    lookback_seconds = lookahead_minutes * 60 * 4  # Look back 4x the prediction window\n\n    # Get recent RPS data points\n    rps_points = [p for p in history['rps'] \n                  if p.timestamp &gt;= current_time - lookback_seconds]\n\n    if len(rps_points) &lt; 10:  # Need sufficient data\n        return self.get_current_metrics(app_name)\n\n    # Simple linear trend calculation\n    x_values = [p.timestamp - current_time for p in rps_points]\n    y_values = [p.value for p in rps_points]\n\n    # Calculate trend (slope)\n    n = len(x_values)\n    sum_x = sum(x_values)\n    sum_y = sum(y_values)\n    sum_xy = sum(x * y for x, y in zip(x_values, y_values))\n    sum_x2 = sum(x * x for x in x_values)\n\n    slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)\n    intercept = (sum_y - slope * sum_x) / n\n\n    # Predict future RPS\n    future_time = lookahead_minutes * 60\n    predicted_rps = slope * future_time + intercept\n\n    # Create predicted metrics\n    current_metrics = self.get_current_metrics(app_name)\n    predicted_metrics = ScalingMetrics(\n        rps=max(predicted_rps, 0),  # RPS can't be negative\n        cpu_percent=current_metrics.cpu_percent,\n        memory_percent=current_metrics.memory_percent,\n        p95_latency_ms=current_metrics.p95_latency_ms,\n        active_connections=current_metrics.active_connections,\n        healthy_replicas=current_metrics.healthy_replicas,\n        total_replicas=current_metrics.total_replicas\n    )\n\n    return predicted_metrics\n</code></pre>"},{"location":"developer-guide/scaling/#custom-scaling-strategies","title":"Custom Scaling Strategies","text":"<pre><code>class ScalingStrategy:\n    \"\"\"Base class for custom scaling strategies.\"\"\"\n\n    def should_scale(self, metrics: ScalingMetrics, policy: ScalingPolicy) -&gt; ScalingDecision:\n        raise NotImplementedError\n\nclass ConservativeStrategy(ScalingStrategy):\n    \"\"\"Conservative scaling strategy - prefers stability over responsiveness.\"\"\"\n\n    def should_scale(self, metrics: ScalingMetrics, policy: ScalingPolicy) -&gt; ScalingDecision:\n        # Require multiple metrics to be over threshold\n        scale_factors = calculate_scale_factors(metrics, policy)\n        over_threshold = sum(1 for f in scale_factors.values() \n                           if f &gt; policy.scale_out_threshold_pct / 100)\n\n        if over_threshold &gt;= 2:  # Require at least 2 metrics\n            return ScalingDecision(should_scale=True, direction='out')\n\n        # Scale in only if all metrics very low\n        if all(f &lt; policy.scale_in_threshold_pct / 200 for f in scale_factors.values()):\n            return ScalingDecision(should_scale=True, direction='in')\n\n        return ScalingDecision(should_scale=False)\n\nclass AggressiveStrategy(ScalingStrategy):\n    \"\"\"Aggressive scaling strategy - prioritizes performance over cost.\"\"\"\n\n    def should_scale(self, metrics: ScalingMetrics, policy: ScalingPolicy) -&gt; ScalingDecision:\n        scale_factors = calculate_scale_factors(metrics, policy)\n\n        # Scale out if any metric approaching threshold\n        if any(f &gt; policy.scale_out_threshold_pct / 150 for f in scale_factors.values()):\n            return ScalingDecision(should_scale=True, direction='out')\n\n        # Scale in only if all metrics very low for extended period\n        if (all(f &lt; policy.scale_in_threshold_pct / 100 for f in scale_factors.values()) and\n            self.low_utilization_duration(app_name) &gt; 600):  # 10 minutes\n            return ScalingDecision(should_scale=True, direction='in')\n\n        return ScalingDecision(should_scale=False)\n</code></pre>"},{"location":"developer-guide/scaling/#performance-optimization","title":"Performance Optimization","text":""},{"location":"developer-guide/scaling/#efficient-metrics-storage","title":"Efficient Metrics Storage","text":"<pre><code>class RingBuffer:\n    \"\"\"Memory-efficient ring buffer for metrics storage.\"\"\"\n\n    def __init__(self, max_size: int = 1000):\n        self.max_size = max_size\n        self.buffer = [None] * max_size\n        self.head = 0\n        self.size = 0\n\n    def append(self, item):\n        self.buffer[self.head] = item\n        self.head = (self.head + 1) % self.max_size\n        if self.size &lt; self.max_size:\n            self.size += 1\n\n    def get_recent(self, count: int):\n        if count &gt;= self.size:\n            # Return all items\n            if self.size &lt; self.max_size:\n                return [item for item in self.buffer[:self.size] if item is not None]\n            else:\n                return (self.buffer[self.head:] + self.buffer[:self.head])\n        else:\n            # Return most recent items\n            items = []\n            pos = (self.head - 1) % self.max_size\n            for _ in range(count):\n                if self.buffer[pos] is not None:\n                    items.append(self.buffer[pos])\n                pos = (pos - 1) % self.max_size\n            return list(reversed(items))\n</code></pre>"},{"location":"developer-guide/scaling/#batch-scaling-operations","title":"Batch Scaling Operations","text":"<pre><code>async def batch_scale_operations(self, scaling_decisions: List[Tuple[str, int]]):\n    \"\"\"\n    Execute multiple scaling operations in parallel.\n\n    Improves performance when scaling multiple applications simultaneously.\n    \"\"\"\n    tasks = []\n    for app_name, target_replicas in scaling_decisions:\n        task = asyncio.create_task(self.execute_scaling(app_name, target_replicas))\n        tasks.append(task)\n\n    # Execute all scaling operations concurrently\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    # Handle results and exceptions\n    for i, result in enumerate(results):\n        app_name, target_replicas = scaling_decisions[i]\n        if isinstance(result, Exception):\n            logger.error(f\"Scaling failed for {app_name}: {result}\")\n        else:\n            logger.info(f\"Successfully scaled {app_name} to {target_replicas} replicas\")\n</code></pre>"},{"location":"developer-guide/scaling/#monitoring-and-debugging","title":"Monitoring and Debugging","text":""},{"location":"developer-guide/scaling/#scaling-decision-logging","title":"Scaling Decision Logging","text":"<pre><code>def log_scaling_decision(self, app_name: str, decision: ScalingDecision):\n    \"\"\"Log detailed scaling decision for debugging and analysis.\"\"\"\n    log_data = {\n        'app_name': app_name,\n        'timestamp': time.time(),\n        'should_scale': decision.should_scale,\n        'current_replicas': decision.current_replicas,\n        'target_replicas': decision.target_replicas,\n        'reason': decision.reason,\n        'triggered_by': decision.triggered_by,\n        'metrics': {\n            'cpu_percent': decision.metrics.cpu_percent,\n            'memory_percent': decision.metrics.memory_percent,\n            'rps': decision.metrics.rps,\n            'latency_p95_ms': decision.metrics.p95_latency_ms,\n            'active_connections': decision.metrics.active_connections\n        } if decision.metrics else None,\n        'scale_factors': self.last_scale_factors.get(app_name, {})\n    }\n\n    # Store in database for analysis\n    asyncio.create_task(\n        self.state_store.log_event(\n            app_name=app_name,\n            event_type='scaling_decision',\n            message=decision.reason,\n            details=log_data\n        )\n    )\n</code></pre>"},{"location":"developer-guide/scaling/#performance-metrics","title":"Performance Metrics","text":"<pre><code>def get_scaling_performance_metrics(self, app_name: str) -&gt; dict:\n    \"\"\"Get performance metrics for the scaling algorithm.\"\"\"\n    decisions = self.get_recent_scaling_decisions(app_name, hours=24)\n\n    total_decisions = len(decisions)\n    scale_out_decisions = len([d for d in decisions if d.target_replicas &gt; d.current_replicas])\n    scale_in_decisions = len([d for d in decisions if d.target_replicas &lt; d.current_replicas])\n    no_scale_decisions = total_decisions - scale_out_decisions - scale_in_decisions\n\n    # Calculate average response time to scaling needs\n    response_times = []\n    for decision in decisions:\n        if decision.should_scale:\n            # Time from when scaling was needed to when it was decided\n            response_time = self.calculate_response_time(app_name, decision.timestamp)\n            if response_time:\n                response_times.append(response_time)\n\n    return {\n        'total_decisions': total_decisions,\n        'scale_out_count': scale_out_decisions,\n        'scale_in_count': scale_in_decisions,\n        'no_scale_count': no_scale_decisions,\n        'avg_response_time_seconds': statistics.mean(response_times) if response_times else 0,\n        'scaling_efficiency': self.calculate_scaling_efficiency(app_name),\n        'oscillation_rate': self.calculate_oscillation_rate(app_name)\n    }\n</code></pre> <p>Next Steps: Learn about Health Monitoring and how health checks integrate with scaling decisions.</p>"},{"location":"examples/applications/","title":"Sample Applications","text":"<p>Real-world examples of applications deployed with Orchestry, showing different patterns and configurations.</p>"},{"location":"examples/applications/#web-applications","title":"Web Applications","text":""},{"location":"examples/applications/#simple-static-website","title":"Simple Static Website","text":"<p>Perfect for serving static content with automatic scaling based on traffic.</p> <pre><code># static-website.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: my-portfolio\n  labels:\n    app: \"my-portfolio\"\n    version: \"v1.0.0\"\n    tier: \"frontend\"\nspec:\n  type: http\n  image: \"nginx:alpine\"\n  ports:\n    - containerPort: 80\n      protocol: HTTP\n  resources:\n    cpu: \"100m\"\n    memory: \"128Mi\"\n  volumes:\n    - name: \"website-content\"\n      mountPath: \"/usr/share/nginx/html\"\nscaling:\n  mode: auto\n  minReplicas: 1\n  maxReplicas: 10\n  targetRPSPerReplica: 100\n  maxP95LatencyMs: 200\n  scaleOutThresholdPct: 75\n  scaleInThresholdPct: 25\nhealthCheck:\n  path: \"/\"\n  port: 80\n  initialDelaySeconds: 5\n  periodSeconds: 30\n</code></pre>"},{"location":"examples/applications/#nodejs-express-api","title":"Node.js Express API","text":"<p>A typical REST API with database connections and environment configuration.</p> <pre><code># express-api.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: user-api\n  labels:\n    app: \"user-api\"\n    version: \"v2.1.0\"\n    environment: \"production\"\n    team: \"backend\"\nspec:\n  type: http\n  image: \"myregistry/user-api:v2.1.0\"\n  ports:\n    - containerPort: 3000\n      protocol: HTTP\n      name: \"api\"\n    - containerPort: 9090\n      protocol: TCP\n      name: \"metrics\"\n  resources:\n    cpu: \"500m\"\n    memory: \"1Gi\"\n  environment:\n    - name: NODE_ENV\n      value: \"production\"\n    - name: PORT\n      value: \"3000\"\n    - name: INSTANCE_ID\n      source: sdk\n      key: \"instance.ip\"\n    - name: DATABASE_URL\n      value: \"postgresql://user:pass@db.example.com:5432/userdb\"\n    - name: REDIS_URL\n      value: \"redis://cache.example.com:6379\"\n    - name: JWT_SECRET\n      source: secret\n      key: \"jwt-credentials\"\n  healthCheck:\n    path: \"/api/health\"\n    port: 3000\n    initialDelaySeconds: 30\n    periodSeconds: 15\n    headers:\n      - name: \"User-Agent\"\n        value: \"Orchestry-HealthCheck/1.0\"\nscaling:\n  mode: auto\n  minReplicas: 2\n  maxReplicas: 15\n  targetRPSPerReplica: 75\n  maxP95LatencyMs: 300\n  maxCPUPercent: 70\n  maxMemoryPercent: 80\n  scaleOutThresholdPct: 80\n  scaleInThresholdPct: 30\n  cooldownSeconds: 180\n</code></pre>"},{"location":"examples/applications/#react-single-page-application","title":"React Single Page Application","text":"<p>Frontend application with build process and optimized serving.</p> <pre><code># react-spa.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: dashboard-ui\n  labels:\n    app: \"dashboard-ui\"\n    version: \"v3.2.1\"\n    tier: \"frontend\"\nspec:\n  type: http\n  image: \"myregistry/dashboard-ui:v3.2.1\"\n  ports:\n    - containerPort: 80\n      protocol: HTTP\n  resources:\n    cpu: \"200m\"\n    memory: \"256Mi\"\n  environment:\n    - name: REACT_APP_API_URL\n      value: \"https://api.example.com\"\n    - name: REACT_APP_VERSION\n      value: \"v3.2.1\"\n    - name: NGINX_WORKER_PROCESSES\n      value: \"auto\"\nscaling:\n  mode: auto\n  minReplicas: 2\n  maxReplicas: 8\n  targetRPSPerReplica: 150\n  maxP95LatencyMs: 150\n  scaleOutThresholdPct: 70\n  scaleInThresholdPct: 20\nhealthCheck:\n  path: \"/health\"\n  port: 80\n  initialDelaySeconds: 10\n  periodSeconds: 30\n</code></pre>"},{"location":"examples/applications/#api-services","title":"API Services","text":""},{"location":"examples/applications/#python-fastapi-service","title":"Python FastAPI Service","text":"<p>High-performance async API with comprehensive monitoring.</p> <pre><code># fastapi-service.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: analytics-api\n  labels:\n    app: \"analytics-api\"\n    version: \"v1.5.2\"\n    team: \"data\"\nspec:\n  type: http\n  image: \"myregistry/analytics-api:v1.5.2\"\n  ports:\n    - containerPort: 8000\n      protocol: HTTP\n      name: \"api\"\n    - containerPort: 8001\n      protocol: HTTP\n      name: \"metrics\"\n  resources:\n    cpu: \"1000m\"\n    memory: \"2Gi\"\n  environment:\n    - name: PYTHONPATH\n      value: \"/app\"\n    - name: DATABASE_URL\n      value: \"postgresql://analytics:password@postgres.example.com/analytics\"\n    - name: REDIS_URL\n      value: \"redis://redis.example.com:6379/0\"\n    - name: LOG_LEVEL\n      value: \"INFO\"\n    - name: WORKERS\n      value: \"4\"\n    - name: INSTANCE_IP\n      source: sdk\n      key: \"instance.ip\"\n  command: [\"uvicorn\"]\n  args: [\"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--workers\", \"4\"]\nscaling:\n  mode: auto\n  minReplicas: 3\n  maxReplicas: 25\n  targetRPSPerReplica: 100\n  maxP95LatencyMs: 500\n  maxCPUPercent: 75\n  maxMemoryPercent: 80\n  scaleOutThresholdPct: 75\n  scaleInThresholdPct: 25\n  cooldownSeconds: 120\nhealthCheck:\n  path: \"/health\"\n  port: 8000\n  method: GET\n  initialDelaySeconds: 45\n  periodSeconds: 20\n  timeoutSeconds: 10\n  expectedStatusCodes: [200]\n</code></pre>"},{"location":"examples/applications/#java-spring-boot-application","title":"Java Spring Boot Application","text":"<p>Enterprise Java application with JVM tuning and monitoring.</p> <pre><code># spring-boot-api.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: order-service\n  labels:\n    app: \"order-service\"\n    version: \"v2.0.5\"\n    framework: \"spring-boot\"\nspec:\n  type: http\n  image: \"myregistry/order-service:v2.0.5\"\n  ports:\n    - containerPort: 8080\n      protocol: HTTP\n      name: \"api\"\n    - containerPort: 8081\n      protocol: HTTP\n      name: \"actuator\"\n  resources:\n    cpu: \"2000m\"\n    memory: \"4Gi\"\n  environment:\n    - name: SPRING_PROFILES_ACTIVE\n      value: \"production\"\n    - name: SERVER_PORT\n      value: \"8080\"\n    - name: MANAGEMENT_SERVER_PORT\n      value: \"8081\"\n    - name: JAVA_OPTS\n      value: \"-Xms2g -Xmx3g -XX:+UseG1GC -XX:MaxGCPauseMillis=200\"\n    - name: DATABASE_URL\n      value: \"jdbc:postgresql://db.example.com:5432/orders\"\n    - name: KAFKA_BROKERS\n      value: \"kafka1.example.com:9092,kafka2.example.com:9092\"\nscaling:\n  mode: auto\n  minReplicas: 2\n  maxReplicas: 12\n  targetRPSPerReplica: 50\n  maxP95LatencyMs: 800\n  maxCPUPercent: 70\n  maxMemoryPercent: 85\n  scaleOutThresholdPct: 80\n  scaleInThresholdPct: 30\n  cooldownSeconds: 300  # Longer cooldown for JVM warmup\nhealthCheck:\n  path: \"/actuator/health\"\n  port: 8081\n  initialDelaySeconds: 60  # JVM startup time\n  periodSeconds: 30\n  timeoutSeconds: 15\n  failureThreshold: 5  # Account for GC pauses\n</code></pre>"},{"location":"examples/applications/#background-workers","title":"Background Workers","text":""},{"location":"examples/applications/#python-celery-worker","title":"Python Celery Worker","text":"<p>Asynchronous task processing with queue-based scaling.</p> <pre><code># celery-worker.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: email-worker\n  labels:\n    app: \"email-worker\"\n    version: \"v1.3.0\"\n    type: \"worker\"\nspec:\n  type: worker\n  image: \"myregistry/email-worker:v1.3.0\"\n  resources:\n    cpu: \"500m\"\n    memory: \"1Gi\"\n  environment:\n    - name: CELERY_BROKER_URL\n      value: \"redis://redis.example.com:6379/0\"\n    - name: CELERY_RESULT_BACKEND\n      value: \"redis://redis.example.com:6379/1\"\n    - name: EMAIL_SERVICE_URL\n      value: \"https://api.sendgrid.com\"\n    - name: WORKER_CONCURRENCY\n      value: \"4\"\n    - name: WORKER_PREFETCH_MULTIPLIER\n      value: \"1\"\n  command: [\"celery\"]\n  args: [\n    \"worker\",\n    \"-A\", \"tasks\",\n    \"--loglevel=INFO\",\n    \"--concurrency=4\",\n    \"--prefetch-multiplier=1\"\n  ]\nscaling:\n  mode: auto\n  minReplicas: 2\n  maxReplicas: 20\n  targetRPSPerReplica: 10  # Lower for background tasks\n  maxCPUPercent: 80\n  maxMemoryPercent: 75\n  scaleOutThresholdPct: 70\n  scaleInThresholdPct: 20\n  cooldownSeconds: 180\nhealthCheck:\n  # Custom health check for worker\n  path: \"/health\"\n  port: 5555  # Flower monitoring port\n  initialDelaySeconds: 30\n  periodSeconds: 60\n</code></pre>"},{"location":"examples/applications/#nodejs-job-processor","title":"Node.js Job Processor","text":"<p>Event-driven job processing with custom metrics.</p> <pre><code># job-processor.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: image-processor\n  labels:\n    app: \"image-processor\"\n    version: \"v2.1.0\"\n    type: \"worker\"\nspec:\n  type: worker\n  image: \"myregistry/image-processor:v2.1.0\"\n  resources:\n    cpu: \"2000m\"  # CPU intensive image processing\n    memory: \"4Gi\"\n  environment:\n    - name: NODE_ENV\n      value: \"production\"\n    - name: QUEUE_URL\n      value: \"amqp://rabbitmq.example.com:5672\"\n    - name: S3_BUCKET\n      value: \"image-processing-bucket\"\n    - name: AWS_REGION\n      value: \"us-west-2\"\n    - name: CONCURRENT_JOBS\n      value: \"2\"\n    - name: HEALTH_CHECK_PORT\n      value: \"3001\"\n  command: [\"node\"]\n  args: [\"worker.js\"]\nscaling:\n  mode: auto\n  minReplicas: 1\n  maxReplicas: 15\n  targetRPSPerReplica: 5  # Few concurrent image processing jobs\n  maxCPUPercent: 85\n  maxMemoryPercent: 80\n  scaleOutThresholdPct: 75\n  scaleInThresholdPct: 15\n  cooldownSeconds: 240\nhealthCheck:\n  path: \"/health\"\n  port: 3001\n  initialDelaySeconds: 20\n  periodSeconds: 45\n</code></pre>"},{"location":"examples/applications/#database-services","title":"Database Services","text":""},{"location":"examples/applications/#postgresql-primary-database","title":"PostgreSQL Primary Database","text":"<p>Stateful database service with persistent storage.</p> <pre><code># postgres-primary.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: postgres-primary\n  labels:\n    app: \"postgres-primary\"\n    version: \"v15.3\"\n    tier: \"database\"\nspec:\n  type: tcp\n  image: \"postgres:15-alpine\"\n  ports:\n    - containerPort: 5432\n      protocol: TCP\n  resources:\n    cpu: \"4000m\"\n    memory: \"8Gi\"\n  environment:\n    - name: POSTGRES_DB\n      value: \"myapp\"\n    - name: POSTGRES_USER\n      value: \"myapp\"\n    - name: POSTGRES_PASSWORD\n      source: secret\n      key: \"postgres-credentials\"\n      field: \"password\"\n    - name: POSTGRES_INITDB_ARGS\n      value: \"--auth-host=md5\"\n    - name: POSTGRES_SHARED_BUFFERS\n      value: \"2GB\"\n    - name: POSTGRES_EFFECTIVE_CACHE_SIZE\n      value: \"6GB\"\n  volumes:\n    - name: \"postgres-data\"\n      mountPath: \"/var/lib/postgresql/data\"\n      size: \"100Gi\"\n    - name: \"postgres-config\"\n      mountPath: \"/etc/postgresql\"\nscaling:\n  mode: manual  # Databases typically don't auto-scale\n  minReplicas: 1\n  maxReplicas: 1\nhealthCheck:\n  port: 5432\n  protocol: TCP\n  initialDelaySeconds: 60\n  periodSeconds: 30\n  timeoutSeconds: 10\n  failureThreshold: 5\n</code></pre>"},{"location":"examples/applications/#redis-cache","title":"Redis Cache","text":"<p>In-memory cache with persistence configuration.</p> <pre><code># redis-cache.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: redis-cache\n  labels:\n    app: \"redis-cache\"\n    version: \"v7.0\"\n    tier: \"cache\"\nspec:\n  type: tcp\n  image: \"redis:7.0-alpine\"\n  ports:\n    - containerPort: 6379\n      protocol: TCP\n  resources:\n    cpu: \"1000m\"\n    memory: \"4Gi\"\n  environment:\n    - name: REDIS_PASSWORD\n      source: secret\n      key: \"redis-credentials\"\n    - name: REDIS_MAXMEMORY\n      value: \"3gb\"\n    - name: REDIS_MAXMEMORY_POLICY\n      value: \"allkeys-lru\"\n  command: [\"redis-server\"]\n  args: [\n    \"--requirepass\", \"${REDIS_PASSWORD}\",\n    \"--maxmemory\", \"${REDIS_MAXMEMORY}\",\n    \"--maxmemory-policy\", \"${REDIS_MAXMEMORY_POLICY}\",\n    \"--save\", \"900\", \"1\",\n    \"--save\", \"300\", \"10\"\n  ]\n  volumes:\n    - name: \"redis-data\"\n      mountPath: \"/data\"\n      size: \"50Gi\"\nscaling:\n  mode: manual\n  minReplicas: 1\n  maxReplicas: 3  # Can scale for read replicas\nhealthCheck:\n  port: 6379\n  protocol: TCP\n  initialDelaySeconds: 10\n  periodSeconds: 15\n</code></pre>"},{"location":"examples/applications/#microservices-examples","title":"Microservices Examples","text":""},{"location":"examples/applications/#e-commerce-order-service","title":"E-commerce Order Service","text":"<p>Complete microservice with dependencies and external integrations.</p> <pre><code># order-service.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: order-service\n  labels:\n    app: \"order-service\"\n    version: \"v1.8.2\"\n    domain: \"ecommerce\"\n    team: \"orders\"\nspec:\n  type: http\n  image: \"myregistry/order-service:v1.8.2\"\n  ports:\n    - containerPort: 8080\n      protocol: HTTP\n      name: \"api\"\n    - containerPort: 9090\n      protocol: HTTP\n      name: \"metrics\"\n  resources:\n    cpu: \"1000m\"\n    memory: \"2Gi\"\n  environment:\n    - name: SPRING_PROFILES_ACTIVE\n      value: \"production\"\n    - name: DATABASE_URL\n      value: \"jdbc:postgresql://postgres.example.com/orders\"\n    - name: PAYMENT_SERVICE_URL\n      value: \"https://payment-service.example.com\"\n    - name: INVENTORY_SERVICE_URL\n      value: \"https://inventory-service.example.com\"\n    - name: NOTIFICATION_SERVICE_URL\n      value: \"https://notification-service.example.com\"\n    - name: KAFKA_BROKERS\n      value: \"kafka.example.com:9092\"\n    - name: REDIS_URL\n      value: \"redis://redis.example.com:6379\"\n    - name: JWT_SECRET\n      source: secret\n      key: \"jwt-secret\"\nscaling:\n  mode: auto\n  minReplicas: 3\n  maxReplicas: 20\n  targetRPSPerReplica: 60\n  maxP95LatencyMs: 400\n  maxCPUPercent: 70\n  maxMemoryPercent: 80\n  scaleOutThresholdPct: 75\n  scaleInThresholdPct: 25\n  cooldownSeconds: 180\nhealthCheck:\n  path: \"/actuator/health\"\n  port: 9090\n  initialDelaySeconds: 60\n  periodSeconds: 30\n  timeoutSeconds: 10\n  headers:\n    - name: \"Authorization\"\n      value: \"Bearer health-check-token\"\n</code></pre>"},{"location":"examples/applications/#user-authentication-service","title":"User Authentication Service","text":"<p>Security-focused microservice with enhanced monitoring.</p> <pre><code># auth-service.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: auth-service\n  labels:\n    app: \"auth-service\"\n    version: \"v2.5.1\"\n    security: \"critical\"\n    team: \"security\"\nspec:\n  type: http\n  image: \"myregistry/auth-service:v2.5.1\"\n  ports:\n    - containerPort: 8080\n      protocol: HTTP\n  resources:\n    cpu: \"500m\"\n    memory: \"1Gi\"\n  environment:\n    - name: NODE_ENV\n      value: \"production\"\n    - name: JWT_SECRET\n      source: secret\n      key: \"jwt-secret\"\n    - name: BCRYPT_ROUNDS\n      value: \"12\"\n    - name: RATE_LIMIT_WINDOW_MS\n      value: \"900000\"  # 15 minutes\n    - name: RATE_LIMIT_MAX_REQUESTS\n      value: \"5\"\n    - name: DATABASE_URL\n      value: \"postgresql://auth:password@postgres.example.com/auth\"\n    - name: REDIS_URL\n      value: \"redis://redis.example.com:6379/2\"\nscaling:\n  mode: auto\n  minReplicas: 4  # High availability for auth\n  maxReplicas: 15\n  targetRPSPerReplica: 30  # Lower due to crypto operations\n  maxP95LatencyMs: 300\n  maxCPUPercent: 65  # Conservative for security service\n  scaleOutThresholdPct: 70\n  scaleInThresholdPct: 30\n  cooldownSeconds: 240\nhealthCheck:\n  path: \"/health\"\n  port: 8080\n  initialDelaySeconds: 30\n  periodSeconds: 20\n  timeoutSeconds: 5\n  failureThreshold: 3\n  successThreshold: 1\n</code></pre>"},{"location":"examples/applications/#development-and-testing","title":"Development and Testing","text":""},{"location":"examples/applications/#development-environment-app","title":"Development Environment App","text":"<p>Relaxed configuration for development and testing.</p> <pre><code># dev-app.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: dev-api\n  labels:\n    app: \"dev-api\"\n    version: \"latest\"\n    environment: \"development\"\nspec:\n  type: http\n  image: \"myregistry/my-api:latest\"\n  ports:\n    - containerPort: 3000\n      protocol: HTTP\n  resources:\n    cpu: \"200m\"\n    memory: \"512Mi\"\n  environment:\n    - name: NODE_ENV\n      value: \"development\"\n    - name: DEBUG\n      value: \"*\"\n    - name: DATABASE_URL\n      value: \"postgresql://dev:dev@postgres-dev.example.com/devdb\"\nscaling:\n  mode: manual  # Manual scaling for development\n  minReplicas: 1\n  maxReplicas: 2\nhealthCheck:\n  path: \"/health\"\n  port: 3000\n  initialDelaySeconds: 10\n  periodSeconds: 60  # Less frequent in dev\n  failureThreshold: 10  # More tolerant in dev\n</code></pre>"},{"location":"examples/applications/#load-testing-application","title":"Load Testing Application","text":"<p>Application specifically configured for load testing scenarios.</p> <pre><code># load-test-target.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: load-test-app\n  labels:\n    app: \"load-test-app\"\n    version: \"v1.0.0\"\n    purpose: \"testing\"\nspec:\n  type: http\n  image: \"nginx:alpine\"\n  ports:\n    - containerPort: 80\n      protocol: HTTP\n  resources:\n    cpu: \"100m\"\n    memory: \"64Mi\"\n  environment:\n    - name: NGINX_WORKER_PROCESSES\n      value: \"1\"\nscaling:\n  mode: auto\n  minReplicas: 1\n  maxReplicas: 50  # Allow high scaling for load tests\n  targetRPSPerReplica: 200\n  maxP95LatencyMs: 100\n  scaleOutThresholdPct: 60  # Scale out early\n  scaleInThresholdPct: 10   # Scale in late\n  cooldownSeconds: 30       # Fast scaling for tests\nhealthCheck:\n  path: \"/\"\n  port: 80\n  initialDelaySeconds: 2\n  periodSeconds: 5\n</code></pre>"},{"location":"examples/applications/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"examples/applications/#multi-container-application","title":"Multi-Container Application","text":"<p>Application with sidecar containers for logging and monitoring.</p> <pre><code># app-with-sidecars.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: monitored-app\n  labels:\n    app: \"monitored-app\"\n    version: \"v1.0.0\"\n    monitoring: \"enhanced\"\nspec:\n  type: http\n  image: \"myregistry/my-app:v1.0.0\"\n  ports:\n    - containerPort: 8080\n      protocol: HTTP\n      name: \"app\"\n  resources:\n    cpu: \"1000m\"\n    memory: \"2Gi\"\n  sidecars:\n    - name: \"log-shipper\"\n      image: \"fluent/fluent-bit:latest\"\n      resources:\n        cpu: \"100m\"\n        memory: \"128Mi\"\n      volumes:\n        - name: \"app-logs\"\n          mountPath: \"/var/log/app\"\n          shared: true\n    - name: \"metrics-exporter\"\n      image: \"prom/node-exporter:latest\"\n      ports:\n        - containerPort: 9100\n          protocol: HTTP\n      resources:\n        cpu: \"50m\"\n        memory: \"64Mi\"\n  environment:\n    - name: LOG_LEVEL\n      value: \"INFO\"\n    - name: METRICS_ENABLED\n      value: \"true\"\nscaling:\n  mode: auto\n  minReplicas: 2\n  maxReplicas: 10\n  targetRPSPerReplica: 50\nhealthCheck:\n  path: \"/health\"\n  port: 8080\n  initialDelaySeconds: 30\n  periodSeconds: 20\n</code></pre>"},{"location":"examples/applications/#blue-green-deployment","title":"Blue-Green Deployment","text":"<p>Configuration for blue-green deployment pattern.</p> <pre><code># blue-green-app.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: production-app-blue\n  labels:\n    app: \"production-app\"\n    version: \"v2.0.0\"\n    deployment: \"blue\"\n    environment: \"production\"\nspec:\n  type: http\n  image: \"myregistry/production-app:v2.0.0\"\n  ports:\n    - containerPort: 8080\n      protocol: HTTP\n  resources:\n    cpu: \"1000m\"\n    memory: \"2Gi\"\n  environment:\n    - name: DEPLOYMENT_SLOT\n      value: \"blue\"\n    - name: DATABASE_URL\n      value: \"postgresql://prod:password@db.example.com/prod\"\nscaling:\n  mode: auto\n  minReplicas: 5\n  maxReplicas: 20\n  targetRPSPerReplica: 75\n  maxP95LatencyMs: 200\n  scaleOutThresholdPct: 75\n  scaleInThresholdPct: 25\nhealthCheck:\n  path: \"/health\"\n  port: 8080\n  initialDelaySeconds: 45\n  periodSeconds: 15\n  headers:\n    - name: \"X-Health-Check\"\n      value: \"blue-deployment\"\n</code></pre>"},{"location":"examples/applications/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"examples/applications/#application-with-custom-metrics","title":"Application with Custom Metrics","text":"<p>Application configured for comprehensive monitoring.</p> <pre><code># monitored-service.yml\napiVersion: v1\nkind: App\nmetadata:\n  name: analytics-service\n  labels:\n    app: \"analytics-service\"\n    version: \"v1.2.0\"\n    monitoring: \"comprehensive\"\nspec:\n  type: http\n  image: \"myregistry/analytics-service:v1.2.0\"  \n  ports:\n    - containerPort: 8080\n      protocol: HTTP\n      name: \"api\"\n    - containerPort: 9090\n      protocol: HTTP\n      name: \"metrics\"\n    - containerPort: 8081\n      protocol: HTTP\n      name: \"health\"\n  resources:\n    cpu: \"2000m\"\n    memory: \"4Gi\"\n  environment:\n    - name: METRICS_PORT\n      value: \"9090\"\n    - name: HEALTH_PORT\n      value: \"8081\"\n    - name: ENABLE_DETAILED_METRICS\n      value: \"true\"\n    - name: JAEGER_ENDPOINT\n      value: \"http://jaeger.example.com:14268/api/traces\"\n    - name: PROMETHEUS_ENDPOINT\n      value: \"http://prometheus.example.com:9090\"\nscaling:\n  mode: auto\n  minReplicas: 3\n  maxReplicas: 25\n  targetRPSPerReplica: 80\n  maxP95LatencyMs: 400\n  customMetrics:\n    - name: \"queue_length\"\n      target: 10\n      query: \"queue_length{service='analytics-service'}\"\n    - name: \"error_rate\"\n      target: 0.01  # 1% error rate\n      query: \"rate(http_requests_total{status=~'5..'}[5m])\"\nhealthCheck:\n  path: \"/health/live\"\n  port: 8081\n  initialDelaySeconds: 60\n  periodSeconds: 20\n  timeoutSeconds: 10\n</code></pre> <p>These examples demonstrate various patterns and configurations for different types of applications. Each example includes:</p> <ul> <li>Appropriate resource allocation</li> <li>Environment-specific configuration</li> <li>Scaling policies tailored to the application type</li> <li>Health checks optimized for the service</li> <li>Security and monitoring considerations</li> </ul> <p>Next Steps: Explore Configuration Guide for advanced deployment settings.</p>"},{"location":"user-guide/api-reference/","title":"REST API Reference","text":"<p>Complete reference for the Orchestry REST API endpoints.</p>"},{"location":"user-guide/api-reference/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000\n</code></pre>"},{"location":"user-guide/api-reference/#authentication","title":"Authentication","text":"<p>Currently, Orchestry does not require authentication. This will be added in future versions.</p>"},{"location":"user-guide/api-reference/#content-types","title":"Content Types","text":"<ul> <li>Request: <code>application/json</code></li> <li>Response: <code>application/json</code></li> </ul>"},{"location":"user-guide/api-reference/#error-responses","title":"Error Responses","text":"<p>All API endpoints return consistent error responses:</p> <pre><code>{\n  \"error\": \"Application not found\",\n  \"details\": \"Application 'my-app' does not exist\",\n  \"code\": \"APP_NOT_FOUND\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre> <p>HTTP Status Codes: - <code>200</code> - Success - <code>201</code> - Created - <code>400</code> - Bad Request - <code>404</code> - Not Found - <code>409</code> - Conflict - <code>500</code> - Internal Server Error - <code>503</code> - Service Unavailable</p>"},{"location":"user-guide/api-reference/#application-management","title":"Application Management","text":""},{"location":"user-guide/api-reference/#register-application","title":"Register Application","text":"<p>Register a new application from specification.</p> <pre><code>POST /api/v1/apps/register\nContent-Type: application/json\n\n{\n  \"apiVersion\": \"v1\",\n  \"kind\": \"App\",\n  \"metadata\": {\n    \"name\": \"my-app\",\n    \"labels\": {\n      \"app\": \"my-app\",\n      \"version\": \"v1\"\n    }\n  },\n  \"spec\": {\n    \"type\": \"http\",\n    \"image\": \"nginx:alpine\",\n    \"ports\": [\n      {\n        \"containerPort\": 80,\n        \"protocol\": \"HTTP\"\n      }\n    ]\n  }\n}\n</code></pre> <p>Response: <pre><code>{\n  \"message\": \"Application registered successfully\",\n  \"app_name\": \"my-app\",\n  \"status\": \"registered\"\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#start-application","title":"Start Application","text":"<p>Start a registered application.</p> <pre><code>POST /api/v1/apps/{app_name}/start\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Request Body (optional): <pre><code>{\n  \"replicas\": 3,\n  \"wait\": true,\n  \"timeout\": 300\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"message\": \"Application started successfully\",\n  \"app_name\": \"my-app\",\n  \"replicas\": 3,\n  \"status\": \"running\"\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#stop-application","title":"Stop Application","text":"<p>Stop a running application.</p> <pre><code>POST /api/v1/apps/{app_name}/stop\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Request Body (optional): <pre><code>{\n  \"force\": false,\n  \"timeout\": 30\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"message\": \"Application stopped successfully\",\n  \"app_name\": \"my-app\",\n  \"status\": \"stopped\"\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#scale-application","title":"Scale Application","text":"<p>Scale an application to specific replica count.</p> <pre><code>POST /api/v1/apps/{app_name}/scale\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Request Body: <pre><code>{\n  \"replicas\": 5,\n  \"wait\": true,\n  \"timeout\": 300\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"message\": \"Application scaled successfully\",\n  \"app_name\": \"my-app\",\n  \"previous_replicas\": 3,\n  \"current_replicas\": 5,\n  \"scaling_time\": 45.2\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#remove-application","title":"Remove Application","text":"<p>Remove an application and all its resources.</p> <pre><code>DELETE /api/v1/apps/{app_name}\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Query Parameters: - <code>force</code> (boolean): Skip confirmation - <code>keep_data</code> (boolean): Keep persistent volumes</p> <p>Response: <pre><code>{\n  \"message\": \"Application removed successfully\",\n  \"app_name\": \"my-app\",\n  \"containers_removed\": 3,\n  \"volumes_removed\": 1\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#application-information","title":"Application Information","text":""},{"location":"user-guide/api-reference/#get-application-status","title":"Get Application Status","text":"<p>Get detailed status of a specific application.</p> <pre><code>GET /api/v1/apps/{app_name}\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Response: <pre><code>{\n  \"name\": \"my-app\",\n  \"status\": \"running\",\n  \"replicas\": {\n    \"current\": 3,\n    \"desired\": 3,\n    \"healthy\": 3\n  },\n  \"metrics\": {\n    \"cpu_percent\": 45.2,\n    \"memory_percent\": 62.1,\n    \"rps\": 127.5,\n    \"latency_p95_ms\": 89,\n    \"active_connections\": 234\n  },\n  \"created_at\": \"2024-01-15T08:00:00Z\",\n  \"updated_at\": \"2024-01-15T10:30:00Z\",\n  \"last_scaled_at\": \"2024-01-15T09:15:00Z\",\n  \"containers\": [\n    {\n      \"id\": \"abc123\",\n      \"name\": \"my-app-1\",\n      \"ip\": \"172.20.0.5\",\n      \"port\": 80,\n      \"status\": \"running\",\n      \"health\": \"healthy\",\n      \"started_at\": \"2024-01-15T09:00:00Z\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#list-applications","title":"List Applications","text":"<p>List all registered applications.</p> <pre><code>GET /api/v1/apps\n</code></pre> <p>Query Parameters: - <code>status</code> (string): Filter by status (<code>running</code>, <code>stopped</code>, <code>error</code>) - <code>format</code> (string): Response format (<code>json</code>, <code>summary</code>)</p> <p>Response: <pre><code>{\n  \"apps\": [\n    {\n      \"name\": \"my-app\",\n      \"status\": \"running\",\n      \"replicas\": {\n        \"current\": 3,\n        \"desired\": 3\n      },\n      \"image\": \"nginx:alpine\",\n      \"created_at\": \"2024-01-15T08:00:00Z\"\n    },\n    {\n      \"name\": \"api-service\",\n      \"status\": \"running\", \n      \"replicas\": {\n        \"current\": 5,\n        \"desired\": 5\n      },\n      \"image\": \"myapp/api:v2.1.0\",\n      \"created_at\": \"2024-01-14T15:30:00Z\"\n    }\n  ],\n  \"total\": 2,\n  \"running\": 2,\n  \"stopped\": 0,\n  \"error\": 0\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#get-application-specification","title":"Get Application Specification","text":"<p>Retrieve the original application specification.</p> <pre><code>GET /api/v1/apps/{app_name}/spec\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Response: <pre><code>{\n  \"apiVersion\": \"v1\",\n  \"kind\": \"App\",\n  \"metadata\": {\n    \"name\": \"my-app\",\n    \"labels\": {\n      \"app\": \"my-app\",\n      \"version\": \"v1\"\n    }\n  },\n  \"spec\": {\n    \"type\": \"http\",\n    \"image\": \"nginx:alpine\",\n    \"ports\": [\n      {\n        \"containerPort\": 80,\n        \"protocol\": \"HTTP\"\n      }\n    ]\n  },\n  \"scaling\": {\n    \"mode\": \"auto\",\n    \"minReplicas\": 1,\n    \"maxReplicas\": 5\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#monitoring-and-metrics","title":"Monitoring and Metrics","text":""},{"location":"user-guide/api-reference/#get-application-metrics","title":"Get Application Metrics","text":"<p>Get current performance metrics for an application.</p> <pre><code>GET /api/v1/apps/{app_name}/metrics\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Query Parameters: - <code>history</code> (integer): Number of historical data points (default: 10) - <code>interval</code> (string): Time interval (<code>5m</code>, <code>1h</code>, <code>1d</code>)</p> <p>Response: <pre><code>{\n  \"app_name\": \"my-app\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"current\": {\n    \"cpu_percent\": 45.2,\n    \"memory_percent\": 62.1,\n    \"rps\": 127.5,\n    \"latency_p95_ms\": 89,\n    \"active_connections\": 234,\n    \"healthy_replicas\": 3,\n    \"total_replicas\": 3\n  },\n  \"history\": [\n    {\n      \"timestamp\": \"2024-01-15T10:25:00Z\",\n      \"cpu_percent\": 42.1,\n      \"memory_percent\": 58.9,\n      \"rps\": 115.2,\n      \"latency_p95_ms\": 92\n    }\n  ]\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#get-application-events","title":"Get Application Events","text":"<p>Get event history for an application.</p> <pre><code>GET /api/v1/apps/{app_name}/events\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Query Parameters: - <code>type</code> (string): Event type filter (<code>scaling</code>, <code>health</code>, <code>config</code>, <code>error</code>) - <code>since</code> (string): Time filter (<code>1h</code>, <code>1d</code>, ISO timestamp) - <code>limit</code> (integer): Maximum events to return (default: 100)</p> <p>Response: <pre><code>{\n  \"app_name\": \"my-app\",\n  \"events\": [\n    {\n      \"id\": 123,\n      \"type\": \"scaling\",\n      \"message\": \"Scaled from 2 to 3 replicas due to high CPU usage\",\n      \"timestamp\": \"2024-01-15T09:15:00Z\",\n      \"details\": {\n        \"previous_replicas\": 2,\n        \"new_replicas\": 3,\n        \"trigger\": \"cpu_high\",\n        \"cpu_percent\": 78.5\n      }\n    },\n    {\n      \"id\": 122,\n      \"type\": \"health\",\n      \"message\": \"Container my-app-2 marked as unhealthy\",\n      \"timestamp\": \"2024-01-15T08:45:00Z\",\n      \"details\": {\n        \"container_id\": \"def456\",\n        \"health_check_failures\": 3\n      }\n    }\n  ],\n  \"total\": 25,\n  \"has_more\": true\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#get-application-logs","title":"Get Application Logs","text":"<p>Get container logs for an application.</p> <pre><code>GET /api/v1/apps/{app_name}/logs\n</code></pre> <p>Parameters: - <code>app_name</code> (path): Application name</p> <p>Query Parameters: - <code>container</code> (string): Specific container name - <code>tail</code> (integer): Number of lines from end (default: 100) - <code>since</code> (string): Time filter (<code>1h</code>, <code>1d</code>, ISO timestamp) - <code>follow</code> (boolean): Stream logs (WebSocket upgrade)</p> <p>Response: <pre><code>{\n  \"app_name\": \"my-app\",\n  \"logs\": [\n    {\n      \"timestamp\": \"2024-01-15T10:30:15Z\",\n      \"container\": \"my-app-1\",\n      \"level\": \"INFO\",\n      \"message\": \"Request processed successfully\"\n    },\n    {\n      \"timestamp\": \"2024-01-15T10:30:10Z\", \n      \"container\": \"my-app-2\",\n      \"level\": \"WARN\",\n      \"message\": \"High memory usage detected\"\n    }\n  ],\n  \"total_lines\": 1543,\n  \"has_more\": true\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#scaling-management","title":"Scaling Management","text":""},{"location":"user-guide/api-reference/#get-scaling-policy","title":"Get Scaling Policy","text":"<p>Get the current scaling policy for an application.</p> <pre><code>GET /api/v1/apps/{app_name}/scaling\n</code></pre> <p>Response: <pre><code>{\n  \"app_name\": \"my-app\",\n  \"mode\": \"auto\",\n  \"policy\": {\n    \"min_replicas\": 1,\n    \"max_replicas\": 5,\n    \"target_rps_per_replica\": 50,\n    \"max_p95_latency_ms\": 250,\n    \"max_cpu_percent\": 70.0,\n    \"max_memory_percent\": 75.0,\n    \"scale_out_threshold_pct\": 80,\n    \"scale_in_threshold_pct\": 30,\n    \"window_seconds\": 60,\n    \"cooldown_seconds\": 180\n  },\n  \"last_scaling_event\": {\n    \"timestamp\": \"2024-01-15T09:15:00Z\",\n    \"action\": \"scale_out\",\n    \"from_replicas\": 2,\n    \"to_replicas\": 3,\n    \"reason\": \"High CPU usage: 78.5%\"\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#update-scaling-policy","title":"Update Scaling Policy","text":"<p>Update the scaling policy for an application.</p> <pre><code>PUT /api/v1/apps/{app_name}/scaling\n</code></pre> <p>Request Body: <pre><code>{\n  \"mode\": \"auto\",\n  \"min_replicas\": 2,\n  \"max_replicas\": 10,\n  \"target_rps_per_replica\": 100,\n  \"max_p95_latency_ms\": 200,\n  \"scale_out_threshold_pct\": 75,\n  \"scale_in_threshold_pct\": 25\n}\n</code></pre></p> <p>Response: <pre><code>{\n  \"message\": \"Scaling policy updated successfully\",\n  \"app_name\": \"my-app\",\n  \"previous_policy\": {\n    \"min_replicas\": 1,\n    \"max_replicas\": 5\n  },\n  \"new_policy\": {\n    \"min_replicas\": 2,\n    \"max_replicas\": 10\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#health-management","title":"Health Management","text":""},{"location":"user-guide/api-reference/#get-health-status","title":"Get Health Status","text":"<p>Get detailed health status for an application.</p> <pre><code>GET /api/v1/apps/{app_name}/health\n</code></pre> <p>Response: <pre><code>{\n  \"app_name\": \"my-app\",\n  \"overall_health\": \"healthy\",\n  \"healthy_replicas\": 3,\n  \"total_replicas\": 3,\n  \"containers\": [\n    {\n      \"id\": \"abc123\",\n      \"name\": \"my-app-1\",\n      \"health\": \"healthy\",\n      \"last_check\": \"2024-01-15T10:30:00Z\",\n      \"consecutive_failures\": 0,\n      \"response_time_ms\": 45\n    },\n    {\n      \"id\": \"def456\", \n      \"name\": \"my-app-2\",\n      \"health\": \"unhealthy\",\n      \"last_check\": \"2024-01-15T10:29:30Z\",\n      \"consecutive_failures\": 2,\n      \"last_error\": \"Connection refused\"\n    }\n  ],\n  \"health_check_config\": {\n    \"path\": \"/health\",\n    \"port\": 80,\n    \"protocol\": \"HTTP\",\n    \"period_seconds\": 30,\n    \"timeout_seconds\": 5,\n    \"failure_threshold\": 3\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#trigger-health-check","title":"Trigger Health Check","text":"<p>Manually trigger health checks for an application.</p> <pre><code>POST /api/v1/apps/{app_name}/health/check\n</code></pre> <p>Response: <pre><code>{\n  \"message\": \"Health check triggered\",\n  \"app_name\": \"my-app\",\n  \"containers_checked\": 3,\n  \"healthy\": 2,\n  \"unhealthy\": 1\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#system-information","title":"System Information","text":""},{"location":"user-guide/api-reference/#system-health","title":"System Health","text":"<p>Get overall system health status.</p> <pre><code>GET /health\n</code></pre> <p>Response: <pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"version\": \"1.0.0\",\n  \"uptime_seconds\": 86400,\n  \"components\": {\n    \"database\": {\n      \"status\": \"healthy\",\n      \"response_time_ms\": 12\n    },\n    \"docker\": {\n      \"status\": \"healthy\",\n      \"containers_running\": 15\n    },\n    \"nginx\": {\n      \"status\": \"healthy\",\n      \"configs_active\": 5\n    }\n  },\n  \"applications\": {\n    \"total\": 8,\n    \"running\": 6,\n    \"stopped\": 1,\n    \"error\": 1\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#system-metrics","title":"System Metrics","text":"<p>Get system-wide metrics and statistics.</p> <pre><code>GET /api/v1/metrics\n</code></pre> <p>Response: <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"system\": {\n    \"cpu_percent\": 35.2,\n    \"memory_used_gb\": 12.5,\n    \"memory_total_gb\": 32.0,\n    \"disk_used_gb\": 45.2,\n    \"disk_total_gb\": 100.0,\n    \"containers_running\": 15,\n    \"containers_total\": 18\n  },\n  \"applications\": [\n    {\n      \"name\": \"my-app\",\n      \"cpu_percent\": 15.2,\n      \"memory_mb\": 256,\n      \"replicas\": 3,\n      \"rps\": 127.5\n    }\n  ],\n  \"network\": {\n    \"requests_per_second\": 342.1,\n    \"total_requests\": 1587432,\n    \"error_rate_percent\": 0.12,\n    \"avg_response_time_ms\": 95\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#configuration-management","title":"Configuration Management","text":""},{"location":"user-guide/api-reference/#get-configuration","title":"Get Configuration","text":"<p>Get current Orchestry configuration.</p> <pre><code>GET /api/v1/config\n</code></pre> <p>Response: <pre><code>{\n  \"version\": \"1.0.0\",\n  \"controller\": {\n    \"host\": \"0.0.0.0\",\n    \"port\": 8000,\n    \"workers\": 4\n  },\n  \"database\": {\n    \"host\": \"orchestry-postgres-primary\",\n    \"port\": 5432,\n    \"name\": \"orchestry\",\n    \"pool_size\": 10\n  },\n  \"scaling\": {\n    \"default_check_interval\": 30,\n    \"default_cooldown\": 180,\n    \"max_concurrent_scales\": 3\n  },\n  \"health\": {\n    \"default_check_interval\": 10,\n    \"default_timeout\": 5,\n    \"default_failure_threshold\": 3\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#update-configuration","title":"Update Configuration","text":"<p>Update Orchestry configuration (requires restart).</p> <pre><code>PUT /api/v1/config\n</code></pre> <p>Request Body: <pre><code>{\n  \"scaling\": {\n    \"default_check_interval\": 45,\n    \"default_cooldown\": 300\n  },\n  \"health\": {\n    \"default_check_interval\": 15\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#websocket-endpoints","title":"WebSocket Endpoints","text":""},{"location":"user-guide/api-reference/#real-time-logs","title":"Real-time Logs","text":"<p>Stream application logs in real-time.</p> <pre><code>const ws = new WebSocket('ws://localhost:8000/api/v1/apps/my-app/logs/stream');\n\nws.onmessage = function(event) {\n  const logEntry = JSON.parse(event.data);\n  console.log(`[${logEntry.timestamp}] ${logEntry.container}: ${logEntry.message}`);\n};\n</code></pre>"},{"location":"user-guide/api-reference/#real-time-metrics","title":"Real-time Metrics","text":"<p>Stream application metrics in real-time.</p> <pre><code>const ws = new WebSocket('ws://localhost:8000/api/v1/apps/my-app/metrics/stream');\n\nws.onmessage = function(event) {\n  const metrics = JSON.parse(event.data);\n  console.log(`CPU: ${metrics.cpu_percent}%, Memory: ${metrics.memory_percent}%`);\n};\n</code></pre>"},{"location":"user-guide/api-reference/#system-events","title":"System Events","text":"<p>Stream system-wide events.</p> <pre><code>const ws = new WebSocket('ws://localhost:8000/api/v1/events/stream');\n\nws.onmessage = function(event) {\n  const event = JSON.parse(event.data);\n  console.log(`[${event.type}] ${event.app_name}: ${event.message}`);\n};\n</code></pre>"},{"location":"user-guide/api-reference/#rate-limiting","title":"Rate Limiting","text":"<p>API endpoints are rate limited to prevent abuse:</p> <ul> <li>Per IP: 1000 requests per hour</li> <li>Per endpoint: Varies by endpoint type</li> <li>Burst limit: 100 requests per minute</li> </ul> <p>Rate limit headers are included in responses:</p> <pre><code>X-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 999\nX-RateLimit-Reset: 1642248000\n</code></pre>"},{"location":"user-guide/api-reference/#error-codes","title":"Error Codes","text":"Code Description HTTP Status <code>APP_NOT_FOUND</code> Application not found 404 <code>APP_ALREADY_EXISTS</code> Application already registered 409 <code>INVALID_SPEC</code> Invalid application specification 400 <code>SCALING_IN_PROGRESS</code> Scaling operation in progress 409 <code>INSUFFICIENT_RESOURCES</code> Not enough system resources 503 <code>DOCKER_ERROR</code> Docker daemon error 500 <code>DATABASE_ERROR</code> Database connection error 500 <code>VALIDATION_ERROR</code> Request validation failed 400 <code>RATE_LIMIT_EXCEEDED</code> Rate limit exceeded 429"},{"location":"user-guide/api-reference/#cluster-management","title":"Cluster Management","text":"<p>These endpoints are available when Orchestry is running in distributed cluster mode.</p>"},{"location":"user-guide/api-reference/#get-cluster-status","title":"Get Cluster Status","text":"<p>Get comprehensive cluster status and node information.</p> <pre><code>GET /cluster/status\n</code></pre> <p>Response: <pre><code>{\n  \"node_id\": \"controller-1\",\n  \"hostname\": \"controller-1.local\",\n  \"state\": \"leader\",\n  \"term\": 5,\n  \"is_leader\": true,\n  \"leader_id\": \"controller-1\",\n  \"cluster_size\": 3,\n  \"nodes\": [\n    {\n      \"node_id\": \"controller-1\",\n      \"hostname\": \"controller-1.local\",\n      \"state\": \"leader\",\n      \"is_healthy\": true,\n      \"last_heartbeat\": 1642248600.123\n    },\n    {\n      \"node_id\": \"controller-2\", \n      \"hostname\": \"controller-2.local\",\n      \"state\": \"follower\",\n      \"is_healthy\": true,\n      \"last_heartbeat\": 1642248595.456\n    },\n    {\n      \"node_id\": \"controller-3\",\n      \"hostname\": \"controller-3.local\", \n      \"state\": \"follower\",\n      \"is_healthy\": true,\n      \"last_heartbeat\": 1642248598.789\n    }\n  ],\n  \"lease\": {\n    \"leader_id\": \"controller-1\",\n    \"term\": 5,\n    \"acquired_at\": 1642248500.0,\n    \"expires_at\": 1642248630.0,\n    \"renewed_at\": 1642248600.0,\n    \"hostname\": \"controller-1.local\",\n    \"api_url\": \"http://controller-1.local:8001\"\n  }\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#get-current-leader","title":"Get Current Leader","text":"<p>Get information about the current cluster leader.</p> <pre><code>GET /cluster/leader\n</code></pre> <p>Response: <pre><code>{\n  \"leader_id\": \"controller-1\",\n  \"hostname\": \"controller-1.local\",\n  \"api_url\": \"http://controller-1.local:8001\",\n  \"term\": 5,\n  \"lease_expires_at\": 1642248630.0\n}\n</code></pre></p> <p>Error Response (No leader elected): <pre><code>{\n  \"error\": \"No leader elected\",\n  \"code\": \"NO_LEADER\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#cluster-health-check","title":"Cluster Health Check","text":"<p>Get cluster health status with leadership information.</p> <pre><code>GET /cluster/health\n</code></pre> <p>Response (Healthy cluster): <pre><code>{\n  \"status\": \"healthy\",\n  \"clustering\": \"enabled\",\n  \"node_id\": \"controller-1\",\n  \"state\": \"leader\",\n  \"is_leader\": true,\n  \"leader_id\": \"controller-1\",\n  \"cluster_size\": 3,\n  \"cluster_ready\": true,\n  \"timestamp\": 1642248600.123,\n  \"version\": \"1.0.0\"\n}\n</code></pre></p> <p>Response (Single node mode): <pre><code>{\n  \"status\": \"healthy\",\n  \"clustering\": \"disabled\",\n  \"timestamp\": 1642248600.123,\n  \"version\": \"1.0.0\"\n}\n</code></pre></p> <p>Response (Degraded cluster): <pre><code>{\n  \"status\": \"degraded\",\n  \"clustering\": \"enabled\",\n  \"node_id\": \"controller-2\",\n  \"state\": \"follower\",\n  \"is_leader\": false,\n  \"leader_id\": null,\n  \"cluster_size\": 2,\n  \"cluster_ready\": false,\n  \"timestamp\": 1642248600.123,\n  \"version\": \"1.0.0\"\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#leader-redirection","title":"Leader Redirection","text":"<p>When write operations are sent to a non-leader node, the API returns a redirect response:</p> <pre><code>POST /api/v1/apps/register\n</code></pre> <p>Response (From non-leader node): <pre><code>HTTP/1.1 307 Temporary Redirect\nLocation: http://controller-1.local:8001/api/v1/apps/register\n\n{\n  \"error\": \"Request must be sent to leader node: http://controller-1.local:8001\",\n  \"code\": \"NOT_LEADER\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre></p> <p>Response (No leader available): <pre><code>HTTP/1.1 503 Service Unavailable\n\n{\n  \"error\": \"No leader elected, cluster not ready\",\n  \"code\": \"CLUSTER_NOT_READY\", \n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre></p>"},{"location":"user-guide/api-reference/#sdks-and-libraries","title":"SDKs and Libraries","text":""},{"location":"user-guide/api-reference/#python-sdk","title":"Python SDK","text":"<pre><code>import orchestry\n\nclient = orchestry.Client(\"http://localhost:8000\")\n\n# Register application\nwith open('app.yml') as f:\n    spec = yaml.safe_load(f)\nclient.register_app(spec)\n\n# Start application\nclient.start_app(\"my-app\", replicas=3)\n\n# Get status\nstatus = client.get_app_status(\"my-app\")\nprint(f\"App is {status['status']} with {status['replicas']['current']} replicas\")\n</code></pre>"},{"location":"user-guide/api-reference/#nodejs-sdk","title":"Node.js SDK","text":"<pre><code>const Orchestry = require('orchestry-client');\n\nconst client = new Orchestry('http://localhost:8000');\n\n// Register application\nconst spec = require('./app.json');\nawait client.registerApp(spec);\n\n// Start application\nawait client.startApp('my-app', { replicas: 3 });\n\n// Get status\nconst status = await client.getAppStatus('my-app');\nconsole.log(`App is ${status.status} with ${status.replicas.current} replicas`);\n</code></pre> <p>Next Steps: Learn about Configuration for advanced settings and environment setup.</p>"},{"location":"user-guide/app-spec/","title":"Application Specification","text":"<p>Learn how to define applications for Orchestry using YAML or JSON specifications.</p>"},{"location":"user-guide/app-spec/#overview","title":"Overview","text":"<p>Orchestry uses declarative specifications to define how your applications should be deployed, scaled, and monitored. These specifications are written in YAML or JSON format and contain all the information needed to run your application.</p>"},{"location":"user-guide/app-spec/#basic-structure","title":"Basic Structure","text":"<pre><code>apiVersion: v1\nkind: App\nmetadata:\n  name: my-application\n  labels:\n    app: \"my-application\"\n    version: \"v1\"\n    environment: \"production\"\nspec:\n  # Application configuration\n  type: http\n  image: \"my-app:latest\"\n  ports: []\n  resources: {}\n  environment: []\nscaling:\n  # Scaling configuration\n  mode: auto\n  minReplicas: 1\n  maxReplicas: 5\nhealthCheck:\n  # Health check configuration\n  path: \"/health\"\n  port: 8080\n</code></pre>"},{"location":"user-guide/app-spec/#complete-reference","title":"Complete Reference","text":""},{"location":"user-guide/app-spec/#root-fields","title":"Root Fields","text":"Field Type Required Description <code>apiVersion</code> string Yes API version (currently <code>v1</code>) <code>kind</code> string Yes Resource type (currently <code>App</code>) <code>metadata</code> object Yes Application metadata <code>spec</code> object Yes Application specification <code>scaling</code> object No Scaling configuration <code>healthCheck</code> object No Health check configuration"},{"location":"user-guide/app-spec/#metadata","title":"Metadata","text":"<p>The <code>metadata</code> section contains information about your application:</p> <pre><code>metadata:\n  name: my-web-app              # Required: DNS-compatible name\n  labels:\n    app: \"my-web-app\"          # Required: Application identifier\n    version: \"v1.2.3\"          # Recommended: Version tag\n    environment: \"production\"   # Optional: Environment label\n    team: \"backend\"            # Optional: Team ownership\n    tier: \"web\"                # Optional: Application tier\n</code></pre> <p>Fields:</p> Field Type Required Description <code>name</code> string Yes Unique application name (DNS-compatible) <code>labels</code> object Yes Key-value labels for organization <code>labels.app</code> string Yes Application identifier (must match name) <p>Label Restrictions: - Must be DNS-compatible (lowercase, alphanumeric, hyphens) - Maximum 63 characters per label value - Cannot start or end with hyphens</p>"},{"location":"user-guide/app-spec/#application-spec","title":"Application Spec","text":"<p>The <code>spec</code> section defines how your application runs:</p> <pre><code>spec:\n  type: http                    # Application type\n  image: \"nginx:alpine\"         # Container image\n  ports:                        # Port configuration\n    - containerPort: 80\n      protocol: HTTP\n  resources:                    # Resource limits\n    cpu: \"500m\"\n    memory: \"512Mi\"\n  environment:                  # Environment variables\n    - name: NODE_ENV\n      value: \"production\"\n    - name: DATABASE_URL\n      value: \"postgresql://...\"\n  command: [\"/bin/sh\"]          # Optional: Override entrypoint\n  args: [\"-c\", \"nginx -g 'daemon off;'\"]  # Optional: Command arguments\n  workingDir: \"/app\"            # Optional: Working directory\n  volumes:                      # Optional: Volume mounts\n    - name: \"app-data\"\n      mountPath: \"/data\"\n</code></pre>"},{"location":"user-guide/app-spec/#application-types","title":"Application Types","text":"Type Description Use Cases <code>http</code> HTTP web applications Web servers, APIs, SPAs"},{"location":"user-guide/app-spec/#ports-configuration","title":"Ports Configuration","text":"<pre><code>ports:\n  - containerPort: 8080         # Port inside container\n    protocol: HTTP              # Protocol (HTTP)\n    name: \"web\"                 # Optional: Port name\n</code></pre> <p>Protocol Types: - <code>HTTP</code>: For web applications (enables load balancing)</p>"},{"location":"user-guide/app-spec/#resources","title":"Resources","text":"<p>Define CPU and memory limits:</p> <pre><code>resources:\n  cpu: \"500m\"      # 500 millicores (0.5 CPU)\n  memory: \"1Gi\"    # 1 GiB memory\n</code></pre> <p>CPU Units: - <code>100m</code> = 0.1 CPU core - <code>1</code> = 1 CPU core - <code>2.5</code> = 2.5 CPU cores</p> <p>Memory Units: - <code>128Mi</code> = 128 MiB - <code>1Gi</code> = 1 GiB - <code>512M</code> = 512 MB</p>"},{"location":"user-guide/app-spec/#environment-variables","title":"Environment Variables","text":"<pre><code>environment:\n  # Static value\n  - name: NODE_ENV\n    value: \"production\"\n\n  # Orchestry-provided values\n  - name: INSTANCE_IP\n    source: sdk\n    key: \"instance.ip\"\n\n  # From secrets (future feature)\n  - name: DB_PASSWORD\n    source: secret\n    key: \"database-credentials\"\n    field: \"password\"\n</code></pre> <p>SDK-Provided Variables:</p> Key Description Example Value <code>instance.ip</code> Container IP address <code>172.20.0.5</code> <code>instance.port</code> Primary container port <code>8080</code> <code>app.name</code> Application name <code>my-web-app</code> <code>app.replicas</code> Current replica count <code>3</code>"},{"location":"user-guide/app-spec/#volumes-future-feature","title":"Volumes (Future Feature)","text":"<pre><code>volumes:\n  - name: \"app-data\"\n    mountPath: \"/data\"\n    size: \"10Gi\"\n    storageClass: \"fast\"\n  - name: \"config\"\n    mountPath: \"/etc/config\"\n    configMap: \"app-config\"\n</code></pre>"},{"location":"user-guide/app-spec/#scaling-configuration","title":"Scaling Configuration","text":"<p>Control how your application scales:</p> <pre><code>scaling:\n  mode: auto                    # Scaling mode: auto, manual\n  minReplicas: 1               # Minimum replicas\n  maxReplicas: 10              # Maximum replicas\n\n  # Auto-scaling thresholds\n  targetRPSPerReplica: 50      # Target requests per second per replica\n  maxP95LatencyMs: 250         # Maximum 95th percentile latency\n  maxCPUPercent: 70            # Maximum CPU utilization\n  maxMemoryPercent: 75         # Maximum memory utilization\n  maxConnPerReplica: 100       # Maximum connections per replica\n\n  # Scaling behavior\n  scaleOutThresholdPct: 80     # Scale out when metrics exceed this %\n  scaleInThresholdPct: 30      # Scale in when metrics below this %\n  windowSeconds: 60            # Metrics evaluation window\n  cooldownSeconds: 180         # Minimum time between scaling events\n</code></pre>"},{"location":"user-guide/app-spec/#scaling-modes","title":"Scaling Modes","text":"Mode Description When to Use <code>auto</code> Automatic scaling based on metrics Production workloads <code>manual</code> Manual scaling only Development, controlled environments"},{"location":"user-guide/app-spec/#scaling-metrics","title":"Scaling Metrics","text":"<p>Orchestry scales based on multiple metrics:</p> <ol> <li>CPU Utilization: Target 70% average across replicas</li> <li>Memory Usage: Target 75% average across replicas  </li> <li>Requests Per Second: Target 50 RPS per replica</li> <li>Response Latency: Keep P95 latency under 250ms</li> <li>Active Connections: Target 100 connections per replica</li> </ol>"},{"location":"user-guide/app-spec/#scaling-behavior","title":"Scaling Behavior","text":"<pre><code>scaling:\n  # Threshold configuration\n  scaleOutThresholdPct: 80     # Scale out when any metric &gt; 80% of target\n  scaleInThresholdPct: 30      # Scale in when all metrics &lt; 30% of target\n\n  # Timing configuration\n  windowSeconds: 60            # Evaluate metrics over 60 seconds\n  cooldownSeconds: 180         # Wait 3 minutes between scaling actions\n\n  # Advanced settings (optional)\n  maxScaleOutStep: 2           # Maximum replicas to add at once\n  maxScaleInStep: 1            # Maximum replicas to remove at once\n  stabilizationWindowSeconds: 300  # Wait for stability after scaling\n</code></pre>"},{"location":"user-guide/app-spec/#health-check-configuration","title":"Health Check Configuration","text":"<p>Define how Orchestry monitors your application health:</p> <pre><code>healthCheck:\n  path: \"/health\"               # Health check endpoint\n  port: 8080                   # Health check port\n  protocol: HTTP               # Protocol (HTTP, TCP)\n  method: GET                  # HTTP method (GET, POST)\n\n  # Timing configuration\n  initialDelaySeconds: 30      # Wait before first check\n  periodSeconds: 10            # Check interval\n  timeoutSeconds: 5            # Request timeout\n\n  # Failure handling\n  failureThreshold: 3          # Failures before marking unhealthy\n  successThreshold: 1          # Successes before marking healthy\n\n  # Advanced options\n  headers:                     # Custom headers\n    - name: \"Authorization\"\n      value: \"Bearer token\"\n  expectedStatusCodes: [200, 204]  # Expected HTTP status codes\n</code></pre>"},{"location":"user-guide/app-spec/#health-check-types","title":"Health Check Types","text":"<p>HTTP Health Checks:</p> <pre><code>healthCheck:\n  path: \"/api/health\"\n  port: 8080\n  protocol: HTTP\n  method: GET\n  expectedStatusCodes: [200]\n  headers:\n    - name: \"User-Agent\"\n      value: \"Orchestry-HealthCheck/1.0\"\n</code></pre> <p>Custom Health Checks:</p> <pre><code>healthCheck:\n  path: \"/health/detailed\"\n  port: 8080\n  protocol: HTTP\n  method: POST\n  headers:\n    - name: \"Content-Type\"\n      value: \"application/json\"\n  body: '{\"check\": \"full\"}'\n  expectedStatusCodes: [200, 202]\n</code></pre>"},{"location":"user-guide/app-spec/#complete-examples","title":"Complete Examples","text":""},{"location":"user-guide/app-spec/#simple-web-application","title":"Simple Web Application","text":"<pre><code>apiVersion: v1\nkind: App\nmetadata:\n  name: simple-web\n  labels:\n    app: \"simple-web\"\n    version: \"v1\"\nspec:\n  type: http\n  image: \"nginx:alpine\"\n  ports:\n    - containerPort: 80\n      protocol: HTTP\n  resources:\n    cpu: \"100m\"\n    memory: \"128Mi\"\nscaling:\n  mode: auto\n  minReplicas: 1\n  maxReplicas: 3\n  targetRPSPerReplica: 100\nhealthCheck:\n  path: \"/\"\n  port: 80\n  initialDelaySeconds: 5\n  periodSeconds: 30\n</code></pre>"},{"location":"user-guide/app-spec/#production-api-service","title":"Production API Service","text":"<pre><code>apiVersion: v1\nkind: App\nmetadata:\n  name: user-api\n  labels:\n    app: \"user-api\"\n    version: \"v2.1.0\"\n    environment: \"production\"\n    team: \"backend\"\nspec:\n  type: http\n  image: \"myregistry/user-api:v2.1.0\"\n  ports:\n    - containerPort: 8080\n      protocol: HTTP\n      name: \"api\"\n  resources:\n    cpu: \"1000m\"\n    memory: \"2Gi\"\n  environment:\n    - name: NODE_ENV\n      value: \"production\"\n    - name: PORT\n      value: \"8080\"\n    - name: DATABASE_URL\n      source: secret\n      key: \"database-credentials\"\n    - name: REDIS_URL\n      source: secret\n      key: \"redis-credentials\"\n    - name: INSTANCE_IP\n      source: sdk\n      key: \"instance.ip\"\nscaling:\n  mode: auto\n  minReplicas: 3\n  maxReplicas: 20\n  targetRPSPerReplica: 100\n  maxP95LatencyMs: 200\n  maxCPUPercent: 70\n  maxMemoryPercent: 80\n  scaleOutThresholdPct: 75\n  scaleInThresholdPct: 25\n  windowSeconds: 120\n  cooldownSeconds: 300\nhealthCheck:\n  path: \"/api/v2/health\"\n  port: 8080\n  protocol: HTTP\n  method: GET\n  initialDelaySeconds: 45\n  periodSeconds: 15\n  timeoutSeconds: 10\n  failureThreshold: 3\n  successThreshold: 1\n  headers:\n    - name: \"Authorization\"\n      value: \"Bearer health-check-token\"\n  expectedStatusCodes: [200]\n</code></pre>"},{"location":"user-guide/app-spec/#validation-rules","title":"Validation Rules","text":"<p>Orchestry validates specifications before deployment:</p>"},{"location":"user-guide/app-spec/#required-fields","title":"Required Fields","text":"<ul> <li><code>apiVersion</code>: Must be <code>v1</code></li> <li><code>kind</code>: Must be <code>App</code></li> <li><code>metadata.name</code>: Must be DNS-compatible</li> <li><code>metadata.labels.app</code>: Must match <code>metadata.name</code></li> <li><code>spec.type</code>: Must be <code>http</code></li> <li><code>spec.image</code>: Must be a valid container image reference</li> </ul>"},{"location":"user-guide/app-spec/#naming-conventions","title":"Naming Conventions","text":"<p>Application Names: - Lowercase letters, numbers, and hyphens only - Must start and end with alphanumeric character - Maximum 253 characters - Must be unique within Orchestry instance</p> <p>Label Values: - Same rules as application names - Maximum 63 characters</p>"},{"location":"user-guide/app-spec/#resource-limits","title":"Resource Limits","text":"<p>CPU: - Minimum: <code>10m</code> (0.01 CPU) - Maximum: <code>16</code> (16 CPUs) - Must be positive number</p> <p>Memory: - Minimum: <code>64Mi</code> (64 MiB) - Maximum: <code>64Gi</code> (64 GiB) - Must be positive number</p>"},{"location":"user-guide/app-spec/#scaling-limits","title":"Scaling Limits","text":"<ul> <li><code>minReplicas</code>: 1-100</li> <li><code>maxReplicas</code>: 1-100, must be \u2265 <code>minReplicas</code></li> <li><code>targetRPSPerReplica</code>: 1-10000</li> <li><code>maxP95LatencyMs</code>: 1-30000</li> <li>Percentages: 1-100</li> </ul>"},{"location":"user-guide/app-spec/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/app-spec/#application-design","title":"Application Design","text":"<ol> <li>Stateless Applications: Design apps to be stateless for easy scaling</li> <li>Health Endpoints: Always provide meaningful health check endpoints</li> <li>Graceful Shutdown: Handle SIGTERM signals for graceful shutdown</li> <li>Resource Limits: Set appropriate CPU and memory limits</li> <li>Environment Configuration: Use environment variables for configuration</li> </ol>"},{"location":"user-guide/app-spec/#scaling-configuration_1","title":"Scaling Configuration","text":"<ol> <li>Conservative Limits: Start with conservative scaling limits</li> <li>Monitoring: Monitor scaling behavior and adjust thresholds</li> <li>Cooldown Periods: Use appropriate cooldown periods to prevent flapping</li> <li>Multiple Metrics: Don't rely on a single metric for scaling decisions</li> </ol>"},{"location":"user-guide/app-spec/#production-readiness","title":"Production Readiness","text":"<ol> <li>Health Checks: Configure comprehensive health checks</li> <li>Resource Monitoring: Set up monitoring and alerting</li> <li>Version Tags: Always use specific version tags, not <code>latest</code></li> <li>Security: Use minimal base images and security scanning</li> <li>Backup Strategy: Plan for data backup and recovery</li> </ol>"},{"location":"user-guide/app-spec/#development-workflow","title":"Development Workflow","text":"<ol> <li>Validate Locally: Test specifications locally before deployment</li> <li>Version Control: Store specifications in version control</li> <li>Environment Promotion: Use different specifications per environment</li> <li>Documentation: Document application-specific configuration</li> </ol>"},{"location":"user-guide/app-spec/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/app-spec/#common-validation-errors","title":"Common Validation Errors","text":"<p>Invalid Name: <pre><code>Error: metadata.name must be DNS-compatible\nSolution: Use lowercase letters, numbers, and hyphens only\n</code></pre></p> <p>Missing Required Fields: <pre><code>Error: spec.image is required\nSolution: Add image field to spec section\n</code></pre></p> <p>Invalid Resource Format: <pre><code>Error: resources.cpu must be a valid quantity (e.g., \"500m\", \"1\")\nSolution: Use proper CPU units (millicores or cores)\n</code></pre></p> <p>Scaling Configuration Issues: <pre><code>Error: scaling.maxReplicas must be &gt;= scaling.minReplicas\nSolution: Ensure maxReplicas is greater than or equal to minReplicas\n</code></pre></p>"},{"location":"user-guide/app-spec/#deployment-issues","title":"Deployment Issues","text":"<p>Image Pull Errors: - Verify image exists and is accessible - Check registry credentials - Use full image path with registry</p> <p>Health Check Failures: - Verify health endpoint is accessible - Check port configuration - Increase initial delay if needed</p> <p>Resource Constraints: - Monitor actual resource usage - Adjust limits based on application needs - Consider node capacity limits</p> <p>Next Steps: Learn about Configuration and Environment Variables for advanced settings.</p>"},{"location":"user-guide/cli-reference/","title":"CLI Reference","text":"<p>Complete reference for the Orchestry command-line interface.</p>"},{"location":"user-guide/cli-reference/#installation","title":"Installation","text":"<p>The CLI is automatically installed when you install Orchestry:</p> <pre><code>pip install orchestry\n</code></pre> <p>Or install from source</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"user-guide/cli-reference/#options","title":"Options","text":"<pre><code>orchestry --help\n</code></pre>"},{"location":"user-guide/cli-reference/#commands-overview","title":"Commands Overview","text":"Command Description <code>config</code> Configure the controller endpoint (interactive) <code>register</code> Register an application from YAML/JSON spec <code>up</code> Start an application <code>down</code> Stop an application <code>delete</code> Delete an application completely (stops &amp; removes) <code>status</code> Show application status <code>scale</code> Scale an application to specific replica count <code>list</code> List all applications <code>metrics</code> Get system or app metrics <code>info</code> Show orchestry system information and status <code>spec</code> Get app specification (supports --raw flag) <code>logs</code> View application logs <code>cluster</code> Get cluster information (status, leader, health) <code>events</code> Get recent events"},{"location":"user-guide/cli-reference/#application-management","title":"Application Management","text":""},{"location":"user-guide/cli-reference/#config","title":"config","text":"<p>Interactively configure the controller endpoint used by all commands.</p> <pre><code>orchestry config\n</code></pre> <p>This command: - Prompts you for Host and Port - Verifies the controller is reachable at http://HOST:PORT/health - Saves the configuration to your OS config directory</p> <p>Examples: <pre><code># Run interactive setup\norchestry config\n</code></pre></p>"},{"location":"user-guide/cli-reference/#register","title":"register","text":"<p>Register an application from a specification file.</p> <pre><code>orchestry register CONFIG_FILE\n</code></pre> <p>Arguments: - <code>CONFIG_FILE</code>: Path to YAML or JSON application specification</p> <p>Examples: <pre><code># Register from YAML file\norchestry register my-app.yml\n\n# Register from JSON file  \norchestry register my-app.json\n</code></pre></p>"},{"location":"user-guide/cli-reference/#up","title":"up","text":"<p>Start a registered application.</p> <pre><code>orchestry up APP_NAME\n</code></pre> <p>Arguments: - <code>APP_NAME</code>: Name of the application to start</p> <p>Examples: <pre><code># Start application\norchestry up my-app\n</code></pre></p>"},{"location":"user-guide/cli-reference/#down","title":"down","text":"<p>Stop a running application.</p> <pre><code>orchestry down APP_NAME\n</code></pre> <p>Arguments: - <code>APP_NAME</code>: Name of the application to stop</p> <p>Examples: <pre><code># Stop application\norchestry down my-app\n</code></pre></p>"},{"location":"user-guide/cli-reference/#delete","title":"delete","text":"<p>Delete an application completely (stops containers and removes registration).</p> <pre><code>orchestry delete APP_NAME [--force]\n</code></pre> <p>Arguments: - <code>APP_NAME</code>: Name of the application to delete</p> <p>Options: - <code>--force, -f</code>: Skip confirmation prompt</p> <p>Examples: <pre><code># Delete application (with confirmation)\norchestry delete my-app\n\n# Delete application (skip confirmation)\norchestry delete my-app --force\norchestry delete my-app -f\n</code></pre></p> <p>What happens: - All running containers are stopped and removed - Health checks are unregistered - Nginx configuration is removed - Application is removed from the database - Deletion event is logged for audit trail</p> <p>Warning: This action cannot be undone. You will need to re-register the application if you want to use it again.</p>"},{"location":"user-guide/cli-reference/#scale","title":"scale","text":"<p>Scale an application to a specific number of replicas.</p> <pre><code>orchestry scale APP_NAME REPLICAS\n</code></pre> <p>Arguments: - <code>APP_NAME</code>: Name of the application to scale - <code>REPLICAS</code>: Target number of replicas</p> <p>Examples: <pre><code># Scale to 5 replicas\norchestry scale my-app 5\n\n# Scale to 3 replicas\norchestry scale my-app 3\n</code></pre></p> <p>Note: If the app is in auto mode, autoscaling may override the manual scaling. To prevent this, set <code>mode: manual</code> in the scaling section of your YAML spec.</p>"},{"location":"user-guide/cli-reference/#information-commands","title":"Information Commands","text":""},{"location":"user-guide/cli-reference/#status","title":"status","text":"<p>Show application status and health.</p> <pre><code>orchestry status APP_NAME\n</code></pre> <p>Arguments: - <code>APP_NAME</code>: Application name</p> <p>Examples: <pre><code># Show status of specific app\norchestry status my-app\n</code></pre></p>"},{"location":"user-guide/cli-reference/#list","title":"list","text":"<p>List all registered applications.</p> <pre><code>orchestry list\n</code></pre> <p>Examples: <pre><code># List all applications\norchestry list\n</code></pre></p>"},{"location":"user-guide/cli-reference/#info","title":"info","text":"<p>Show orchestry system information and status.</p> <pre><code>orchestry info\n</code></pre> <p>Examples: <pre><code># Show system info\norchestry info\n</code></pre></p> <p>This displays: - Orchestry Controller status - API endpoint - Number of registered apps - Docker services status</p>"},{"location":"user-guide/cli-reference/#spec","title":"spec","text":"<p>Get app specification.</p> <pre><code>orchestry spec APP_NAME [--raw]\n</code></pre> <p>Arguments: - <code>APP_NAME</code>: Name of the application</p> <p>Options: - <code>--raw</code>: Show the original submitted spec (default: false)</p> <p>Examples: <pre><code># Get parsed specification\norchestry spec my-app\n\n# Get raw specification as originally submitted\norchestry spec my-app --raw\n</code></pre></p>"},{"location":"user-guide/cli-reference/#monitoring-commands","title":"Monitoring Commands","text":""},{"location":"user-guide/cli-reference/#logs","title":"logs","text":"<p>View application container logs.</p> <pre><code>orchestry logs APP_NAME [OPTIONS]\n</code></pre> <p>Arguments: - <code>APP_NAME</code>: Name of the application</p> <p>Options: - <code>--lines, -n INTEGER</code>: Number of log lines to retrieve (default: 100) - <code>--follow, -f</code>: Follow log output (not yet implemented)</p> <p>Examples: <pre><code># Show recent logs (last 100 lines)\norchestry logs my-app\n\n# Show last 50 lines\norchestry logs my-app --lines 50\n\n# Show last 200 lines\norchestry logs my-app -n 200\n</code></pre></p> <p>Note: The <code>--follow</code> option is recognized but not yet implemented. Logs are displayed sorted by timestamp across all containers.</p>"},{"location":"user-guide/cli-reference/#events","title":"events","text":"<p>Get recent events.</p> <pre><code>orchestry events\n</code></pre> <p>Examples: <pre><code># Show recent events\norchestry events\n</code></pre></p>"},{"location":"user-guide/cli-reference/#metrics","title":"metrics","text":"<p>Get system or app metrics.</p> <pre><code>orchestry metrics [APP_NAME]\n</code></pre> <p>Arguments: - <code>APP_NAME</code>: Name of the application (optional)</p> <p>Examples: <pre><code># Show system metrics\norchestry metrics\n\n# Show metrics for specific app\norchestry metrics my-app\n</code></pre></p>"},{"location":"user-guide/cli-reference/#cluster-commands","title":"Cluster Commands","text":""},{"location":"user-guide/cli-reference/#cluster","title":"cluster","text":"<p>Get cluster information (status, leader, health).</p> <pre><code>orchestry cluster OPTS\n</code></pre> <p>Arguments: - <code>OPTS</code>: Options like <code>status</code>, <code>leader</code>, or <code>health</code></p> <p>Examples: <pre><code># Show cluster status\norchestry cluster status\n\n# Show cluster leader\norchestry cluster leader\n\n# Show cluster health\norchestry cluster health\n</code></pre></p>"},{"location":"user-guide/cli-reference/#output-format","title":"Output Format","text":"<p>All commands return JSON-formatted output that can be piped to other tools like <code>jq</code> for parsing:</p> <pre><code># Pretty-print with jq\norchestry list | jq .\n\n# Get specific field\norchestry status my-app | jq '.status'\n</code></pre>"},{"location":"user-guide/cli-reference/#error-handling","title":"Error Handling","text":"<p>The CLI provides clear error messages:</p> <pre><code># Service not running\n$ orchestry status my-app\n orchestry controller is not running, run 'orchestry config' to configure\n\n# Application not found\n$ orchestry status nonexistent\n App 'nonexistent' not found\n\n# Registration failed\n$ orchestry register invalid.yml\n Registration failed: {...}\n</code></pre>"},{"location":"user-guide/cli-reference/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ol> <li>Configure first: Always run <code>orchestry config</code> before using other commands</li> <li>Use descriptive app names: Choose clear, meaningful names for your applications</li> <li>Monitor scaling: For apps in auto mode, remember that manual scaling may be overridden</li> <li>Keep specs in version control: Store your YAML/JSON specs in git</li> <li>Check info regularly: Use <code>orchestry info</code> to monitor system health</li> </ol> <p>Next Steps: Learn about Application Specifications to define your applications.</p>"},{"location":"user-guide/configuration/","title":"Configuration Guide","text":"<p>Complete guide to configuring Orchestry for different environments and use cases.</p>"},{"location":"user-guide/configuration/#configuration-overview","title":"Configuration Overview","text":"<p>Orchestry can be configured through multiple methods:</p> <ol> <li>Environment Variables - Runtime configuration</li> <li>Configuration Files - Structured configuration</li> <li>Docker Compose - Container orchestration settings</li> <li>Application Specifications - Per-app configuration</li> </ol>"},{"location":"user-guide/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"user-guide/configuration/#controller-settings","title":"Controller Settings","text":"<p>Configure the main Orchestry controller:</p> <pre><code># API Server Configuration\nORCHESTRY_HOST=0.0.0.0              # Bind address (default: 0.0.0.0)\nORCHESTRY_PORT=8000                 # API port (default: 8000)\n# ORCHESTRY_WORKERS=4                 # Number of worker processes\nORCHESTRY_LOG_LEVEL=INFO            # Logging level (DEBUG, INFO, WARN, ERROR)\n\n# Controller Settings\nCONTROLLER_NODE_ID=controller-1     # Unique node identifier\nCONTROLLER_API_URL=http://localhost:8000  # External API URL\nCLUSTER_MODE=false                  # Enable cluster mode\n</code></pre>"},{"location":"user-guide/configuration/#database-configuration","title":"Database Configuration","text":"<p>Configure PostgreSQL connection and behavior:</p> <pre><code># Primary Database\nPOSTGRES_HOST=localhost             # Database host\nPOSTGRES_PORT=5432                  # Database port\nPOSTGRES_DB=orchestry              # Database name\nPOSTGRES_USER=orchestry            # Database username\nPOSTGRES_PASSWORD=orchestry_password # Database password\n\n# Connection Pool\nPOSTGRES_POOL_SIZE=10              # Maximum connections\nPOSTGRES_POOL_TIMEOUT=30           # Connection timeout (seconds)\nPOSTGRES_RETRY_ATTEMPTS=3          # Connection retry attempts\nPOSTGRES_RETRY_DELAY=5             # Retry delay (seconds)\n\n# Read Replica (Optional)\nPOSTGRES_REPLICA_HOST=localhost    # Replica host\nPOSTGRES_REPLICA_PORT=5433         # Replica port\nPOSTGRES_READ_ONLY=false           # Force read-only operations to replica\n</code></pre>"},{"location":"user-guide/configuration/#docker-configuration","title":"Docker Configuration","text":"<p>Configure Docker daemon integration:</p> <pre><code># Docker Settings\nDOCKER_HOST=unix:///var/run/docker.sock  # Docker daemon socket\nDOCKER_API_VERSION=auto            # Docker API version\nDOCKER_TIMEOUT=60                  # Operation timeout (seconds)\n\n# Container Network\nDOCKER_NETWORK=orchestry           # Container network name\nDOCKER_SUBNET=172.20.0.0/16       # Network subnet\nCONTAINER_CPU_LIMIT=2.0            # Default CPU limit per container\nCONTAINER_MEMORY_LIMIT=2Gi         # Default memory limit per container\n</code></pre>"},{"location":"user-guide/configuration/#scaling-configuration","title":"Scaling Configuration","text":"<p>Configure auto-scaling behavior:</p> <pre><code># Scaling Engine\nSCALE_CHECK_INTERVAL=30            # Scaling check interval (seconds)\nSCALE_COOLDOWN=180                 # Default cooldown (seconds)\nSCALE_MAX_CONCURRENT=3             # Max concurrent scaling operations\nSCALE_HISTORY_RETENTION=168        # Hours to retain scaling history\n\n# Default Scaling Policies\nDEFAULT_MIN_REPLICAS=1             # Default minimum replicas\nDEFAULT_MAX_REPLICAS=5             # Default maximum replicas\nDEFAULT_TARGET_RPS=50              # Default target RPS per replica\nDEFAULT_MAX_LATENCY=250            # Default max P95 latency (ms)\nDEFAULT_MAX_CPU=70                 # Default max CPU % \nDEFAULT_MAX_MEMORY=75              # Default max memory %\n</code></pre>"},{"location":"user-guide/configuration/#health-check-configuration","title":"Health Check Configuration","text":"<p>Configure health monitoring:</p> <pre><code># Health Check Engine\nHEALTH_CHECK_INTERVAL=10           # Health check interval (seconds)\nHEALTH_CHECK_TIMEOUT=5             # Health check timeout (seconds)\nHEALTH_CHECK_RETRIES=3             # Retries before marking unhealthy\nHEALTH_CHECK_PARALLEL=10           # Max parallel health checks\n\n# Default Health Check Settings\nDEFAULT_INITIAL_DELAY=30           # Default initial delay (seconds)\nDEFAULT_PERIOD=30                  # Default check period (seconds)\nDEFAULT_FAILURE_THRESHOLD=3        # Default failure threshold\nDEFAULT_SUCCESS_THRESHOLD=1        # Default success threshold\n</code></pre>"},{"location":"user-guide/configuration/#nginx-configuration","title":"Nginx Configuration","text":"<p>Configure the load balancer:</p> <pre><code># Nginx Settings\nNGINX_CONFIG_PATH=/etc/nginx/conf.d # Nginx configuration directory\nNGINX_TEMPLATE_PATH=/etc/nginx/templates # Template directory\nNGINX_RELOAD_COMMAND=\"nginx -s reload\" # Reload command\nNGINX_TEST_COMMAND=\"nginx -t\"      # Configuration test command\n\n# Load Balancing\nNGINX_UPSTREAM_METHOD=least_conn   # Load balancing method\nNGINX_KEEPALIVE_TIMEOUT=75         # Keepalive timeout\nNGINX_KEEPALIVE_REQUESTS=100       # Keepalive requests\nNGINX_PROXY_TIMEOUT=60             # Proxy timeout\n</code></pre>"},{"location":"user-guide/configuration/#metrics-and-monitoring","title":"Metrics and Monitoring","text":"<p>Configure metrics collection:</p> <pre><code># Metrics Collection\nMETRICS_ENABLED=true               # Enable metrics collection\nMETRICS_INTERVAL=10                # Collection interval (seconds)\nMETRICS_RETENTION_HOURS=168        # Hours to retain metrics\nMETRICS_EXPORT_PORT=9090           # Prometheus export port\n\n# Alerting (Future)\nALERTS_ENABLED=false               # Enable alerting\nALERT_MANAGER_URL=http://localhost:9093 # AlertManager URL\n</code></pre>"},{"location":"user-guide/configuration/#configuration-files","title":"Configuration Files","text":""},{"location":"user-guide/configuration/#main-configuration-file","title":"Main Configuration File","text":"<p>Create <code>/etc/orchestry/config.yaml</code>:</p> <pre><code># Orchestry Configuration\nversion: \"1.0\"\n\n# Controller Configuration\ncontroller:\n  host: \"0.0.0.0\"\n  port: 8000\n  workers: 4\n  log_level: \"INFO\"\n  cluster_mode: false\n  node_id: \"controller-1\"\n  api_url: \"http://localhost:8000\"\n\n# Database Configuration\ndatabase:\n  primary:\n    host: \"localhost\"\n    port: 5432\n    name: \"orchestry\"\n    user: \"orchestry\"\n    password: \"orchestry_password\"\n    pool_size: 10\n    timeout: 30\n  replica:\n    enabled: false\n    host: \"localhost\"\n    port: 5433\n    read_only: false\n\n# Docker Configuration\ndocker:\n  host: \"unix:///var/run/docker.sock\"\n  api_version: \"auto\"\n  timeout: 60\n  network: \"orchestry\"\n  subnet: \"172.20.0.0/16\"\n\n# Default Resource Limits\nresources:\n  default_cpu_limit: \"1000m\"\n  default_memory_limit: \"1Gi\"\n  max_cpu_per_container: \"4000m\"\n  max_memory_per_container: \"8Gi\"\n\n# Scaling Configuration\nscaling:\n  check_interval: 30\n  default_cooldown: 180\n  max_concurrent_operations: 3\n  history_retention_hours: 168\n\n  # Default Policies\n  defaults:\n    min_replicas: 1\n    max_replicas: 5\n    target_rps_per_replica: 50\n    max_p95_latency_ms: 250\n    max_cpu_percent: 70\n    max_memory_percent: 75\n    scale_out_threshold_pct: 80\n    scale_in_threshold_pct: 30\n    window_seconds: 60\n\n# Health Check Configuration\nhealth:\n  check_interval: 10\n  check_timeout: 5\n  max_retries: 3\n  parallel_checks: 10\n\n  # Default Settings\n  defaults:\n    initial_delay_seconds: 30\n    period_seconds: 30\n    failure_threshold: 3\n    success_threshold: 1\n\n# Nginx Configuration\nnginx:\n  config_path: \"/etc/nginx/conf.d\"\n  template_path: \"/etc/nginx/templates\"\n  reload_command: \"nginx -s reload\"\n  test_command: \"nginx -t\"\n\n  # Load Balancing\n  upstream_method: \"least_conn\"\n  keepalive_timeout: 75\n  keepalive_requests: 100\n  proxy_timeout: 60\n\n# Metrics Configuration\nmetrics:\n  enabled: true\n  collection_interval: 10\n  retention_hours: 168\n  export_port: 9090\n\n# Logging Configuration\nlogging:\n  level: \"INFO\"\n  format: \"json\"\n  file: \"/var/log/orchestry/controller.log\"\n  max_size_mb: 100\n  max_files: 10\n  compress: true\n</code></pre>"},{"location":"user-guide/configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"user-guide/configuration/#development-configuration","title":"Development Configuration","text":"<p>Create <code>.env.development</code>:</p> <pre><code># Development Environment\nNODE_ENV=development\nORCHESTRY_LOG_LEVEL=DEBUG\n\n# Relaxed Settings\nSCALE_CHECK_INTERVAL=60\nHEALTH_CHECK_INTERVAL=30\nDEFAULT_MIN_REPLICAS=1\nDEFAULT_MAX_REPLICAS=3\n\n# Local Database\nPOSTGRES_HOST=localhost\nPOSTGRES_DB=orchestry_dev\n\n# Development Features\nMETRICS_ENABLED=false\nCLUSTER_MODE=false\n</code></pre>"},{"location":"user-guide/configuration/#production-configuration","title":"Production Configuration","text":"<p>Create <code>.env.production</code>:</p> <pre><code># Production Environment\nNODE_ENV=production\nORCHESTRY_LOG_LEVEL=INFO\n\n# Optimized Settings\nSCALE_CHECK_INTERVAL=15\nHEALTH_CHECK_INTERVAL=10\nDEFAULT_MIN_REPLICAS=2\nDEFAULT_MAX_REPLICAS=20\n\n# Production Database\nPOSTGRES_HOST=postgres-cluster.example.com\nPOSTGRES_DB=orchestry_prod\nPOSTGRES_POOL_SIZE=20\n\n# High Availability\nCLUSTER_MODE=true\nMETRICS_ENABLED=true\nPOSTGRES_REPLICA_HOST=postgres-read.example.com\n</code></pre>"},{"location":"user-guide/configuration/#staging-configuration","title":"Staging Configuration","text":"<p>Create <code>.env.staging</code>:</p> <pre><code># Staging Environment\nNODE_ENV=staging\nORCHESTRY_LOG_LEVEL=INFO\n\n# Moderate Settings\nSCALE_CHECK_INTERVAL=30\nHEALTH_CHECK_INTERVAL=15\nDEFAULT_MIN_REPLICAS=1\nDEFAULT_MAX_REPLICAS=10\n\n# Staging Database\nPOSTGRES_HOST=postgres-staging.example.com\nPOSTGRES_DB=orchestry_staging\n\n# Testing Features\nMETRICS_ENABLED=true\nCLUSTER_MODE=false\n</code></pre>"},{"location":"user-guide/configuration/#docker-compose-configuration","title":"Docker Compose Configuration","text":""},{"location":"user-guide/configuration/#basic-docker-compose","title":"Basic Docker Compose","text":"<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  orchestry-controller:\n    build: .\n    container_name: orchestry-controller\n    environment:\n      - ORCHESTRY_HOST=0.0.0.0\n      - ORCHESTRY_PORT=8000\n      - POSTGRES_HOST=postgres-primary\n      - POSTGRES_DB=orchestry\n      - POSTGRES_USER=orchestry\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ./logs:/app/logs\n    depends_on:\n      - postgres-primary\n    networks:\n      - orchestry\n    restart: unless-stopped\n\n  postgres-primary:\n    image: postgres:15-alpine\n    container_name: orchestry-postgres-primary\n    environment:\n      POSTGRES_DB: orchestry\n      POSTGRES_USER: orchestry\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    ports:\n      - \"5432:5432\"\n    networks:\n      - orchestry\n    restart: unless-stopped\n\n  nginx:\n    image: nginx:alpine\n    container_name: orchestry-nginx\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./configs/nginx/nginx.conf:/etc/nginx/nginx.conf\n      - ./configs/nginx/conf.d:/etc/nginx/conf.d\n      - ./ssl:/etc/nginx/ssl\n    networks:\n      - orchestry\n    restart: unless-stopped\n\nvolumes:\n  postgres_data:\n\nnetworks:\n  orchestry:\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 172.20.0.0/16\n</code></pre>"},{"location":"user-guide/configuration/#production-docker-compose","title":"Production Docker Compose","text":"<pre><code># docker-compose.prod.yml\nversion: '3.8'\n\nservices:\n  orchestry-controller:\n    image: orchestry:latest\n    deploy:\n      replicas: 3\n      resources:\n        limits:\n          cpus: '2.0'\n          memory: 2G\n        reservations:\n          cpus: '1.0'\n          memory: 1G\n    environment:\n      - NODE_ENV=production\n      - CLUSTER_MODE=true\n      - POSTGRES_POOL_SIZE=20\n      - SCALE_CHECK_INTERVAL=15\n    configs:\n      - source: orchestry_config\n        target: /etc/orchestry/config.yaml\n    secrets:\n      - postgres_password\n      - api_secret_key\n    networks:\n      - orchestry\n      - monitoring\n\n  postgres-primary:\n    image: postgres:15-alpine\n    deploy:\n      replicas: 1\n      resources:\n        limits:\n          cpus: '4.0'\n          memory: 8G\n    environment:\n      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password\n    volumes:\n      - postgres_primary_data:/var/lib/postgresql/data\n    secrets:\n      - postgres_password\n    networks:\n      - orchestry\n\n  postgres-replica:\n    image: postgres:15-alpine\n    deploy:\n      replicas: 2\n    environment:\n      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password\n    volumes:\n      - postgres_replica_data:/var/lib/postgresql/data\n    secrets:\n      - postgres_password\n    networks:\n      - orchestry\n\n  nginx:\n    image: nginx:alpine\n    deploy:\n      replicas: 2\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    configs:\n      - source: nginx_config\n        target: /etc/nginx/nginx.conf\n    networks:\n      - orchestry\n      - external\n\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n    configs:\n      - source: prometheus_config\n        target: /etc/prometheus/prometheus.yml\n    networks:\n      - monitoring\n\n  grafana:\n    image: grafana/grafana:latest\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD__FILE=/run/secrets/grafana_password\n    secrets:\n      - grafana_password\n    networks:\n      - monitoring\n\nconfigs:\n  orchestry_config:\n    file: ./configs/orchestry/config.yaml\n  nginx_config:\n    file: ./configs/nginx/nginx.conf\n  prometheus_config:\n    file: ./configs/prometheus/prometheus.yml\n\nsecrets:\n  postgres_password:\n    external: true\n  api_secret_key:\n    external: true\n  grafana_password:\n    external: true\n\nvolumes:\n  postgres_primary_data:\n  postgres_replica_data:\n\nnetworks:\n  orchestry:\n    driver: overlay\n    attachable: true\n  monitoring:\n    driver: overlay\n  external:\n    external: true\n</code></pre>"},{"location":"user-guide/configuration/#application-specific-configuration","title":"Application-Specific Configuration","text":""},{"location":"user-guide/configuration/#resource-management","title":"Resource Management","text":"<p>Configure resource limits per application type:</p> <pre><code># High-CPU Application\napiVersion: v1\nkind: App\nmetadata:\n  name: cpu-intensive-app\nspec:\n  type: http\n  image: \"my-app:latest\"\n  resources:\n    cpu: \"4000m\"        # 4 CPU cores\n    memory: \"2Gi\"       # 2 GiB memory\nscaling:\n  mode: auto\n  minReplicas: 2\n  maxReplicas: 10\n  maxCPUPercent: 80     # Scale when CPU &gt; 80%\n  targetRPSPerReplica: 25  # Lower RPS due to CPU intensity\n</code></pre> <pre><code># Memory-Intensive Application\napiVersion: v1\nkind: App\nmetadata:\n  name: memory-intensive-app\nspec:\n  type: http\n  image: \"my-app:latest\"\n  resources:\n    cpu: \"1000m\"        # 1 CPU core\n    memory: \"8Gi\"       # 8 GiB memory\nscaling:\n  mode: auto\n  minReplicas: 1\n  maxReplicas: 5\n  maxMemoryPercent: 85  # Scale when memory &gt; 85%\n  targetRPSPerReplica: 100\n</code></pre>"},{"location":"user-guide/configuration/#environment-specific-scaling","title":"Environment-Specific Scaling","text":"<pre><code># Development Environment\nscaling:\n  mode: manual         # Manual scaling only\n  minReplicas: 1\n  maxReplicas: 2\nhealthCheck:\n  periodSeconds: 60    # Less frequent checks\n  initialDelaySeconds: 60\n</code></pre> <pre><code># Production Environment\nscaling:\n  mode: auto\n  minReplicas: 3       # Always have at least 3\n  maxReplicas: 50      # Scale up to 50 replicas\n  targetRPSPerReplica: 100\n  maxP95LatencyMs: 150 # Strict latency requirements\n  scaleOutThresholdPct: 70  # Scale out early\n  scaleInThresholdPct: 20   # Scale in conservatively\n  cooldownSeconds: 120      # Faster scaling\nhealthCheck:\n  periodSeconds: 10    # Frequent health checks\n  failureThreshold: 2  # Fail fast\n</code></pre>"},{"location":"user-guide/configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"user-guide/configuration/#network-security","title":"Network Security","text":"<pre><code># Network Configuration\nDOCKER_NETWORK_DRIVER=bridge      # Network driver\nNETWORK_ISOLATION=true            # Enable network isolation\nFIREWALL_ENABLED=true             # Enable firewall rules\nALLOWED_CIDR_BLOCKS=10.0.0.0/8,172.16.0.0/12,192.168.0.0/16\n\n# TLS Configuration\nTLS_ENABLED=true                  # Enable TLS\nTLS_CERT_PATH=/etc/ssl/certs/orchestry.crt\nTLS_KEY_PATH=/etc/ssl/private/orchestry.key\nTLS_CA_PATH=/etc/ssl/certs/ca.crt\n</code></pre>"},{"location":"user-guide/configuration/#authentication-future","title":"Authentication (Future)","text":"<pre><code># Authentication\nAUTH_ENABLED=true                 # Enable authentication\nAUTH_METHOD=jwt                   # Authentication method\nJWT_SECRET_KEY=your-secret-key    # JWT signing key\nJWT_EXPIRY=24h                    # Token expiry\n</code></pre>"},{"location":"user-guide/configuration/#rbac-configuration-future","title":"RBAC Configuration (Future)","text":"<pre><code># rbac.yaml\napiVersion: v1\nkind: RoleBinding\nmetadata:\n  name: admin-binding\nsubjects:\n  - kind: User\n    name: admin\n    namespace: default\nroleRef:\n  kind: Role\n  name: admin\n  apiGroup: rbac.orchestry.io\n\n---\napiVersion: v1\nkind: Role\nmetadata:\n  name: developer\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"apps\"]\n    verbs: [\"get\", \"list\", \"create\", \"update\"]\n  - apiGroups: [\"\"]\n    resources: [\"apps/scale\"]\n    verbs: [\"update\"]\n</code></pre>"},{"location":"user-guide/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"user-guide/configuration/#database-optimization","title":"Database Optimization","text":"<pre><code># PostgreSQL Performance\nPOSTGRES_SHARED_BUFFERS=256MB     # Shared buffer size\nPOSTGRES_EFFECTIVE_CACHE_SIZE=1GB # Effective cache size\nPOSTGRES_WORK_MEM=4MB             # Work memory per query\nPOSTGRES_MAINTENANCE_WORK_MEM=64MB # Maintenance work memory\nPOSTGRES_WAL_BUFFERS=16MB         # WAL buffer size\nPOSTGRES_CHECKPOINT_SEGMENTS=32   # Checkpoint segments\n</code></pre>"},{"location":"user-guide/configuration/#controller-performance","title":"Controller Performance","text":"<pre><code># Controller Optimization\nORCHESTRY_WORKERS=8               # Number of worker processes\nUVICORN_WORKER_CLASS=uvicorn.workers.UvicornWorker\nUVICORN_WORKER_CONNECTIONS=1000   # Connections per worker\nUVICORN_BACKLOG=2048             # Listen backlog\nUVICORN_KEEPALIVE_TIMEOUT=5      # Keep-alive timeout\n\n# Async Settings\nASYNC_POOL_SIZE=100              # Async connection pool\nASYNC_TIMEOUT=30                 # Async operation timeout\n</code></pre>"},{"location":"user-guide/configuration/#scaling-performance","title":"Scaling Performance","text":"<pre><code># Scaling Optimization\nSCALE_CONCURRENT_LIMIT=5         # Max concurrent scaling ops\nSCALE_BATCH_SIZE=3               # Containers to scale per batch  \nSCALE_METRICS_CACHE_TTL=10       # Metrics cache TTL (seconds)\nHEALTH_CHECK_CACHE_TTL=5         # Health check cache TTL\n</code></pre>"},{"location":"user-guide/configuration/#monitoring-configuration","title":"Monitoring Configuration","text":""},{"location":"user-guide/configuration/#prometheus-integration","title":"Prometheus Integration","text":"<pre><code># prometheus.yml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'orchestry'\n    static_configs:\n      - targets: ['orchestry-controller:9090']\n    scrape_interval: 10s\n    metrics_path: /metrics\n\n  - job_name: 'applications'\n    http_sd_configs:\n      - url: http://orchestry-controller:8000/api/v1/metrics/targets\n    scrape_interval: 30s\n</code></pre>"},{"location":"user-guide/configuration/#grafana-dashboards","title":"Grafana Dashboards","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Orchestry Overview\",\n    \"panels\": [\n      {\n        \"title\": \"Application Count\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"orchestry_applications_total\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Scaling Events\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(orchestry_scaling_events_total[5m])\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"user-guide/configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"user-guide/configuration/#debug-settings","title":"Debug Settings","text":"<pre><code># Enable debug mode\nORCHESTRY_LOG_LEVEL=DEBUG\nORCHESTRY_DEBUG=true\nDEBUG_METRICS=true\nDEBUG_SCALING=true\nDEBUG_HEALTH_CHECKS=true\n</code></pre>"},{"location":"user-guide/configuration/#common-configuration-issues","title":"Common Configuration Issues","text":"<p>Database Connection Issues: <pre><code># Check connection\nPOSTGRES_RETRY_ATTEMPTS=5\nPOSTGRES_RETRY_DELAY=10\nPOSTGRES_POOL_TIMEOUT=60\n</code></pre></p> <p>Docker Socket Issues: <pre><code># Docker socket permissions\nDOCKER_HOST=unix:///var/run/docker.sock\n# Ensure orchestry user has docker group membership\nsudo usermod -aG docker orchestry\n</code></pre></p> <p>Nginx Configuration Issues: <pre><code># Nginx debugging\nNGINX_DEBUG=true\nNGINX_ERROR_LOG_LEVEL=debug\n# Test configuration\nnginx -t -c /etc/nginx/nginx.conf\n</code></pre></p> <p>Next Steps: Learn about Troubleshooting for solving common issues.</p>"},{"location":"user-guide/quick-start/","title":"Quick Start Guide","text":"<p>Get Orchestry up and running in minutes and deploy your first application.</p>"},{"location":"user-guide/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker (20.10+) and Docker Compose (v2.0+)</li> <li>Python 3.8+ (for CLI)</li> <li>Linux/macOS (Windows with WSL2)</li> <li>At least 2GB RAM and 10GB disk space</li> </ul>"},{"location":"user-guide/quick-start/#installation","title":"Installation","text":""},{"location":"user-guide/quick-start/#option-1-single-node-setup-development","title":"Option 1: Single Node Setup (Development)","text":"<pre><code># Clone the repository\ngit clone https://github.com/admincodes7/Orchestry.git\ncd Orchestry\n\n# Run the quick start script\n./start.sh\n</code></pre> <p>This script will: - Start a single Orchestry controller - Set up the PostgreSQL database - Configure Nginx load balancer - Install the CLI tool</p>"},{"location":"user-guide/quick-start/#option-2-distributed-cluster-setup-production","title":"Option 2: Distributed Cluster Setup (Production)","text":"<pre><code># Clone the repository\ngit clone https://github.com/admincodes7/Orchestry.git\ncd Orchestry\n\n# Start the 3-node distributed cluster\n./start-cluster.sh\n</code></pre> <p>This script will: - Start 3 controller nodes with leader election - Set up PostgreSQL HA cluster (primary + replica) - Configure load balancer for cluster routing - Initialize cluster coordination - Install the CLI tool</p> <p>Note: For production deployments, use the distributed cluster setup for high availability.</p>"},{"location":"user-guide/quick-start/#option-2-manual-setup","title":"Option 2: Manual Setup","text":"<pre><code># 1. Clone the repository\ngit clone https://github.com/admincodes7/Orchestry.git\ncd Orchestry\n\n# 2. Start services with Docker Compose\ndocker-compose up -d\n\n# 3. Install the CLI\npip install -e .\n\n# 4. Verify installation\norchestry --help\n</code></pre>"},{"location":"user-guide/quick-start/#verification","title":"Verification","text":""},{"location":"user-guide/quick-start/#single-node-setup","title":"Single Node Setup","text":"<p>Check that all services are running:</p> <pre><code># Check service status\ndocker-compose ps\n\n# Verify API is accessible\ncurl http://localhost:8000/health\n\n# Test CLI\norchestry list\n</code></pre> <p>You should see: - \u2705 <code>orchestry-controller</code> - Main orchestration service - \u2705 <code>orchestry-postgres-primary</code> - Primary database - \u2705 <code>orchestry-postgres-replica</code> - Replica database - \u2705 <code>orchestry-nginx</code> - Load balancer</p>"},{"location":"user-guide/quick-start/#distributed-cluster-setup","title":"Distributed Cluster Setup","text":"<p>Check cluster status:</p> <pre><code># Check cluster health\ncurl http://localhost:8000/cluster/health\n\n# Get cluster status\ncurl http://localhost:8000/cluster/status\n\n# Check current leader\ncurl http://localhost:8000/cluster/leader\n\n# View all services\ndocker-compose ps\n</code></pre> <p>You should see: - \u2705 <code>controller-1</code>, <code>controller-2</code>, <code>controller-3</code> - Controller cluster nodes - \u2705 <code>postgres-primary</code>, <code>postgres-replica</code> - PostgreSQL HA cluster - \u2705 <code>nginx-lb</code> - Load balancer with cluster routing - \ud83d\udc51 One controller node elected as leader</p>"},{"location":"user-guide/quick-start/#deploying-your-first-app","title":"Deploying Your First App","text":""},{"location":"user-guide/quick-start/#step-1-create-application-specification","title":"Step 1: Create Application Specification","text":"<p>Create a file called <code>my-app.yml</code>:</p> <pre><code>apiVersion: v1\nkind: App\nmetadata:\n  name: my-web-app\n  labels:\n    app: \"my-web-app\"\n    version: \"v1\"\nspec:\n  type: http\n  image: \"nginx:alpine\"\n  ports:\n    - containerPort: 80\n      protocol: HTTP\n  resources:\n    cpu: \"100m\"\n    memory: \"128Mi\"\n  environment:\n    - name: ENV\n      value: \"production\"\nscaling:\n  mode: auto\n  minReplicas: 1\n  maxReplicas: 5\n  targetRPSPerReplica: 50\n  maxP95LatencyMs: 250\n  scaleOutThresholdPct: 80\n  scaleInThresholdPct: 30\nhealthCheck:\n  path: \"/\"\n  port: 80\n  initialDelaySeconds: 10\n  periodSeconds: 30\n</code></pre>"},{"location":"user-guide/quick-start/#step-2-register-the-application","title":"Step 2: Register the Application","text":"<pre><code>orchestry register my-app.yml\n</code></pre>"},{"location":"user-guide/quick-start/#step-3-start-the-application","title":"Step 3: Start the Application","text":"<pre><code>orchestry up my-web-app\n</code></pre>"},{"location":"user-guide/quick-start/#step-4-check-status","title":"Step 4: Check Status","text":"<pre><code># View application status\norchestry status my-web-app\n\n# List all applications\norchestry list\n\n# View application logs\norchestry logs my-web-app\n</code></pre>"},{"location":"user-guide/quick-start/#step-5-test-your-application","title":"Step 5: Test Your Application","text":"<p>Your application is now accessible through the load balancer:</p> <pre><code># Test the application\ncurl http://localhost/my-web-app\n\n# Or open in browser\nopen http://localhost/my-web-app\n</code></pre>"},{"location":"user-guide/quick-start/#scaling-your-application","title":"Scaling Your Application","text":""},{"location":"user-guide/quick-start/#manual-scaling","title":"Manual Scaling","text":"<pre><code># Scale to 3 replicas\norchestry scale my-web-app 3\n\n# Scale down to 1 replica\norchestry scale my-web-app 1\n</code></pre>"},{"location":"user-guide/quick-start/#auto-scaling","title":"Auto-Scaling","text":"<p>Orchestry automatically scales based on: - CPU utilization (target: 70%) - Memory usage (target: 75%) - Requests per second (50 RPS per replica) - Response latency (P95 &lt; 250ms) - Active connections (80 per replica)</p> <p>Monitor scaling decisions:</p> <pre><code># View scaling events\norchestry events my-web-app\n\n# View current metrics\norchestry metrics my-web-app\n</code></pre>"},{"location":"user-guide/quick-start/#management-commands","title":"Management Commands","text":"<pre><code># Stop application\norchestry down my-web-app\n\n# Remove application\norchestry remove my-web-app\n\n# View all applications\norchestry list\n\n# Get application details\norchestry describe my-web-app\n\n# View system status\norchestry status\n</code></pre>"},{"location":"user-guide/quick-start/#configuration","title":"Configuration","text":""},{"location":"user-guide/quick-start/#environment-variables","title":"Environment Variables","text":"<p>Configure Orchestry behavior with environment variables:</p> <pre><code># Controller API settings\nexport ORCHESTRY_HOST=localhost\nexport ORCHESTRY_PORT=8000\n\n# Database settings\nexport POSTGRES_HOST=localhost\nexport POSTGRES_PORT=5432\nexport POSTGRES_DB=orchestry\nexport POSTGRES_USER=orchestry\nexport POSTGRES_PASSWORD=orchestry_password\n\n# Scaling settings\nexport DEFAULT_SCALE_CHECK_INTERVAL=30\nexport DEFAULT_HEALTH_CHECK_INTERVAL=10\n</code></pre>"},{"location":"user-guide/quick-start/#cluster-mode","title":"Cluster Mode","text":"<p>For high availability, run Orchestry in cluster mode:</p> <pre><code># Start cluster\n./start-cluster.sh\n\n# Check cluster status\norchestry cluster status\n</code></pre>"},{"location":"user-guide/quick-start/#next-steps","title":"Next Steps","text":"<p>Now that you have Orchestry running:</p> <ol> <li>Learn the CLI: Check out the CLI Reference</li> <li>Understand App Specs: Read the Application Specification guide</li> <li>Explore the API: See the REST API Reference</li> <li>Configure Scaling: Dive into Configuration Guide</li> <li>Monitor Applications: Learn about health monitoring</li> </ol>"},{"location":"user-guide/quick-start/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Browse the complete docs</li> <li>Examples: Check the <code>examples/</code> directory</li> <li>Issues: Report bugs on GitHub</li> <li>Community: Join our discussions</li> </ul> <p>Troubleshooting: If you encounter issues, see the Troubleshooting Guide.</p>"},{"location":"user-guide/troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues, solutions, and debugging techniques for Orchestry.</p>"},{"location":"user-guide/troubleshooting/#quick-diagnosis","title":"Quick Diagnosis","text":""},{"location":"user-guide/troubleshooting/#service-status-check","title":"Service Status Check","text":"<p>First, verify all services are running:</p> <pre><code># Check Orchestry services\ndocker-compose ps\n\n# Check API health\ncurl http://localhost:8000/health\n\n# Check database connectivity\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"SELECT 1;\"\n\n# Check nginx status\ndocker exec -it orchestry-nginx nginx -t\n</code></pre>"},{"location":"user-guide/troubleshooting/#common-status-issues","title":"Common Status Issues","text":"Service Status Possible Cause Solution <code>orchestry-controller</code> Exited Configuration error Check logs: <code>docker logs orchestry-controller</code> <code>orchestry-postgres-primary</code> Unhealthy Database startup issue Check DB logs: <code>docker logs orchestry-postgres-primary</code> <code>orchestry-nginx</code> Restarting Config syntax error Validate nginx config: <code>nginx -t</code>"},{"location":"user-guide/troubleshooting/#application-issues","title":"Application Issues","text":""},{"location":"user-guide/troubleshooting/#application-wont-start","title":"Application Won't Start","text":"<p>Symptoms: - Application status shows \"error\" or \"failed\" - Containers are not created - API returns 500 errors</p> <p>Diagnostic Steps:</p> <pre><code># Check application status\norchestry status my-app\n\n# View application events\norchestry events my-app\n\n# Check Docker daemon\ndocker info\n\n# Verify image exists\ndocker pull my-app:latest\n\n# Check network configuration\ndocker network ls | grep orchestry\n</code></pre> <p>Common Causes and Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-image-pull-errors","title":"1. Image Pull Errors","text":"<pre><code># Error: \"pull access denied\" or \"image not found\"\n# Solution: Verify image name and registry access\ndocker login myregistry.com\ndocker pull myregistry.com/my-app:v1.0.0\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-resource-constraints","title":"2. Resource Constraints","text":"<pre><code># Error: \"insufficient memory\" or \"insufficient cpu\"\n# Check system resources\ndocker system df\ndocker stats\n\n# Solution: Increase limits or reduce resource requests\n</code></pre> <pre><code># Reduce resource requirements\nspec:\n  resources:\n    cpu: \"100m\"    # Reduced from 1000m\n    memory: \"256Mi\" # Reduced from 1Gi\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-port-conflicts","title":"3. Port Conflicts","text":"<pre><code># Error: \"port already in use\"\n# Check port usage\nnetstat -tulpn | grep :8000\ndocker ps --format \"table {{.Names}}\\t{{.Ports}}\"\n\n# Solution: Use different ports or stop conflicting services\n</code></pre>"},{"location":"user-guide/troubleshooting/#4-environment-variable-issues","title":"4. Environment Variable Issues","text":"<pre><code># Check container logs for env var errors\norchestry logs my-app --tail 50\n\n# Common issues:\n# - Missing required environment variables\n# - Invalid database URLs\n# - Incorrect service endpoints\n</code></pre>"},{"location":"user-guide/troubleshooting/#application-crashes-repeatedly","title":"Application Crashes Repeatedly","text":"<p>Symptoms: - Container keeps restarting - Health checks failing - High failure count in status</p> <p>Diagnostic Steps:</p> <pre><code># Check crash logs\norchestry logs my-app --since 1h\n\n# View container restart events\norchestry events my-app --type error\n\n# Check resource usage\ndocker stats $(docker ps -q --filter \"label=orchestry.app=my-app\")\n</code></pre> <p>Common Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-memory-issues-oom-kills","title":"1. Memory Issues (OOM Kills)","text":"<pre><code># Check for OOM kills in system logs\ndmesg | grep -i \"killed process\"\njournalctl -u docker.service | grep -i \"oom\"\n</code></pre> <p>Solution: <pre><code># Increase memory limits\nspec:\n  resources:\n    memory: \"2Gi\"  # Increased from 1Gi\n\n# Or optimize application memory usage\nenvironment:\n  - name: NODE_OPTIONS\n    value: \"--max-old-space-size=1536\"  # For Node.js apps\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#2-health-check-failures","title":"2. Health Check Failures","text":"<pre><code># Test health check manually\ncurl -f http://container-ip:port/health\n\n# Check health check configuration\norchestry describe my-app --show-spec | grep -A 10 healthCheck\n</code></pre> <p>Solution: <pre><code># Adjust health check settings\nhealthCheck:\n  path: \"/health\"\n  port: 8080\n  initialDelaySeconds: 60  # Increased startup time\n  periodSeconds: 30\n  timeoutSeconds: 10       # Increased timeout\n  failureThreshold: 5      # More tolerance\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#3-dependency-issues","title":"3. Dependency Issues","text":"<pre><code># Check if app depends on external services\norchestry logs my-app | grep -i \"connection\\|database\\|redis\\|timeout\"\n</code></pre> <p>Solution: <pre><code># Add dependency health checks and retries\nenvironment:\n  - name: DB_RETRY_ATTEMPTS\n    value: \"10\"\n  - name: DB_RETRY_DELAY\n    value: \"5\"\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#scaling-issues","title":"Scaling Issues","text":""},{"location":"user-guide/troubleshooting/#application-not-scaling","title":"Application Not Scaling","text":"<p>Symptoms: - Load increases but replica count stays same - Scaling events show \"no scaling needed\" - Manual scaling works but auto-scaling doesn't</p> <p>Diagnostic Steps:</p> <pre><code># Check scaling policy\norchestry describe my-app | grep -A 20 scaling\n\n# View scaling events\norchestry events my-app --type scaling\n\n# Check current metrics\norchestry metrics my-app\n\n# Verify auto-scaling is enabled\norchestry status my-app | grep -i mode\n</code></pre> <p>Common Causes and Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-scaling-mode-set-to-manual","title":"1. Scaling Mode Set to Manual","text":"<pre><code># Check current mode\norchestry describe my-app | grep mode\n\n# Solution: Enable auto scaling\ncurl -X PUT http://localhost:8000/api/v1/apps/my-app/scaling \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"mode\": \"auto\"}'\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-in-cooldown-period","title":"2. In Cooldown Period","text":"<pre><code># Check last scaling event\norchestry events my-app --type scaling --limit 1\n\n# If recent scaling occurred, wait for cooldown period\n# Default cooldown is 180 seconds\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-metrics-below-threshold","title":"3. Metrics Below Threshold","text":"<pre><code># Check current metrics vs thresholds\norchestry metrics my-app --format json | jq '.current'\n\n# View scaling thresholds\norchestry describe my-app | grep -i threshold\n</code></pre> <p>Solution: <pre><code># Adjust scaling thresholds\nscaling:\n  scaleOutThresholdPct: 60  # Reduced from 80\n  scaleInThresholdPct: 20   # Reduced from 30\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#4-insufficient-resources","title":"4. Insufficient Resources","text":"<pre><code># Check system resources\ndocker system df\ndocker stats --no-stream\n\n# Check Docker daemon limits\ndocker info | grep -i memory\n</code></pre>"},{"location":"user-guide/troubleshooting/#scaling-too-aggressiveconservative","title":"Scaling Too Aggressive/Conservative","text":"<p>Symptoms: - Application scales up/down too frequently - Resource waste due to over-provisioning - Performance issues due to under-provisioning</p> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#too-aggressive-scaling","title":"Too Aggressive Scaling","text":"<pre><code># Increase cooldown period\nscaling:\n  cooldownSeconds: 300  # Increased from 180\n\n# Make thresholds more conservative\nscaling:\n  scaleOutThresholdPct: 85  # Increased from 80\n  scaleInThresholdPct: 15   # Decreased from 30\n\n# Increase evaluation window\nscaling:\n  windowSeconds: 120  # Increased from 60\n</code></pre>"},{"location":"user-guide/troubleshooting/#too-conservative-scaling","title":"Too Conservative Scaling","text":"<pre><code># Decrease cooldown period\nscaling:\n  cooldownSeconds: 120  # Decreased from 180\n\n# Make thresholds more aggressive\nscaling:\n  scaleOutThresholdPct: 70  # Decreased from 80\n  scaleInThresholdPct: 40   # Increased from 30\n</code></pre>"},{"location":"user-guide/troubleshooting/#network-and-load-balancing-issues","title":"Network and Load Balancing Issues","text":""},{"location":"user-guide/troubleshooting/#application-not-accessible","title":"Application Not Accessible","text":"<p>Symptoms: - Application status shows \"running\" but requests fail - 502/503 errors from load balancer - Connection timeouts</p> <p>Diagnostic Steps:</p> <pre><code># Check nginx configuration\ndocker exec orchestry-nginx nginx -t\n\n# View nginx error logs\ndocker logs orchestry-nginx\n\n# Check upstream configuration\ndocker exec orchestry-nginx cat /etc/nginx/conf.d/my-app.conf\n\n# Test container directly\ndocker exec -it my-app-1 curl localhost:8080/health\n</code></pre> <p>Common Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-nginx-configuration-errors","title":"1. Nginx Configuration Errors","text":"<pre><code># Check nginx config syntax\ndocker exec orchestry-nginx nginx -t\n\n# Reload nginx configuration\ndocker exec orchestry-nginx nginx -s reload\n\n# View generated upstream config\ndocker exec orchestry-nginx ls -la /etc/nginx/conf.d/\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-container-network-issues","title":"2. Container Network Issues","text":"<pre><code># Check container network connectivity\ndocker network inspect orchestry\n\n# Verify container IPs\ndocker inspect my-app-1 | jq '.[0].NetworkSettings.Networks.orchestry.IPAddress'\n\n# Test inter-container connectivity\ndocker exec orchestry-nginx ping container-ip\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-health-check-failures","title":"3. Health Check Failures","text":"<pre><code># Check container health status\norchestry status my-app\n\n# Test health checks manually\ncurl http://container-ip:port/health\n\n# Check health check logs\norchestry events my-app --type health\n</code></pre>"},{"location":"user-guide/troubleshooting/#load-distribution-issues","title":"Load Distribution Issues","text":"<p>Symptoms: - Uneven load distribution across replicas - Some containers overloaded while others idle - Inconsistent response times</p> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-nginx-load-balancing-method","title":"1. Nginx Load Balancing Method","text":"<pre><code># Check current load balancing method\ndocker exec orchestry-nginx grep -r \"least_conn\\|ip_hash\" /etc/nginx/conf.d/\n\n# For session-less apps, use least_conn (default)\n# For session-based apps, consider ip_hash\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-container-resource-imbalance","title":"2. Container Resource Imbalance","text":"<pre><code># Check resource usage per container\ndocker stats --format \"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\"\n\n# Ensure containers have same resource limits\norchestry describe my-app | grep -A 5 resources\n</code></pre>"},{"location":"user-guide/troubleshooting/#database-issues","title":"Database Issues","text":""},{"location":"user-guide/troubleshooting/#database-connection-errors","title":"Database Connection Errors","text":"<p>Symptoms: - Applications can't connect to database - Connection timeout errors - \"too many connections\" errors</p> <p>Diagnostic Steps:</p> <pre><code># Check database status\ndocker logs orchestry-postgres-primary\n\n# Test database connectivity\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"SELECT 1;\"\n\n# Check active connections\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"SELECT count(*) FROM pg_stat_activity;\"\n\n# Verify connection string format\necho $DATABASE_URL\n</code></pre> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-connection-pool-exhaustion","title":"1. Connection Pool Exhaustion","text":"<pre><code># Check max connections\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"SHOW max_connections;\"\n\n# Increase max connections\n# Edit postgresql.conf or use environment variable\n</code></pre> <pre><code># In docker-compose.yml\nenvironment:\n  POSTGRES_MAX_CONNECTIONS: 200\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-network-connectivity","title":"2. Network Connectivity","text":"<pre><code># Test network connectivity from app container\ndocker exec -it my-app-1 nc -zv postgres-host 5432\n\n# Check Docker network\ndocker network inspect orchestry\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-authentication-issues","title":"3. Authentication Issues","text":"<pre><code># Check pg_hba.conf settings\ndocker exec orchestry-postgres-primary cat /var/lib/postgresql/data/pg_hba.conf\n\n# Test authentication\ndocker exec -it orchestry-postgres-primary psql -U orchestry -h localhost -d orchestry\n</code></pre>"},{"location":"user-guide/troubleshooting/#database-performance-issues","title":"Database Performance Issues","text":"<p>Symptoms: - Slow query response times - Database CPU/memory high - Application timeouts</p> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-resource-allocation","title":"1. Resource Allocation","text":"<pre><code># Increase database resources\nservices:\n  postgres-primary:\n    environment:\n      POSTGRES_SHARED_BUFFERS: 256MB\n      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB\n    deploy:\n      resources:\n        limits:\n          memory: 4G\n          cpus: '2.0'\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-connection-pooling","title":"2. Connection Pooling","text":"<pre><code># Implement connection pooling in applications\n# Use pgbouncer or application-level pooling\n</code></pre> <pre><code># Application configuration\nenvironment:\n  - name: DB_POOL_SIZE\n    value: \"10\"\n  - name: DB_POOL_TIMEOUT\n    value: \"30\"\n</code></pre>"},{"location":"user-guide/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"user-guide/troubleshooting/#high-latency","title":"High Latency","text":"<p>Symptoms: - Response times consistently high - P95 latency above thresholds - User complaints about slow responses</p> <p>Diagnostic Steps:</p> <pre><code># Check application metrics\norchestry metrics my-app\n\n# View scaling decisions\norchestry events my-app --type scaling\n\n# Check resource utilization\ndocker stats my-app-1 my-app-2 my-app-3\n\n# Test response times directly\ncurl -w \"%{time_total}\\n\" -o /dev/null -s http://localhost/my-app/\n</code></pre> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-scale-out-application","title":"1. Scale Out Application","text":"<pre><code># Manual scaling\norchestry scale my-app 5\n\n# Or adjust auto-scaling thresholds\n</code></pre> <pre><code>scaling:\n  maxP95LatencyMs: 200      # Reduced threshold\n  scaleOutThresholdPct: 70  # Scale out earlier\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-optimize-resource-allocation","title":"2. Optimize Resource Allocation","text":"<pre><code># Increase CPU allocation\nspec:\n  resources:\n    cpu: \"2000m\"  # Increased from 1000m\n    memory: \"2Gi\"\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-add-caching","title":"3. Add Caching","text":"<pre><code># Add Redis cache\nenvironment:\n  - name: REDIS_URL\n    value: \"redis://redis.example.com:6379\"\n  - name: CACHE_TTL\n    value: \"300\"\n</code></pre>"},{"location":"user-guide/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptoms: - Containers being OOM killed - Memory usage consistently high - Frequent container restarts</p> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-increase-memory-limits","title":"1. Increase Memory Limits","text":"<pre><code>spec:\n  resources:\n    memory: \"4Gi\"  # Increased from 2Gi\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-optimize-application","title":"2. Optimize Application","text":"<pre><code># For Node.js applications\nenvironment:\n  - name: NODE_OPTIONS\n    value: \"--max-old-space-size=3072\"\n\n# For Java applications\nenvironment:\n  - name: JAVA_OPTS\n    value: \"-Xms1g -Xmx3g -XX:+UseG1GC\"\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-memory-profiling","title":"3. Memory Profiling","text":"<pre><code># Enable memory profiling\n# Add profiling tools to container\n# Monitor memory usage patterns\n</code></pre>"},{"location":"user-guide/troubleshooting/#monitoring-and-debugging","title":"Monitoring and Debugging","text":""},{"location":"user-guide/troubleshooting/#insufficient-logging","title":"Insufficient Logging","text":"<p>Problem: Can't debug issues due to lack of logs</p> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-increase-log-levels","title":"1. Increase Log Levels","text":"<pre><code>environment:\n  - name: LOG_LEVEL\n    value: \"DEBUG\"  # Temporarily for debugging\n  - name: DEBUG\n    value: \"*\"      # For debug module\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-structured-logging","title":"2. Structured Logging","text":"<pre><code>environment:\n  - name: LOG_FORMAT\n    value: \"json\"\n  - name: LOG_TIMESTAMP\n    value: \"true\"\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-log-aggregation","title":"3. Log Aggregation","text":"<pre><code># View logs from all replicas\norchestry logs my-app --follow\n\n# View specific time range\norchestry logs my-app --since 2h --until 1h\n</code></pre>"},{"location":"user-guide/troubleshooting/#missing-metrics","title":"Missing Metrics","text":"<p>Problem: Can't monitor application performance</p> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-enable-application-metrics","title":"1. Enable Application Metrics","text":"<pre><code># Add metrics endpoint\nports:\n  - containerPort: 8080\n    name: \"api\"\n  - containerPort: 9090\n    name: \"metrics\"\n\nenvironment:\n  - name: METRICS_ENABLED\n    value: \"true\"\n  - name: METRICS_PORT\n    value: \"9090\"\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-custom-health-checks","title":"2. Custom Health Checks","text":"<pre><code>healthCheck:\n  path: \"/health/detailed\"\n  port: 8080\n  headers:\n    - name: \"X-Health-Check\"\n      value: \"orchestry\"\n</code></pre>"},{"location":"user-guide/troubleshooting/#configuration-issues","title":"Configuration Issues","text":""},{"location":"user-guide/troubleshooting/#environment-variable-problems","title":"Environment Variable Problems","text":"<p>Symptoms: - Application fails to start - Feature flags not working - Database connections failing</p> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-validate-environment-variables","title":"1. Validate Environment Variables","text":"<pre><code># Check container environment\ndocker exec my-app-1 env | grep MY_VAR\n\n# Validate in application specification\norchestry describe my-app | grep -A 20 environment\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-secret-management","title":"2. Secret Management","text":"<pre><code># Use secrets for sensitive data\nenvironment:\n  - name: DATABASE_PASSWORD\n    source: secret\n    key: \"db-credentials\"\n    field: \"password\"\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-configuration-validation","title":"3. Configuration Validation","text":"<pre><code># Add configuration validation to application startup\n# Log all configuration values (except secrets)\n# Fail fast on missing required configuration\n</code></pre>"},{"location":"user-guide/troubleshooting/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"user-guide/troubleshooting/#complete-system-recovery","title":"Complete System Recovery","text":"<p>If Orchestry is completely down:</p> <pre><code># 1. Stop all services\ndocker-compose down\n\n# 2. Check for disk space issues\ndf -h\ndocker system prune -f\n\n# 3. Restart services\ndocker-compose up -d\n\n# 4. Wait for services to be healthy\ndocker-compose ps\n\n# 5. Verify database connectivity\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"SELECT count(*) FROM applications;\"\n\n# 6. Restart applications\norchestry list\nfor app in $(orchestry list --format json | jq -r '.apps[].name'); do\n  orchestry up $app\ndone\n</code></pre>"},{"location":"user-guide/troubleshooting/#database-recovery","title":"Database Recovery","text":"<p>If database is corrupted:</p> <pre><code># 1. Stop Orchestry\ndocker-compose stop orchestry-controller\n\n# 2. Backup current database\ndocker exec orchestry-postgres-primary pg_dump -U orchestry orchestry &gt; backup.sql\n\n# 3. Check database integrity\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"SELECT pg_database_size('orchestry');\"\n\n# 4. If needed, restore from backup\ndocker exec -i orchestry-postgres-primary psql -U orchestry -d orchestry &lt; backup.sql\n\n# 5. Restart services\ndocker-compose up -d\n</code></pre>"},{"location":"user-guide/troubleshooting/#application-recovery","title":"Application Recovery","text":"<p>If specific application is stuck:</p> <pre><code># 1. Stop application\norchestry down my-app --force\n\n# 2. Clean up containers\ndocker rm -f $(docker ps -aq --filter \"label=orchestry.app=my-app\")\n\n# 3. Clear application state (if needed)\n# This will lose scaling history but preserve configuration\ncurl -X DELETE http://localhost:8000/api/v1/apps/my-app/instances\n\n# 4. Restart application\norchestry up my-app\n\n# 5. Monitor startup\norchestry logs my-app --follow\n</code></pre>"},{"location":"user-guide/troubleshooting/#cluster-and-leader-election-issues","title":"Cluster and Leader Election Issues","text":""},{"location":"user-guide/troubleshooting/#requests-not-reaching-current-leader","title":"Requests Not Reaching Current Leader","text":"<p>Symptoms: - Write operations (POST, PUT, DELETE) return 503 Service Unavailable - API returns \"Not the leader\" errors after leader failover - Applications not updating despite API calls</p> <p>Diagnostic Steps:</p> <pre><code># Check cluster status\ncurl http://localhost:8000/cluster/status\n\n# Check current leader\ncurl http://localhost:8000/cluster/leader\n\n# Check individual controller health  \ncurl http://localhost:8001/health  # Controller 1\ncurl http://localhost:8002/health  # Controller 2\ncurl http://localhost:8003/health  # Controller 3\n\n# Check controller load balancer logs\ndocker logs orchestry-controller-lb\n\n# Check if load balancer is routing correctly\ncurl -H \"X-Debug: true\" http://localhost:8000/cluster/leader\n</code></pre> <p>Common Causes and Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-load-balancer-not-routing-to-current-leader","title":"1. Load Balancer Not Routing to Current Leader","text":"<p>The load balancer should automatically route write operations to the current leader. If this isn't working:</p> <pre><code># Check nginx upstream configuration\ndocker exec orchestry-controller-lb cat /etc/nginx/conf.d/default.conf\n\n# Verify all controllers are reachable\ndocker exec orchestry-controller-lb nslookup controller-1\ndocker exec orchestry-controller-lb nslookup controller-2  \ndocker exec orchestry-controller-lb nslookup controller-3\n\n# Check nginx error logs for upstream failures\ndocker logs orchestry-controller-lb | grep -i error\n</code></pre> <p>Solution: The system now uses nginx failover. When a non-leader controller receives a write request, it returns 503, causing nginx to try the next controller until it finds the leader.</p>"},{"location":"user-guide/troubleshooting/#2-leader-election-split-brain","title":"2. Leader Election Split-Brain","text":"<p>Symptoms: - Multiple controllers claim to be leader - Inconsistent cluster status from different controllers</p> <pre><code># Check each controller's view of leadership\nfor port in 8001 8002 8003; do\n  echo \"Controller $port leadership status:\"\n  curl -s http://localhost:$port/cluster/status | jq '.is_leader'\ndone\n\n# Check database lease table\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"SELECT * FROM leader_lease ORDER BY term DESC LIMIT 5;\"\n</code></pre> <p>Solution: <pre><code># Force leadership release (from current leader)\ncurl -X DELETE http://localhost:8000/api/v1/cluster/leadership\n\n# Restart all controllers to re-trigger election\ndocker-compose restart controller-1 controller-2 controller-3\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#3-stale-leader-information","title":"3. Stale Leader Information","text":"<p>Symptoms: - Clients redirected to dead leader - API calls timeout or return connection errors</p> <pre><code># Check if leader info is stale\nLEADER_URL=$(curl -s http://localhost:8000/cluster/leader | jq -r '.api_url')\ncurl -f $LEADER_URL/health || echo \"Leader not reachable\"\n\n# Check leader lease expiration\ncurl -s http://localhost:8000/cluster/leader | jq '.lease_expires_at'\ndate +%s  # Compare with current timestamp\n</code></pre> <p>Solution: The new implementation always redirects clients to the load balancer, not individual controllers, preventing stale leader issues.</p>"},{"location":"user-guide/troubleshooting/#4-network-partitioning","title":"4. Network Partitioning","text":"<p>Symptoms: - Some controllers can't reach database - Controllers in different network states</p> <pre><code># Test database connectivity from each controller\nfor service in controller-1 controller-2 controller-3; do\n  echo \"Testing $service database connectivity:\"\n  docker exec $service nc -zv postgres-primary 5432\ndone\n\n# Check network partitions\ndocker network inspect orchestry\n</code></pre>"},{"location":"user-guide/troubleshooting/#leader-election-taking-too-long","title":"Leader Election Taking Too Long","text":"<p>Symptoms: - No leader elected for extended periods - Cluster shows \"No leader elected\" status - Write operations return 503 for long periods</p> <p>Diagnostic Steps:</p> <pre><code># Check election process\ndocker logs orchestry-controller-1 | grep -i \"election\\|leader\"\ndocker logs orchestry-controller-2 | grep -i \"election\\|leader\"  \ndocker logs orchestry-controller-3 | grep -i \"election\\|leader\"\n\n# Check database lease attempts\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"SELECT * FROM leader_lease ORDER BY acquired_at DESC LIMIT 10;\"\n\n# Monitor election attempts\ncurl -s http://localhost:8000/cluster/status | jq '.election_status'\n</code></pre> <p>Common Causes:</p>"},{"location":"user-guide/troubleshooting/#1-database-connectivity-issues","title":"1. Database Connectivity Issues","text":"<pre><code># Test database connectivity\nfor port in 8001 8002 8003; do\n  echo \"Controller $port database test:\"\n  curl -s http://localhost:$port/health | jq '.database'\ndone\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-clock-synchronization-issues","title":"2. Clock Synchronization Issues","text":"<pre><code># Check system clocks on containers\ndocker exec controller-1 date\ndocker exec controller-2 date\ndocker exec controller-3 date\n\n# Large time differences can cause lease issues\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-resource-constraints","title":"3. Resource Constraints","text":"<pre><code># Check controller resource usage\ndocker stats controller-1 controller-2 controller-3 --no-stream\n\n# High CPU/memory usage can delay election processing\n</code></pre>"},{"location":"user-guide/troubleshooting/#frequent-leader-changes","title":"Frequent Leader Changes","text":"<p>Symptoms: - Leader changes every few minutes - Applications experience interruptions - Scaling decisions inconsistent</p> <p>Diagnostic Steps:</p> <pre><code># Monitor leader changes\nwatch -n 5 'curl -s http://localhost:8000/cluster/leader | jq .leader_id'\n\n# Check lease renewal logs\ndocker logs orchestry-controller-1 | grep -i \"lease\\|renew\"\n\n# Check for resource issues\ndocker stats --no-stream | grep controller\n</code></pre> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-increase-lease-duration","title":"1. Increase Lease Duration","text":"<pre><code># In controller configuration\nenvironment:\n  - name: LEADER_LEASE_TTL\n    value: \"45\"  # Increased from 30 seconds\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-improve-network-stability","title":"2. Improve Network Stability","text":"<pre><code># Check for network issues\ndocker network inspect orchestry | jq '.Containers'\n\n# Monitor network latency between controllers\n</code></pre>"},{"location":"user-guide/troubleshooting/#controller-startup-issues","title":"Controller Startup Issues","text":"<p>Symptoms: - Controllers fail to join cluster - Startup errors in logs - Services not reaching healthy state</p> <p>Solutions:</p>"},{"location":"user-guide/troubleshooting/#1-database-migration-issues","title":"1. Database Migration Issues","text":"<pre><code># Check database schema\ndocker exec -it orchestry-postgres-primary psql -U orchestry -d orchestry -c \"\\dt\"\n\n# Manually run migrations if needed\ndocker exec orchestry-controller-1 python -m alembic upgrade head\n</code></pre>"},{"location":"user-guide/troubleshooting/#2-port-conflicts","title":"2. Port Conflicts","text":"<pre><code># Check port availability\nnetstat -tulpn | grep -E \":(8001|8002|8003|8000)\"\n\n# Ensure ports in .env file match docker-compose.yml\ngrep -E \"CONTROLLER.*PORT\" .env.docker\n</code></pre>"},{"location":"user-guide/troubleshooting/#3-environment-configuration","title":"3. Environment Configuration","text":"<pre><code># Verify required environment variables\ndocker exec controller-1 env | grep -E \"CLUSTER|CONTROLLER|POSTGRES\"\n\n# Check for missing variables\ndocker-compose config | grep -A 10 -B 5 controller-1\n</code></pre>"},{"location":"user-guide/troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"user-guide/troubleshooting/#collecting-diagnostic-information","title":"Collecting Diagnostic Information","text":"<p>Before seeking help, collect this information:</p> <pre><code>#!/bin/bash\n# Orchestry diagnostic script\n\necho \"=== Orchestry Diagnostic Information ===\"\necho \"Date: $(date)\"\necho \"Version: $(orchestry --version)\"\necho\n\necho \"=== System Information ===\"\nuname -a\ndocker --version\ndocker-compose --version\necho\n\necho \"=== Service Status ===\"\ndocker-compose ps\necho\n\necho \"=== API Health ===\"\ncurl -s http://localhost:8000/health | jq '.' || echo \"API not responding\"\necho\n\necho \"=== Application Status ===\"\norchestry list\necho\n\necho \"=== Recent Events ===\"\norchestry events --limit 20\necho\n\necho \"=== System Resources ===\"\ndocker system df\ndocker stats --no-stream\necho\n\necho \"=== Recent Logs ===\"\necho \"Controller logs:\"\ndocker logs --tail 50 orchestry-controller\necho\necho \"Database logs:\"\ndocker logs --tail 20 orchestry-postgres-primary\necho\necho \"Nginx logs:\"\ndocker logs --tail 20 orchestry-nginx\n</code></pre>"},{"location":"user-guide/troubleshooting/#support-channels","title":"Support Channels","text":"<ol> <li>GitHub Issues: Report bugs and feature requests</li> <li>Documentation: Check latest documentation</li> <li>Community: Join discussions and ask questions</li> <li>Enterprise Support: Contact for enterprise deployments</li> </ol>"},{"location":"user-guide/troubleshooting/#best-practices-for-issue-reporting","title":"Best Practices for Issue Reporting","text":"<ol> <li>Include diagnostic information from the script above</li> <li>Describe expected vs actual behavior</li> <li>Provide minimal reproduction steps</li> <li>Include application specifications (without secrets)</li> <li>Mention environment details (OS, Docker version, etc.)</li> </ol> <p>Next Steps: Learn about Configuration for advanced settings and optimizations.</p>"}]}